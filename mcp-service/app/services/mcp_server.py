"""
MCPæœåŠ¡å™¨æ ¸å¿ƒæœåŠ¡
æ•´åˆAIåˆ†æå’Œå›¾è¡¨ç”ŸæˆåŠŸèƒ½
"""

import logging
import json
import os
from typing import Dict, List, Any, Optional
from datetime import datetime
import psycopg2
from psycopg2.extras import RealDictCursor

from .ai_service import DeepSeekAIService
from .claude_ai_service import ClaudeAIService
from .chart_service import ChartConfigGenerator
from .mcp_tools import MCPTools

logger = logging.getLogger(__name__)

class MCPServer:
    """MCPæœåŠ¡å™¨æ ¸å¿ƒæœåŠ¡"""
    
    def __init__(self, ai_service: DeepSeekAIService, chart_generator: ChartConfigGenerator):
        self.ai_service = ai_service
        self.chart_generator = chart_generator
        
        # æ•°æ®åº“è¿æ¥é…ç½®
        self.db_config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'port': int(os.getenv('DB_PORT', '5432')),
            'database': os.getenv('DB_NAME', 'financetool_test'),
            'user': os.getenv('DB_USER', 'financetool_user'),
            'password': os.getenv('DB_PASSWORD', 'financetool_pass')
        }
        
        # åˆå§‹åŒ–MCPå·¥å…·
        self.mcp_tools = MCPTools(self.db_config)
        
        # é‡æ–°åˆå§‹åŒ–DeepSeek AIæœåŠ¡ï¼Œä¼ å…¥MCPå·¥å…·
        if hasattr(self.ai_service, '__class__') and self.ai_service.__class__.__name__ == 'DeepSeekAIService':
            # åˆ›å»ºæ–°çš„DeepSeek AIæœåŠ¡å®ä¾‹ï¼Œä¼ å…¥MCPå·¥å…·
            from .ai_service import DeepSeekAIService as DeepSeekClass
            self.ai_service = DeepSeekClass(self.mcp_tools)
            logger.info("âœ… é‡æ–°åˆå§‹åŒ–DeepSeek AIæœåŠ¡ï¼Œé›†æˆMCPå·¥å…·")
        
        # åˆå§‹åŒ–Claude AIæœåŠ¡ï¼ˆä»…åœ¨APIå¯†é’¥é…ç½®æ—¶ï¼‰
        self.claude_ai = None
        if os.getenv("CLAUDE_API_KEY"):
            self.claude_ai = ClaudeAIService(self.mcp_tools)
        
        # æ‰“å°æ•°æ®åº“é…ç½®ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
        logger.info(f"æ•°æ®åº“é…ç½®: host={self.db_config['host']}, port={self.db_config['port']}, database={self.db_config['database']}, user={self.db_config['user']}")
        
        # æ¨¡æ‹Ÿæ•°æ®ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        self.mock_data = {
            "asset_snapshot": [
                {
                    "platform": "æ”¯ä»˜å®",
                    "asset_type": "åŸºé‡‘", 
                    "asset_code": "005827",
                    "asset_name": "æ˜“æ–¹è¾¾è“ç­¹ç²¾é€‰æ··åˆ",
                    "balance_cny": 85230.45,
                    "snapshot_time": "2024-01-15 09:00:00"
                },
                {
                    "platform": "æ”¯ä»˜å®",
                    "asset_type": "åŸºé‡‘",
                    "asset_code": "110022", 
                    "asset_name": "æ˜“æ–¹è¾¾æ¶ˆè´¹è¡Œä¸šè‚¡ç¥¨",
                    "balance_cny": 73229.85,
                    "snapshot_time": "2024-01-15 09:00:00"
                },
                {
                    "platform": "Wise",
                    "asset_type": "å¤–æ±‡",
                    "asset_code": "USD",
                    "asset_name": "ç¾å…ƒç°é‡‘",
                    "balance_cny": 6458.23,
                    "snapshot_time": "2024-01-15 09:00:00"
                },
                {
                    "platform": "Wise", 
                    "asset_type": "å¤–æ±‡",
                    "asset_code": "EUR",
                    "asset_name": "æ¬§å…ƒç°é‡‘", 
                    "balance_cny": 1700.00,
                    "snapshot_time": "2024-01-15 09:00:00"
                },
                {
                    "platform": "IBKR",
                    "asset_type": "è‚¡ç¥¨",
                    "asset_code": "AAPL", 
                    "asset_name": "è‹¹æœå…¬å¸",
                    "balance_cny": 42.03,
                    "snapshot_time": "2024-01-15 09:00:00"
                },
                {
                    "platform": "OKX",
                    "asset_type": "æ•°å­—è´§å¸",
                    "asset_code": "BTC",
                    "asset_name": "æ¯”ç‰¹å¸",
                    "balance_cny": 1205.67,
                    "snapshot_time": "2024-01-15 09:00:00"
                }
            ]
        }
        
        # é¢„å®šä¹‰çš„ä¸šåŠ¡æŸ¥è¯¢æ¨¡æ¿
        self.query_templates = {
            "platform_distribution": {
                "sql": """
                    SELECT platform, SUM(COALESCE(balance_cny, 0)) as total_value, COUNT(*) as asset_count
                    FROM asset_snapshot 
                    WHERE snapshot_time = (SELECT MAX(snapshot_time) FROM asset_snapshot)
                    GROUP BY platform 
                    ORDER BY total_value DESC
                """,
                "chart_hint": "bar",
                "description": "å„å¹³å°èµ„äº§åˆ†å¸ƒå¯¹æ¯”"
            },
            "asset_type_distribution": {
                "sql": """
                    SELECT asset_type, SUM(COALESCE(balance_cny, 0)) as total_value, COUNT(*) as asset_count
                    FROM asset_snapshot 
                    WHERE snapshot_time = (SELECT MAX(snapshot_time) FROM asset_snapshot)
                    GROUP BY asset_type 
                    ORDER BY total_value DESC
                """,
                "chart_hint": "pie",
                "description": "å„èµ„äº§ç±»å‹åˆ†å¸ƒå¯¹æ¯”"
            },
            "monthly_trend": {
                "sql": """
                    SELECT TO_CHAR(snapshot_time, 'YYYY-MM-DD') as date, SUM(balance_cny) as total_value
                    FROM asset_snapshot 
                    WHERE snapshot_time >= CURRENT_DATE - INTERVAL '30 days'
                    GROUP BY TO_CHAR(snapshot_time, 'YYYY-MM-DD')
                    ORDER BY date ASC
                """,
                "chart_hint": "line",
                "description": "æœ€è¿‘30å¤©èµ„äº§å˜åŒ–è¶‹åŠ¿"
            },
            "top_assets": {
                "sql": """
                    SELECT asset_name, balance_cny as total_value, platform, asset_type
                    FROM asset_snapshot 
                    WHERE snapshot_time = (SELECT MAX(snapshot_time) FROM asset_snapshot)
                    ORDER BY balance_cny DESC 
                    LIMIT 10
                """,
                "chart_hint": "bar",
                "description": "å‰10å¤§èµ„äº§æ’å"
            }
        }
    
    async def execute_sql(self, sql: str, max_rows: int = 1000) -> Dict[str, Any]:
        """æ‰§è¡ŒSQLæŸ¥è¯¢"""
        start_time = datetime.now()
        
        try:
            # å°è¯•è¿æ¥æ•°æ®åº“æ‰§è¡ŒæŸ¥è¯¢
            data = await self._execute_database_query(sql, max_rows)
            
            if data is not None:
                execution_time = (datetime.now() - start_time).total_seconds()
                return {
                    "success": True,
                    "sql": sql,
                    "data": data,
                    "execution_time": execution_time,
                    "row_count": len(data),
                    "method": "database"
                }
        
        except Exception as e:
            logger.warning(f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®: {e}")
        
        # å¦‚æœæ•°æ®åº“æŸ¥è¯¢å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        try:
            mock_data = self._get_mock_data_for_sql(sql)
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return {
                "success": True,
                "sql": sql,
                "data": mock_data,
                "execution_time": execution_time,
                "row_count": len(mock_data),
                "method": "mock"
            }
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            logger.error(f"SQLæ‰§è¡Œå¼‚å¸¸: {e}")
            return {
                "success": False,
                "sql": sql,
                "error": str(e),
                "execution_time": execution_time,
                "method": "error"
            }
    
    async def natural_language_query(self, question: str, context: Dict[str, Any] = None, max_rows: int = 1000, ai_service: str = "auto") -> Dict[str, Any]:
        """è‡ªç„¶è¯­è¨€æŸ¥è¯¢å¤„ç†"""
        start_time = datetime.now()
        
        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        logger.info(f"ğŸ” å¼€å§‹è‡ªç„¶è¯­è¨€æŸ¥è¯¢: question='{question}', ai_service='{ai_service}'")
        logger.info(f"ğŸ” AIæœåŠ¡å®ä¾‹çŠ¶æ€: ai_service={self.ai_service}, type={type(self.ai_service)}")
        if self.ai_service:
            logger.info(f"ğŸ” AIæœåŠ¡APIå¯†é’¥çŠ¶æ€: api_key={'å·²è®¾ç½®' if self.ai_service.api_key else 'æœªè®¾ç½®'}")
        else:
            logger.error("âŒ AIæœåŠ¡å®ä¾‹ä¸ºNoneï¼")
        
        # è‡ªåŠ¨é€‰æ‹©AIæœåŠ¡
        if ai_service == "auto":
            # å¼ºåˆ¶ä½¿ç”¨DeepSeek AIï¼Œå› ä¸ºClaude API Keyæ— æ•ˆ
            ai_service = "deepseek"
            logger.info("ğŸ”§ å¼ºåˆ¶ä½¿ç”¨DeepSeek AIï¼Œå› ä¸ºClaude API Keyæ— æ•ˆ")
        
        logger.info(f"ğŸ” é€‰æ‹©çš„AIæœåŠ¡: {ai_service}")
        
        try:
            if ai_service == "claude":
                # ä½¿ç”¨Claude AIåˆ†æé—®é¢˜
                if not self.claude_ai or not hasattr(self.claude_ai, 'api_key') or not self.claude_ai.api_key:
                    logger.warning("Claude API Keyæœªé…ç½®ï¼Œå›é€€åˆ°DeepSeek")
                    ai_service = "deepseek"
                else:
                    logger.info(f"ä½¿ç”¨Claude AIåˆ†æé—®é¢˜: {question}")
                    
                    ai_analysis = await self.claude_ai.analyze_with_tools(question)
                    
                    if ai_analysis and ai_analysis.get('sql'):
                        # Claude AIæˆåŠŸç”ŸæˆSQLï¼Œç›´æ¥æ‰§è¡Œ
                        generated_sql = ai_analysis['sql']
                        logger.info(f"Claude AIç”Ÿæˆçš„SQL: {generated_sql}")
                        
                        # æ‰§è¡Œç”Ÿæˆçš„SQL
                        sql_result = await self.execute_sql(generated_sql, max_rows)
                        
                        # å¦‚æœSQLæ‰§è¡ŒæˆåŠŸï¼Œæ·»åŠ AIåˆ†æä¿¡æ¯
                        if sql_result.get('success'):
                            sql_result['ai_analysis'] = ai_analysis
                            sql_result['method'] = "claude_ai"
                            logger.info("âœ… Claude AIè°ƒç”¨æˆåŠŸï¼Œä½¿ç”¨AIç”Ÿæˆçš„SQL")
                        
                        return sql_result
                    else:
                        logger.warning(f"Claude AIæœªè¿”å›æœ‰æ•ˆSQL: {ai_analysis}")
            
            if ai_service == "deepseek":
                # ä½¿ç”¨DeepSeek AIåˆ†æé—®é¢˜
                logger.info(f"ä½¿ç”¨DeepSeek AIåˆ†æé—®é¢˜: {question}")
                
                # å†æ¬¡æ£€æŸ¥AIæœåŠ¡å®ä¾‹
                if not self.ai_service:
                    logger.error("âŒ DeepSeek AIæœåŠ¡å®ä¾‹ä¸ºNoneï¼Œæ— æ³•ç»§ç»­")
                    raise Exception("DeepSeek AIæœåŠ¡æœªåˆå§‹åŒ–")
                
                logger.info(f"ğŸ” è°ƒç”¨DeepSeek AIæœåŠ¡: {type(self.ai_service)}")
                ai_analysis = await self.ai_service.analyze_financial_question(question)
                
                if ai_analysis and ai_analysis.get('sql'):
                    # DeepSeek AIæˆåŠŸç”ŸæˆSQLï¼Œç›´æ¥æ‰§è¡Œ
                    generated_sql = ai_analysis['sql']
                    logger.info(f"DeepSeek AIç”Ÿæˆçš„SQL: {generated_sql}")
                    
                    # æ‰§è¡Œç”Ÿæˆçš„SQL
                    sql_result = await self.execute_sql(generated_sql, max_rows)
                    
                    # å¦‚æœSQLæ‰§è¡ŒæˆåŠŸï¼Œæ·»åŠ AIåˆ†æä¿¡æ¯
                    if sql_result.get('success'):
                        sql_result['ai_analysis'] = ai_analysis
                        sql_result['method'] = "deepseek_ai"
                        logger.info("âœ… DeepSeek AIè°ƒç”¨æˆåŠŸï¼Œä½¿ç”¨AIç”Ÿæˆçš„SQL")
                    
                    return sql_result
                else:
                    logger.warning(f"DeepSeek AIæœªè¿”å›æœ‰æ•ˆSQL: {ai_analysis}")
        
        except Exception as e:
            logger.error(f"AIåˆ†æå¤±è´¥: {e}")
            logger.error(f"AIåˆ†æå¤±è´¥è¯¦æƒ…: {str(e)}")
            import traceback
            logger.error(f"AIåˆ†æå¤±è´¥å †æ ˆ: {traceback.format_exc()}")
        
        # 2. å¦‚æœAIå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿åŒ¹é…
        try:
            template_result = self._match_query_template(question)
            if template_result:
                logger.info(f"ä½¿ç”¨æ¨¡æ¿åŒ¹é…: {template_result['description']}")
                return await self.execute_sql(template_result["sql"], max_rows)
        except Exception as e:
            logger.error(f"æ¨¡æ¿åŒ¹é…å¤±è´¥: {e}")
        
        # 3. æœ€åè¿”å›é€šç”¨æ¨¡æ‹Ÿæ•°æ®
        try:
            execution_time = (datetime.now() - start_time).total_seconds()
            return {
                "success": True,
                "sql": "SELECT * FROM asset_snapshot LIMIT 10",
                "data": self.mock_data["asset_snapshot"][:10],
                "execution_time": execution_time,
                "row_count": 10,
                "method": "fallback"
            }
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            return {
                "success": False,
                "error": str(e),
                "execution_time": execution_time,
                "method": "error"
            }
    
    async def get_database_schema(self, tables: List[str] = None) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“Schemaä¿¡æ¯"""
        try:
            if not tables:
                tables = ["asset_snapshot", "user_operations", "asset_positions"]
            
            # å°è¯•ä»æ•°æ®åº“è·å–Schema
            schema = await self._get_database_schema_info(tables)
            if schema:
                return schema
        
        except Exception as e:
            logger.warning(f"æ•°æ®åº“SchemaæŸ¥è¯¢å¤±è´¥: {e}")
        
        # è¿”å›é»˜è®¤Schema
        return {
            "tables": {
                "asset_snapshot": {
                    "description": "èµ„äº§å¿«ç…§è¡¨ - æ ¸å¿ƒåˆ†ææ•°æ®æº",
                    "columns": {
                        "platform": "å¹³å°åç§° (æ”¯ä»˜å®, Wise, IBKR, OKX)",
                        "asset_type": "èµ„äº§ç±»å‹ (åŸºé‡‘, å¤–æ±‡, è‚¡ç¥¨, æ•°å­—è´§å¸)",
                        "asset_code": "èµ„äº§ä»£ç ",
                        "balance_cny": "äººæ°‘å¸ä½™é¢ - ä¸»è¦åˆ†æå­—æ®µ",
                        "snapshot_time": "å¿«ç…§æ—¶é—´"
                    }
                },
                "user_operations": {
                    "description": "ç”¨æˆ·æ“ä½œè®°å½•è¡¨ - äº¤æ˜“å†å²åˆ†æ",
                    "columns": {
                        "operation_date": "æ“ä½œæ—¶é—´",
                        "platform": "æ“ä½œå¹³å°",
                        "operation_type": "æ“ä½œç±»å‹ (ä¹°å…¥, å–å‡º, è½¬è´¦)",
                        "amount": "æ“ä½œé‡‘é¢"
                    }
                }
            }
        }
    
    async def generate_chart_config(self, question: str, data: List[Dict[str, Any]], chart_type: str = "auto") -> Dict[str, Any]:
        """ç”Ÿæˆå›¾è¡¨é…ç½®"""
        try:
            if chart_type == "auto":
                chart_config = self.chart_generator.generate_config(data, question)
            else:
                # å¼ºåˆ¶æŒ‡å®šå›¾è¡¨ç±»å‹
                chart_config = self.chart_generator.generate_config(data, question)
                chart_config.chart_type = chart_type
            
            return {
                "success": True,
                "chart_config": chart_config.to_dict(),
                "question": question,
                "data_points": len(data)
            }
            
        except Exception as e:
            logger.error(f"å›¾è¡¨é…ç½®ç”Ÿæˆå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _execute_database_query(self, sql: str, max_rows: int) -> Optional[List[Dict[str, Any]]]:
        """æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
            if os.getenv('USE_MOCK_DATA', 'false').lower() == 'true':
                return None
            
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            
            # æ¸…ç†SQLè¯­å¥ï¼šç§»é™¤æœ«å°¾åˆ†å·ï¼Œç¡®ä¿è¯­æ³•æ­£ç¡®
            clean_sql = sql.strip().rstrip(';')
            
            # é™åˆ¶ç»“æœè¡Œæ•°
            if "LIMIT" not in clean_sql.upper():
                clean_sql = f"{clean_sql} LIMIT {max_rows}"
            
            cursor.execute(clean_sql)
            results = cursor.fetchall()
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            data = [dict(row) for row in results]
            
            cursor.close()
            conn.close()
            
            return data
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
            logger.error(f"æ•°æ®åº“é…ç½®: {self.db_config}")
            logger.error(f"åŸå§‹SQLè¯­å¥: {sql}")
            logger.error(f"æ¸…ç†åSQLè¯­å¥: {clean_sql if 'clean_sql' in locals() else 'N/A'}")
            return None
    
    async def _get_database_schema_info(self, tables: List[str]) -> Optional[Dict[str, Any]]:
        """è·å–æ•°æ®åº“Schemaä¿¡æ¯"""
        try:
            if os.getenv('USE_MOCK_DATA', 'false').lower() == 'true':
                return None
            
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor()
            
            schema_info = {}
            
            for table in tables:
                # è·å–è¡¨ç»“æ„
                cursor.execute("""
                    SELECT column_name, data_type, is_nullable, column_default
                    FROM information_schema.columns 
                    WHERE table_name = %s 
                    ORDER BY ordinal_position
                """, (table,))
                
                columns = cursor.fetchall()
                schema_info[table] = {
                    "columns": {col[0]: {"type": col[1], "nullable": col[2], "default": col[3]} for col in columns}
                }
            
            cursor.close()
            conn.close()
            
            return {"tables": schema_info}
            
        except Exception as e:
            logger.error(f"è·å–æ•°æ®åº“Schemaå¤±è´¥: {e}")
            return None
    
    def _match_query_template(self, question: str) -> Optional[Dict[str, Any]]:
        """åŒ¹é…æŸ¥è¯¢æ¨¡æ¿"""
        question_lower = question.lower()
        
        # å¹³å°åˆ†å¸ƒå…³é”®è¯
        if any(word in question_lower for word in ['å¹³å°', 'åˆ†å¸ƒ', 'platform']):
            return self.query_templates["platform_distribution"]
        
        # èµ„äº§ç±»å‹å…³é”®è¯
        if any(word in question_lower for word in ['ç±»å‹', 'ç§ç±»', 'å æ¯”', 'æ¯”ä¾‹']):
            return self.query_templates["asset_type_distribution"]
        
        # è¶‹åŠ¿å…³é”®è¯
        if any(word in question_lower for word in ['è¶‹åŠ¿', 'å˜åŒ–', 'èµ°åŠ¿', 'trend']):
            return self.query_templates["monthly_trend"]
        
        # æ’åå…³é”®è¯
        if any(word in question_lower for word in ['æ’å', 'æ’è¡Œ', 'æœ€å¤š', 'æœ€å°‘', 'top']):
            return self.query_templates["top_assets"]
        
        return None
    
    def _get_mock_data_for_sql(self, sql: str) -> List[Dict[str, Any]]:
        """æ ¹æ®SQLè·å–ç›¸åº”çš„æ¨¡æ‹Ÿæ•°æ®"""
        sql_lower = sql.lower()
        
        # æ›´æ™ºèƒ½çš„SQLåˆ†æ
        logger.info(f"åˆ†æSQLç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®: {sql}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ”¯ä»˜å®å†…éƒ¨çš„æŸ¥è¯¢
        if "platform = 'æ”¯ä»˜å®'" in sql or "platform='æ”¯ä»˜å®'" in sql:
            if "asset_type" in sql_lower:
                # æ”¯ä»˜å®å†…éƒ¨èµ„äº§ç±»å‹åˆ†å¸ƒ
                logger.info("è¿”å›æ”¯ä»˜å®å†…éƒ¨èµ„äº§ç±»å‹åˆ†å¸ƒæ•°æ®")
                return [
                    {"asset_type": "åŸºé‡‘", "total_balance": 158460.30, "asset_count": 2},
                    {"asset_type": "è‚¡ç¥¨", "total_balance": 50000.00, "asset_count": 1},
                    {"asset_type": "å€ºåˆ¸", "total_balance": 25000.00, "asset_count": 1},
                    {"asset_type": "ç°é‡‘", "total_balance": 15000.00, "asset_count": 1}
                ]
            elif "date" in sql_lower or "snapshot_time" in sql_lower:
                # æ”¯ä»˜å®èµ„äº§å˜åŒ–è¶‹åŠ¿
                logger.info("è¿”å›æ”¯ä»˜å®èµ„äº§å˜åŒ–è¶‹åŠ¿æ•°æ®")
                return [
                    {"date": "2024-01-01", "daily_total": 150000.00},
                    {"date": "2024-01-02", "daily_total": 151000.00},
                    {"date": "2024-01-03", "daily_total": 152500.00},
                    {"date": "2024-01-04", "daily_total": 154000.00},
                    {"date": "2024-01-05", "daily_total": 155500.00}
                ]
            else:
                # æ”¯ä»˜å®æ€»ä½“æ•°æ®
                logger.info("è¿”å›æ”¯ä»˜å®æ€»ä½“æ•°æ®")
                return [
                    {"platform": "æ”¯ä»˜å®", "total_value": 158460.30, "asset_count": 5}
                ]
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¹³å°åˆ†å¸ƒæŸ¥è¯¢
        elif "platform" in sql_lower and "group by platform" in sql_lower:
            logger.info("è¿”å›å„å¹³å°èµ„äº§åˆ†å¸ƒæ•°æ®")
            return [
                {"platform": "æ”¯ä»˜å®", "total_value": 158460.30, "asset_count": 2},
                {"platform": "Wise", "total_value": 8158.23, "asset_count": 2},
                {"platform": "IBKR", "total_value": 42.03, "asset_count": 1},
                {"platform": "OKX", "total_value": 1205.67, "asset_count": 1}
            ]
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯èµ„äº§ç±»å‹åˆ†å¸ƒæŸ¥è¯¢
        elif "asset_type" in sql_lower and "group by asset_type" in sql_lower:
            logger.info("è¿”å›å„èµ„äº§ç±»å‹åˆ†å¸ƒæ•°æ®")
            return [
                {"asset_type": "åŸºé‡‘", "total_value": 158460.30, "asset_count": 2},
                {"asset_type": "å¤–æ±‡", "total_value": 8158.23, "asset_count": 2},
                {"asset_type": "è‚¡ç¥¨", "total_value": 42.03, "asset_count": 1},
                {"asset_type": "æ•°å­—è´§å¸", "total_value": 1205.67, "asset_count": 1}
            ]
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ—¶é—´è¶‹åŠ¿æŸ¥è¯¢
        elif any(word in sql_lower for word in ["date_trunc", "to_char", "snapshot_time"]) and "group by" in sql_lower:
            logger.info("è¿”å›æ—¶é—´è¶‹åŠ¿æ•°æ®")
            return [
                {"date": "2024-01-01", "total_value": 150000.00},
                {"date": "2024-01-02", "total_value": 151000.00},
                {"date": "2024-01-03", "total_value": 152500.00},
                {"date": "2024-01-04", "total_value": 154000.00},
                {"date": "2024-01-05", "total_value": 155500.00}
            ]
        
        # é»˜è®¤è¿”å›åŸå§‹æ•°æ®
        else:
            logger.info("è¿”å›é»˜è®¤æ¨¡æ‹Ÿæ•°æ®")
            return self.mock_data["asset_snapshot"]
    
    def get_available_ai_services(self) -> Dict[str, Any]:
        """è·å–å¯ç”¨çš„AIæœåŠ¡ä¿¡æ¯"""
        services = {
            "deepseek": {
                "available": bool(self.ai_service.api_key),
                "model": getattr(self.ai_service, 'model', 'unknown'),
                "description": "DeepSeek AIæœåŠ¡"
            }
        }
        
        # åªæœ‰åœ¨ClaudeæœåŠ¡åˆå§‹åŒ–æ—¶æ‰æ·»åŠ 
        if self.claude_ai:
            services["claude"] = {
                "available": bool(self.claude_ai.api_key),
                "model": getattr(self.claude_ai, 'model', 'unknown'),
                "description": "Claude AIæœåŠ¡ï¼ˆæ”¯æŒMCPå·¥å…·è°ƒç”¨ï¼‰"
            }
        
        return services
