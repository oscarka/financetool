#!/usr/bin/env python3
"""
å¯åŠ¨è„šæœ¬
"""
import sys
import os
from pathlib import Path
import subprocess
import logging
from sqlalchemy import create_engine, inspect, text
from app.settings import settings
import time

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def check_database_compatibility(conn):
    """æ£€æŸ¥æ•°æ®åº“å…¼å®¹æ€§"""
    print("ğŸ” å¼€å§‹æ•°æ®åº“å…¼å®¹æ€§æ£€æŸ¥...")
    issues = []
    
    # å®šä¹‰å¿…éœ€çš„è¡¨å’Œå­—æ®µï¼ˆåŸºäºå®é™…æ¨¡å‹ï¼‰
    required_tables = {
        'user_operations': ['id', 'operation_date', 'platform', 'asset_type', 'operation_type', 'asset_code', 'asset_name', 'amount', 'currency', 'created_at'],
        'asset_positions': ['id', 'platform', 'asset_type', 'asset_code', 'asset_name', 'currency', 'quantity', 'current_price', 'current_value', 'last_updated'],
        'fund_info': ['id', 'fund_code', 'fund_name', 'fund_type', 'created_at'],
        'fund_nav': ['id', 'fund_code', 'nav_date', 'nav', 'created_at'],
        'fund_dividend': ['id', 'fund_code', 'dividend_date', 'dividend_amount', 'created_at'],
        'dca_plans': ['id', 'plan_name', 'platform', 'asset_type', 'asset_code', 'asset_name', 'amount', 'currency', 'frequency', 'smart_dca', 'skip_holidays', 'enable_notification', 'created_at'],
        'exchange_rates': ['id', 'from_currency', 'to_currency', 'rate', 'rate_date', 'created_at'],
        'system_config': ['id', 'config_key', 'config_value', 'updated_at'],
        'wise_transactions': ['id', 'transaction_id', 'amount', 'currency', 'status', 'created_at'],
        'wise_balances': ['id', 'account_id', 'currency', 'available_balance', 'created_at'],
        'wise_exchange_rates': ['id', 'source_currency', 'target_currency', 'rate', 'created_at'],
        'ibkr_accounts': ['id', 'account_id', 'account_name', 'created_at'],
        'ibkr_balances': ['id', 'account_id', 'currency', 'total_cash', 'created_at'],
        'ibkr_positions': ['id', 'account_id', 'symbol', 'quantity', 'created_at'],
        'ibkr_sync_logs': ['id', 'sync_type', 'status', 'created_at'],
        'okx_balances': ['id', 'account_id', 'currency', 'available_balance', 'created_at'],
        'okx_transactions': ['id', 'transaction_id', 'account_id', 'inst_type', 'inst_id', 'trade_id', 'order_id', 'bill_id', 'type', 'side', 'amount', 'currency', 'fee', 'fee_currency', 'price', 'quantity', 'timestamp', 'created_at', 'bal', 'bal_chg', 'ccy', 'cl_ord_id', 'exec_type', 'fill_fwd_px', 'fill_idx_px', 'fill_mark_px', 'fill_mark_vol', 'fill_px_usd', 'fill_px_vol', 'fill_time', 'from_addr', 'interest', 'mgn_mode', 'notes', 'pnl', 'pos_bal', 'pos_bal_chg', 'sub_type', 'tag', 'to_addr'],
        'okx_positions': ['id', 'account_id', 'inst_id', 'quantity', 'created_at'],
        'okx_market_data': ['id', 'inst_id', 'last_price', 'timestamp', 'created_at'],
        'okx_account_overview': ['id', 'total_assets_usd', 'created_at'],
        'web3_balances': ['id', 'project_id', 'account_id', 'total_value', 'created_at'],
        'web3_tokens': ['id', 'project_id', 'account_id', 'token_address', 'token_name', 'token_symbol', 'created_at'],
        'web3_transactions': ['id', 'project_id', 'account_id', 'transaction_hash', 'from_address', 'to_address', 'amount', 'created_at'],
        'asset_snapshot': ['id', 'user_id', 'platform', 'asset_type', 'asset_code', 'asset_name', 'currency', 'balance', 'base_value', 'snapshot_time', 'created_at'],
        'exchange_rate_snapshot': ['id', 'from_currency', 'to_currency', 'rate', 'snapshot_time', 'created_at']
    }
    
    # æ£€æŸ¥è¡¨ç»“æ„
    for table_name, required_fields in required_tables.items():
        print(f"ğŸ“Š æ£€æŸ¥è¡¨: {table_name}")
        
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        result = conn.execute(text(f"""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = '{table_name}'
            )
        """))
        table_exists = result.scalar()
        
        if not table_exists:
            issues.append(f"âŒ è¡¨ {table_name} ä¸å­˜åœ¨")
            continue
        
        # æ£€æŸ¥å­—æ®µ
        result = conn.execute(text(f"""
            SELECT column_name, data_type, is_nullable
            FROM information_schema.columns 
            WHERE table_schema = 'public' AND table_name = '{table_name}'
        """))
        existing_fields = {row[0]: {'type': row[1], 'nullable': row[2]} for row in result}
        
        for field in required_fields:
            if field not in existing_fields:
                issues.append(f"âŒ è¡¨ {table_name} ç¼ºå°‘å­—æ®µ: {field}")
        
        # æ£€æŸ¥ç´¢å¼•
        result = conn.execute(text(f"""
            SELECT indexname, indexdef
            FROM pg_indexes 
            WHERE tablename = '{table_name}'
        """))
        existing_indexes = [row[0] for row in result]
        
        # æ£€æŸ¥ä¸»é”®ç´¢å¼•
        if f"{table_name}_pkey" not in existing_indexes:
            issues.append(f"âŒ è¡¨ {table_name} ç¼ºå°‘ä¸»é”®ç´¢å¼•")
    
    # æ£€æŸ¥ alembic_version è¡¨
    result = conn.execute(text("""
        SELECT EXISTS (
            SELECT FROM information_schema.tables 
            WHERE table_schema = 'public' AND table_name = 'alembic_version'
        )
    """))
    alembic_version_exists = result.scalar()
    
    if not alembic_version_exists:
        issues.append("âŒ alembic_version è¡¨ä¸å­˜åœ¨")
    else:
        # æ£€æŸ¥å½“å‰ç‰ˆæœ¬
        result = conn.execute(text("SELECT version_num FROM alembic_version"))
        current_version = result.scalar()
        print(f"ğŸ“‹ å½“å‰ Alembic ç‰ˆæœ¬: {current_version}")
    
    if issues:
        print("âŒ æ£€æµ‹åˆ°æ•°æ®åº“ä¸ä¸€è‡´:")
        for issue in issues:
            print(f"  {issue}")
        return False
    else:
        print("âœ… æ•°æ®åº“å…¼å®¹æ€§æ£€æŸ¥é€šè¿‡")
        return True

def rollback_database_changes(conn):
    """å›é€€æ•°æ®åº“ä¿®æ”¹"""
    print("ğŸ”„ å¼€å§‹å›é€€æ•°æ®åº“ä¿®æ”¹...")
    
    try:
        # 1. æ¢å¤ alembic ç‰ˆæœ¬å·åˆ°åŸºç¡€ç‰ˆæœ¬
        print("ğŸ“‹ æ¢å¤ Alembic ç‰ˆæœ¬å·...")
        try:
            # å°è¯•æ¢å¤åˆ°åŸºç¡€ç‰ˆæœ¬
            subprocess.run(["alembic", "stamp", "base"], check=True)
            print("âœ… Alembic ç‰ˆæœ¬å·å·²æ¢å¤åˆ°åŸºç¡€ç‰ˆæœ¬")
        except Exception as e:
            print(f"âš ï¸  æ¢å¤ç‰ˆæœ¬å·å¤±è´¥: {e}")
            print("â„¹ï¸  ç»§ç»­æ‰§è¡Œå…¶ä»–å›é€€æ“ä½œ")
        
        # 2. åˆ é™¤æ–°åˆ›å»ºçš„è¡¨ï¼ˆå¦‚æœæœ‰ï¼‰
        print("ğŸ—‘ï¸  åˆ é™¤æ–°åˆ›å»ºçš„è¡¨...")
        new_tables = [
            'asset_snapshot', 'exchange_rate_snapshot', 'okx_account_overview',
            'web3_balances', 'web3_tokens', 'web3_transactions'
        ]
        
        for table in new_tables:
            try:
                conn.execute(text(f"DROP TABLE IF EXISTS {table} CASCADE"))
                print(f"  âœ… åˆ é™¤è¡¨ {table}")
            except Exception as e:
                print(f"  âš ï¸  åˆ é™¤è¡¨ {table} æ—¶å‡ºé”™: {e}")
        
        conn.commit()
        print("âœ… æ–°è¡¨åˆ é™¤å®Œæˆ")
        
        # 3. æ£€æŸ¥å¹¶æ¢å¤è¢«ä¿®æ”¹çš„è¡¨ç»“æ„
        print("ğŸ”§ æ£€æŸ¥è¡¨ç»“æ„...")
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´è¯¦ç»†çš„è¡¨ç»“æ„æ¢å¤é€»è¾‘
        print("âœ… è¡¨ç»“æ„æ£€æŸ¥å®Œæˆ")
        
        print("âœ… æ•°æ®åº“å›é€€å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ å›é€€å¤±è´¥: {e}")
        print("âš ï¸  éœ€è¦æ‰‹åŠ¨å¹²é¢„")
        return False

def safe_railway_migration():
    """å®‰å…¨çš„Railwayè¿ç§»"""
    database_url = os.getenv("DATABASE_URL")
    if not database_url or not database_url.startswith("postgresql://"):
        print("âš ï¸  æœªé…ç½®PostgreSQLæ•°æ®åº“ï¼Œè·³è¿‡Railwayè¿ç§»")
        return True
    
    print("ğŸš€ å¼€å§‹å®‰å…¨çš„Railwayæ•°æ®åº“è¿ç§»...")
    
    try:
        from sqlalchemy import create_engine
        
        # åˆ›å»ºæ•°æ®åº“å¼•æ“
        engine = create_engine(database_url, echo=False)
        
        with engine.connect() as conn:
            # 1. é¢„æ£€æŸ¥
            print("ğŸ” æ‰§è¡Œé¢„æ£€æŸ¥...")
            if not check_database_compatibility(conn):
                print("âŒ é¢„æ£€æŸ¥å¤±è´¥ï¼Œå¼€å§‹å›é€€...")
                if rollback_database_changes(conn):
                    print("âœ… å›é€€æˆåŠŸï¼Œè¿ç§»ç»ˆæ­¢")
                    return False
                else:
                    print("âŒ å›é€€å¤±è´¥ï¼Œéœ€è¦æ‰‹åŠ¨å¹²é¢„")
                    return False
            
            # 2. æ£€æŸ¥ç°æœ‰æ•°æ®
            print("ğŸ“Š æ£€æŸ¥ç°æœ‰æ•°æ®...")
            data_exists = False
            for table in ['user_operations', 'asset_positions', 'wise_transactions']:
                try:
                    result = conn.execute(text(f"SELECT COUNT(*) FROM {table}"))
                    count = result.scalar()
                    if count > 0:
                        print(f"ğŸ“ˆ {table} è¡¨æœ‰ {count} æ¡æ•°æ®")
                        data_exists = True
                except Exception as e:
                    print(f"âš ï¸  æ£€æŸ¥ {table} è¡¨æ•°æ®æ—¶å‡ºé”™: {e}")
            
            # 3. æ‰§è¡Œè¿ç§»
            print("ğŸ”„ æ‰§è¡Œè¿ç§»...")
            try:
                result = subprocess.run(["alembic", "upgrade", "head"], capture_output=True, text=True)
                if result.returncode != 0:
                    print(f"âŒ è¿ç§»å¤±è´¥: {result.stderr}")
                    print("ğŸ”„ å¼€å§‹å›é€€...")
                    if rollback_database_changes(conn):
                        print("âœ… å›é€€æˆåŠŸ")
                        return False
                    else:
                        print("âŒ å›é€€å¤±è´¥")
                        return False
                else:
                    print("âœ… è¿ç§»æ‰§è¡ŒæˆåŠŸ")
                    print("ğŸ“ è¿ç§»è¾“å‡º:")
                    print(result.stdout)
            except Exception as e:
                print(f"âŒ æ‰§è¡Œè¿ç§»å‘½ä»¤å¤±è´¥: {e}")
                print("ğŸ”„ å¼€å§‹å›é€€...")
                if rollback_database_changes(conn):
                    print("âœ… å›é€€æˆåŠŸ")
                    return False
                else:
                    print("âŒ å›é€€å¤±è´¥")
                    return False
            
            # 4. è¿ç§»åéªŒè¯
            print("ğŸ” æ‰§è¡Œè¿ç§»åéªŒè¯...")
            if not check_database_compatibility(conn):
                print("âŒ è¿ç§»åéªŒè¯å¤±è´¥ï¼Œå¼€å§‹å›é€€...")
                if rollback_database_changes(conn):
                    print("âœ… å›é€€æˆåŠŸ")
                    return False
                else:
                    print("âŒ å›é€€å¤±è´¥")
                    return False
            
            print("âœ… è¿ç§»éªŒè¯é€šè¿‡")
            return True
            
    except Exception as e:
        print(f"âŒ è¿ç§»è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        print("ğŸ”„ å¼€å§‹å›é€€...")
        try:
            with engine.connect() as conn:
                if rollback_database_changes(conn):
                    print("âœ… å›é€€æˆåŠŸ")
                    return False
                else:
                    print("âŒ å›é€€å¤±è´¥")
                    return False
        except Exception as rollback_error:
            print(f"âŒ å›é€€è¿‡ç¨‹ä¸­å‡ºé”™: {rollback_error}")
            return False

# ç§»é™¤wise_balanceså”¯ä¸€çº¦æŸæ£€æµ‹ç›¸å…³ä¸´æ—¶ä»£ç 

def check_railway_environment():
    """æ£€æŸ¥Railwayç¯å¢ƒé…ç½®"""
    is_railway = os.getenv("RAILWAY_ENVIRONMENT") is not None
    data_path = os.getenv("DATABASE_PERSISTENT_PATH", "/app/data")
    
    print(f"ğŸš€ å¯åŠ¨ä¸ªäººè´¢åŠ¡ç®¡ç†ç³»ç»Ÿ")
    print(f"ğŸ“ è¿è¡Œç¯å¢ƒ: {'Railway' if is_railway else 'æœ¬åœ°/å…¶ä»–'}")
    print(f"ğŸ“ æ•°æ®ç›®å½•: {data_path}")
    
    # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
    Path(data_path).mkdir(parents=True, exist_ok=True)
    print(f"âœ… æ•°æ®ç›®å½•å·²ç¡®ä¿å­˜åœ¨")
    
    # åœ¨Railwayç¯å¢ƒä¸­ä¿®å¤volumeæƒé™
    if is_railway:
        try:
            import pwd
            
            # è·å–å½“å‰ç”¨æˆ·ID
            current_uid = os.getuid()
            current_gid = os.getgid()
            
            print(f"ğŸ”§ ä¿®å¤volumeæƒé™...")
            print(f"   å½“å‰ç”¨æˆ·ID: {current_uid}")
            print(f"   å½“å‰ç»„ID: {current_gid}")
            
            # ä¿®å¤æ•°æ®ç›®å½•æƒé™
            subprocess.run(["chown", "-R", f"{current_uid}:{current_gid}", data_path], check=True)
            subprocess.run(["chmod", "-R", "755", data_path], check=True)
            print(f"âœ… æ•°æ®ç›®å½•æƒé™å·²ä¿®å¤")
            
            # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æƒé™
            db_file = os.path.join(data_path, "personalfinance.db")
            if os.path.exists(db_file):
                subprocess.run(["chown", f"{current_uid}:{current_gid}", db_file], check=True)
                subprocess.run(["chmod", "644", db_file], check=True)
                print(f"âœ… æ•°æ®åº“æ–‡ä»¶æƒé™å·²ä¿®å¤")
                
        except Exception as e:
            print(f"âš ï¸  æƒé™ä¿®å¤å¤±è´¥: {e}")
            print(f"   ç»§ç»­å¯åŠ¨ï¼Œä½†å¯èƒ½é‡åˆ°æƒé™é—®é¢˜")
    
    # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶
    db_file = os.path.join(data_path, "personalfinance.db")
    if os.path.exists(db_file):
        size_mb = os.path.getsize(db_file) / (1024 * 1024)
        print(f"ğŸ“Š æ•°æ®åº“æ–‡ä»¶: {db_file} (å¤§å°: {size_mb:.2f}MB)")
    else:
        print(f"ğŸ“Š æ•°æ®åº“æ–‡ä»¶: {db_file} (ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶)")
    
    # åœ¨Railwayç¯å¢ƒä¸­è®¾ç½®PostgreSQLæ•°æ®åº“
    if is_railway:
        setup_postgresql_database(data_path)

def setup_postgresql_database(data_path):
    """è®¾ç½®PostgreSQLæ•°æ®åº“"""
    database_url = os.getenv("DATABASE_URL")
    if not database_url or not database_url.startswith("postgresql://"):
        print("âš ï¸  æœªé…ç½®PostgreSQLæ•°æ®åº“ï¼Œè·³è¿‡è®¾ç½®")
        return
    
    print("ğŸ—„ï¸  è®¾ç½®PostgreSQLæ•°æ®åº“...")
    
    try:
        from sqlalchemy import create_engine, text
        from app.models.database import Base
        
        # åˆ›å»ºæ•°æ®åº“å¼•æ“
        engine = create_engine(database_url, echo=False)
        
        with engine.connect() as conn:
            # æ£€æŸ¥ç°æœ‰è¡¨
            result = conn.execute(text("""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public'
            """))
            existing_tables = [row[0] for row in result]
            
            if existing_tables:
                print(f"âš ï¸  å‘ç°ç°æœ‰è¡¨: {existing_tables}")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†è¡¨ï¼ˆåªåœ¨ç‰¹å®šæ¡ä»¶ä¸‹ï¼‰
                should_clean_tables = os.getenv("CLEAN_DATABASE", "false").lower() == "true"
                
                if should_clean_tables:
                    print("ğŸ—‘ï¸  æ¸…ç†ç°æœ‰è¡¨ç»“æ„...")
                    
                    # åˆ é™¤æ‰€æœ‰ç°æœ‰è¡¨
                    for table in reversed(existing_tables):
                        try:
                            conn.execute(text(f"DROP TABLE IF EXISTS {table} CASCADE"))
                        except Exception as e:
                            print(f"âš ï¸  åˆ é™¤è¡¨ {table} æ—¶å‡ºé”™: {e}")
                    
                    conn.commit()
                    print("âœ… ç°æœ‰è¡¨å·²æ¸…ç†")
                    
                    # åˆ›å»ºæ–°è¡¨ç»“æ„
                    print("ğŸ—ï¸  åˆ›å»ºPostgreSQLè¡¨ç»“æ„...")
                    Base.metadata.create_all(bind=engine)
                    print("âœ… PostgreSQLè¡¨ç»“æ„åˆ›å»ºæˆåŠŸ")
                else:
                    print("â„¹ï¸  ä¿ç•™ç°æœ‰è¡¨ç»“æ„ï¼Œè·³è¿‡æ¸…ç†")
                    
                    # åªåˆ›å»ºç¼ºå¤±çš„è¡¨
                    print("ğŸ—ï¸  æ£€æŸ¥å¹¶åˆ›å»ºç¼ºå¤±çš„è¡¨...")
                    Base.metadata.create_all(bind=engine)
                    print("âœ… è¡¨ç»“æ„æ£€æŸ¥å®Œæˆ")
            else:
                # æ²¡æœ‰ç°æœ‰è¡¨ï¼Œåˆ›å»ºæ‰€æœ‰è¡¨
                print("ğŸ—ï¸  åˆ›å»ºPostgreSQLè¡¨ç»“æ„...")
                Base.metadata.create_all(bind=engine)
                print("âœ… PostgreSQLè¡¨ç»“æ„åˆ›å»ºæˆåŠŸ")
            
            # æ£€æŸ¥SQLiteæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™è¿ç§»æ•°æ®
            sqlite_file = os.path.join(data_path, "personalfinance.db")
            if os.path.exists(sqlite_file):

                # æ£€æŸ¥PostgreSQLæ˜¯å¦å·²æœ‰æ•°æ®
                result = conn.execute(text("SELECT COUNT(*) FROM user_operations"))
                pg_data_count = result.scalar()
                
                if pg_data_count == 0:
                    print("ğŸ“¦ å‘ç°SQLiteæ•°æ®æ–‡ä»¶ï¼ŒPostgreSQLä¸ºç©ºï¼Œå¼€å§‹è¿ç§»...")
                    migrate_sqlite_to_postgresql(sqlite_file, engine)
                else:
                    print(f"â„¹ï¸  PostgreSQLå·²æœ‰ {pg_data_count} æ¡æ•°æ®ï¼Œè·³è¿‡SQLiteè¿ç§»")
            else:
                print("â„¹ï¸  æœªå‘ç°SQLiteæ•°æ®æ–‡ä»¶ï¼Œè·³è¿‡æ•°æ®è¿ç§»")
            
            # æ•°æ®åº“è¯Šæ–­æŸ¥è¯¢å°†åœ¨åº”ç”¨å¯åŠ¨å®Œæˆåæ‰§è¡Œ
            print("â„¹ï¸  æ•°æ®åº“è¯Šæ–­æŸ¥è¯¢å°†åœ¨åº”ç”¨å¯åŠ¨å®Œæˆåæ‰§è¡Œ")

        
    except Exception as e:
        print(f"âŒ PostgreSQLè®¾ç½®å¤±è´¥: {e}")
        print("âš ï¸  ç»§ç»­å¯åŠ¨ï¼Œä½†å¯èƒ½æ— æ³•ä½¿ç”¨æ•°æ®åº“åŠŸèƒ½")

def handle_railway_database_migration():
    """å¤„ç†Railwayçº¿ä¸Šæ•°æ®åº“è¿ç§»"""
    database_url = os.getenv("DATABASE_URL")
    if not database_url or not database_url.startswith("postgresql://"):
        print("âš ï¸  æœªé…ç½®PostgreSQLæ•°æ®åº“ï¼Œè·³è¿‡Railwayè¿ç§»")
        return
    
    print("ğŸš€ å¤„ç†Railwayçº¿ä¸Šæ•°æ®åº“è¿ç§»...")
    
    try:
        from sqlalchemy import create_engine, text
        
        # åˆ›å»ºæ•°æ®åº“å¼•æ“
        engine = create_engine(database_url, echo=False)
        
        with engine.connect() as conn:
            # æ£€æŸ¥ç°æœ‰è¡¨
            result = conn.execute(text("""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public'
            """))
            existing_tables = [row[0] for row in result]
            
            print(f"ğŸ“Š å‘ç°ç°æœ‰è¡¨: {existing_tables}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
            data_exists = False
            if existing_tables:
                for table in ['user_operations', 'asset_positions', 'wise_transactions']:
                    if table in existing_tables:
                        try:
                            result = conn.execute(text(f"SELECT COUNT(*) FROM {table}"))
                            count = result.scalar()
                            if count > 0:
                                print(f"ğŸ“ˆ {table} è¡¨æœ‰ {count} æ¡æ•°æ®")
                                data_exists = True
                        except Exception as e:
                            print(f"âš ï¸  æ£€æŸ¥ {table} è¡¨æ•°æ®æ—¶å‡ºé”™: {e}")
            
            if data_exists:
                print("ğŸ”„ æ£€æµ‹åˆ°çº¿ä¸Šæ•°æ®ï¼Œæ‰§è¡Œå®‰å…¨è¿ç§»ç­–ç•¥...")
                
                # å®‰å…¨ç­–ç•¥ï¼šåªåˆ›å»ºç¼ºå¤±çš„è¡¨ï¼Œä¸åˆ é™¤ç°æœ‰è¡¨
                safe_migrate_with_data(conn, existing_tables)
                
                print("âœ… Railwayæ•°æ®åº“å®‰å…¨è¿ç§»å®Œæˆ")
            else:
                print("â„¹ï¸  çº¿ä¸Šæ•°æ®åº“æ— æ•°æ®ï¼Œæ‰§è¡Œå®Œæ•´è¿ç§»")
                execute_full_migration(conn, existing_tables)
                
    except Exception as e:
        print(f"âŒ Railwayæ•°æ®åº“è¿ç§»å¤±è´¥: {e}")
        print("âš ï¸  ç»§ç»­å¯åŠ¨ï¼Œä½†å¯èƒ½æ— æ³•ä½¿ç”¨æ•°æ®åº“åŠŸèƒ½")

def safe_migrate_with_data(conn, existing_tables):
    """å®‰å…¨è¿ç§»ï¼šä¿ç•™ç°æœ‰æ•°æ®ï¼Œåªåˆ›å»ºç¼ºå¤±çš„è¡¨"""
    print("ğŸ›¡ï¸  æ‰§è¡Œå®‰å…¨è¿ç§»ç­–ç•¥...")
    print("ğŸ“Š æ£€æµ‹åˆ°ç°æœ‰æ•°æ®ï¼Œå°†ä¿ç•™æ•°æ®å¹¶åªåˆ›å»ºç¼ºå¤±çš„è¡¨")
    
    # æ£€æŸ¥æ–°è¿ç§»éœ€è¦çš„è¡¨
    required_tables = [
        'user_operations', 'asset_positions', 'fund_info', 'fund_nav', 'fund_dividend',
        'dca_plans', 'exchange_rates', 'system_config', 'wise_transactions', 
        'wise_balances', 'wise_exchange_rates', 'ibkr_accounts', 'ibkr_balances',
        'ibkr_positions', 'ibkr_sync_logs', 'okx_balances', 'okx_transactions',
        'okx_positions', 'okx_market_data', 'okx_account_overview', 'web3_balances',
        'web3_tokens', 'web3_transactions', 'asset_snapshot', 'exchange_rate_snapshot'
    ]
    
    missing_tables = [table for table in required_tables if table not in existing_tables]
    
    if missing_tables:
        print(f"ğŸ“‹ éœ€è¦åˆ›å»ºçš„è¡¨: {missing_tables}")
        print("âš ï¸  æ³¨æ„ï¼šå°†ä¿ç•™ç°æœ‰æ•°æ®ï¼Œåªåˆ›å»ºç¼ºå¤±çš„è¡¨")
        
        # æ‰§è¡Œè¿ç§»åˆ›å»ºç¼ºå¤±çš„è¡¨
        try:
            import subprocess
            print("ğŸ”„ æ‰§è¡Œ alembic upgrade head...")
            result = subprocess.run(["alembic", "upgrade", "head"], capture_output=True, text=True)
            if result.returncode == 0:
                print("âœ… ç¼ºå¤±è¡¨åˆ›å»ºæˆåŠŸ")
                print("ğŸ“ è¿ç§»è¾“å‡º:")
                print(result.stdout)
            else:
                print(f"âŒ è¡¨åˆ›å»ºå¤±è´¥: {result.stderr}")
        except Exception as e:
            print(f"âŒ æ‰§è¡Œè¿ç§»å¤±è´¥: {e}")
    else:
        print("âœ… æ‰€æœ‰å¿…éœ€è¡¨éƒ½å·²å­˜åœ¨")
        print("â„¹ï¸  æ— éœ€åˆ›å»ºæ–°è¡¨ï¼Œç°æœ‰æ•°æ®ç»“æ„å®Œæ•´")
    
    # æ£€æŸ¥å¹¶ä¿®å¤è¡¨ç»“æ„å·®å¼‚
    check_and_fix_table_structure(conn, existing_tables)

def execute_full_migration(conn, existing_tables):
    """æ‰§è¡Œå®Œæ•´è¿ç§»ï¼šåˆ é™¤æ—§è¡¨ï¼Œåˆ›å»ºæ–°è¡¨"""
    print("ğŸ—ï¸  æ‰§è¡Œå®Œæ•´è¿ç§»...")
    
    # åˆ é™¤ç°æœ‰è¡¨ï¼ˆé™¤äº†alembic_versionï¼‰
    for table in existing_tables:
        if table != 'alembic_version':
            try:
                conn.execute(text(f"DROP TABLE IF EXISTS {table} CASCADE"))
                print(f"ğŸ—‘ï¸  åˆ é™¤è¡¨ {table}")
            except Exception as e:
                print(f"âš ï¸  åˆ é™¤è¡¨ {table} æ—¶å‡ºé”™: {e}")
    
    conn.commit()
    
    # æ‰§è¡Œæ–°çš„è¿ç§»
    try:
        import subprocess
        result = subprocess.run(["alembic", "upgrade", "head"], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… æ–°è¡¨ç»“æ„åˆ›å»ºæˆåŠŸ")
        else:
            print(f"âŒ è¡¨ç»“æ„åˆ›å»ºå¤±è´¥: {result.stderr}")
    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿ç§»å¤±è´¥: {e}")

def check_and_fix_table_structure(conn, existing_tables):
    """æ£€æŸ¥å¹¶ä¿®å¤è¡¨ç»“æ„å·®å¼‚"""
    print("ğŸ” æ£€æŸ¥è¡¨ç»“æ„å·®å¼‚...")
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„è¡¨ç»“æ„æ£€æŸ¥å’Œä¿®å¤é€»è¾‘
    # æ¯”å¦‚æ£€æŸ¥ç¼ºå¤±çš„å­—æ®µã€ç´¢å¼•ç­‰
    print("â„¹ï¸  è¡¨ç»“æ„æ£€æŸ¥å®Œæˆï¼ˆåŸºç¡€ç‰ˆæœ¬ï¼‰")



def migrate_sqlite_to_postgresql(sqlite_file, pg_engine):
    """å°†SQLiteæ•°æ®è¿ç§»åˆ°PostgreSQLï¼Œè‡ªåŠ¨ä¿®å¤å¸ƒå°”å­—æ®µ"""
    try:
        import sqlite3
        import pandas as pd
        from sqlalchemy import text
        
        print("ğŸ”„ å¼€å§‹æ•°æ®è¿ç§»...")
        
        # è¿æ¥SQLite
        sqlite_conn = sqlite3.connect(sqlite_file)
        
        # è·å–æ‰€æœ‰è¡¨å
        cursor = sqlite_conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'")
        tables = [row[0] for row in cursor.fetchall()]
        
        print(f"ğŸ“‹ å‘ç° {len(tables)} ä¸ªè¡¨éœ€è¦è¿ç§»")
        
        success_count = 0
        for table_name in tables:
            try:
                # è¯»å–SQLiteæ•°æ®
                df = pd.read_sql_query(f"SELECT * FROM {table_name}", sqlite_conn)
                
                # é’ˆå¯¹dca_plansè¡¨ï¼Œè‡ªåŠ¨ä¿®å¤å¸ƒå°”å­—æ®µ
                if table_name == "dca_plans" and not df.empty:
                    for col in ["smart_dca", "skip_holidays", "enable_notification"]:
                        if col in df.columns:
                            df[col] = df[col].apply(lambda x: True if x in [1, "1", True] else False if x in [0, "0", False] else None)
                
                if not df.empty:
                    # å†™å…¥PostgreSQL
                    df.to_sql(table_name, pg_engine, if_exists='append', index=False, method='multi')
                    print(f"âœ… {table_name}: {len(df)} æ¡è®°å½•")
                    success_count += 1
                else:
                    print(f"â„¹ï¸  {table_name}: æ— æ•°æ®")
                    success_count += 1
                    
            except Exception as e:
                print(f"âŒ {table_name}: {str(e)[:100]}...")  # åªæ˜¾ç¤ºå‰100ä¸ªå­—ç¬¦
        
        sqlite_conn.close()
        
        print(f"ğŸ‰ æ•°æ®è¿ç§»å®Œæˆ: {success_count}/{len(tables)} ä¸ªè¡¨æˆåŠŸ")
        
        # å¤‡ä»½SQLiteæ–‡ä»¶
        backup_file = sqlite_file + ".backup"
        import shutil
        try:
            shutil.copy2(sqlite_file, backup_file)
            print(f"ğŸ’¾ SQLiteæ–‡ä»¶å·²å¤‡ä»½åˆ°: {backup_file}")
        except Exception as e:
            print(f"âš ï¸  å¤‡ä»½SQLiteæ–‡ä»¶å¤±è´¥: {e}")
        
    except Exception as e:
        print(f"âŒ æ•°æ®è¿ç§»å¤±è´¥: {e}")
        print("âš ï¸  ç»§ç»­å¯åŠ¨ï¼Œä½†æ•°æ®å¯èƒ½ä¸å®Œæ•´")

def auto_alembic_upgrade():
    try:
        print("[ALEMBIC] è‡ªåŠ¨æ‰§è¡Œæ•°æ®åº“è¿ç§»: alembic upgrade head ...")
        result = subprocess.run(["alembic", "upgrade", "head"], capture_output=True, text=True)
        print(result.stdout)
        if result.returncode != 0:
            print("[ALEMBIC] è¿ç§»å¤±è´¥:")
            print(result.stderr)
        else:
            print("[ALEMBIC] è¿ç§»å®Œæˆ")
    except Exception as e:
        print(f"[ALEMBIC] æ‰§è¡Œè¿ç§»å‘½ä»¤å‡ºé”™: {e}")

if __name__ == "__main__":
    import uvicorn
    
    # æ£€æŸ¥ç¯å¢ƒ
    check_railway_environment()
    
    # åœ¨Railwayç¯å¢ƒä¸­å¤„ç†æ•°æ®åº“è¿ç§»
    if os.getenv("RAILWAY_ENVIRONMENT") is not None:
        print("ğŸš€ æ£€æµ‹åˆ°Railwayç¯å¢ƒï¼Œæ‰§è¡Œå®‰å…¨æ•°æ®åº“è¿ç§»...")
        migration_success = safe_railway_migration()
        if not migration_success:
            print("âŒ æ•°æ®åº“è¿ç§»å¤±è´¥ï¼ŒæœåŠ¡æ— æ³•å¯åŠ¨")
            sys.exit(1)
    else:
        print("ğŸ  æœ¬åœ°ç¯å¢ƒï¼Œæ‰§è¡Œæ ‡å‡†æ•°æ®åº“è®¾ç½®...")
        auto_alembic_upgrade()
    
    # æµ‹è¯•æ¨¡å¼ï¼šæ¨¡æ‹ŸRailwayç¯å¢ƒ
    if os.getenv("TEST_RAILWAY_MIGRATION", "false").lower() == "true":
        print("ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šæ¨¡æ‹ŸRailwayç¯å¢ƒè¿ç§»...")
        os.environ["RAILWAY_ENVIRONMENT"] = "test"
        migration_success = safe_railway_migration()
        if not migration_success:
            print("âŒ æµ‹è¯•è¿ç§»å¤±è´¥")
            sys.exit(1)
    
    port = int(os.environ.get("PORT", 8000))
    debug = os.environ.get("DEBUG", "False").lower() == "true"
    
    print(f"ğŸŒ æœåŠ¡ç«¯å£: {port}")
    print(f"ğŸ› è°ƒè¯•æ¨¡å¼: {debug}")
    
    # ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–é…ç½®
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=port,
        reload=debug,  # ç”Ÿäº§ç¯å¢ƒç¦ç”¨reload
        workers=1,  # å›ºå®šä½¿ç”¨å•è¿›ç¨‹ï¼Œé¿å…å¹¶å‘é—®é¢˜
        access_log=debug,  # ç”Ÿäº§ç¯å¢ƒå¯ä»¥ç¦ç”¨è®¿é—®æ—¥å¿—ä»¥æé«˜æ€§èƒ½
        log_level="info" if not debug else "debug"
    ) 