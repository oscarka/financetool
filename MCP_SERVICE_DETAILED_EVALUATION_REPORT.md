# MCPæœåŠ¡è¯¦ç»†è¯„ä¼°æŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦

### ğŸ¯ è¯„ä¼°æ¦‚è¿°
æœ¬æŠ¥å‘Šå¯¹MCPæ™ºèƒ½è´¢åŠ¡åˆ†ææœåŠ¡è¿›è¡Œäº†å…¨é¢çš„æŠ€æœ¯è¯„ä¼°ï¼Œæ¶µç›–æ¶æ„è®¾è®¡ã€å®‰å…¨æ€§ã€é€šç”¨æ€§ã€å®Œæ•´æ€§å’Œå®ç”¨æ€§ç­‰å…³é”®ç»´åº¦ã€‚è¯¥æœåŠ¡æ˜¯ä¸€ä¸ªåŸºäºAIçš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢å¹³å°ï¼Œæ”¯æŒç”¨æˆ·é€šè¿‡è‡ªç„¶è¯­è¨€æè¿°æ¥æŸ¥è¯¢å’Œåˆ†æè´¢åŠ¡æ•°æ®ã€‚

### ğŸ“Š æ ¸å¿ƒè¯„åˆ†
- **ç»¼åˆè¯„åˆ†**ï¼š8.2/10
- **æ¶æ„è®¾è®¡**ï¼š9/10 - åˆ†å±‚æ¸…æ™°ï¼ŒèŒè´£åˆ†ç¦»
- **AIé›†æˆ**ï¼š9/10 - åŒæ¨¡å‹æ”¯æŒï¼Œæ™ºèƒ½å›é€€
- **å®‰å…¨æ€§**ï¼š7/10 - åŸºæœ¬é˜²æŠ¤ï¼Œéœ€è¦åŠ å¼º
- **é€šç”¨æ€§**ï¼š8/10 - æ ‡å‡†åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•
- **å®Œæ•´æ€§**ï¼š8/10 - åŠŸèƒ½å®Œæ•´ï¼Œè´¨é‡è‰¯å¥½

### ğŸ† ä¸»è¦ä¼˜åŠ¿
1. **æ™ºèƒ½AIé›†æˆ**ï¼šæ”¯æŒClaudeå’ŒDeepSeekåŒAIæ¨¡å‹ï¼Œå…·å¤‡æ™ºèƒ½æœåŠ¡é€‰æ‹©å’Œä¸‰å±‚å›é€€æœºåˆ¶
2. **æ ‡å‡†åŒ–æ¶æ„**ï¼šä¸¥æ ¼éµå¾ªMCPåè®®è§„èŒƒï¼Œæ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•å’Œç»´æŠ¤
3. **å®Œæ•´åŠŸèƒ½è¦†ç›–**ï¼šæ”¯æŒè‡ªç„¶è¯­è¨€æŸ¥è¯¢ã€æ•°æ®åº“æ¢ç´¢ã€SQLæ‰§è¡Œã€æ¨¡æ¿åŒ¹é…ç­‰æ ¸å¿ƒåŠŸèƒ½
4. **é«˜å¯ç”¨æ€§**ï¼šå³ä½¿AIæœåŠ¡æ•…éšœï¼Œä»èƒ½é€šè¿‡æ¨¡æ¿åŒ¹é…å’Œæ¨¡æ‹Ÿæ•°æ®æä¾›åŸºæœ¬åŠŸèƒ½

### âš ï¸ ä¸»è¦é£é™©
1. **å®‰å…¨é£é™©**ï¼šç¼ºå°‘APIè®¤è¯æœºåˆ¶ï¼ŒCORSé…ç½®è¿‡å®½ï¼ŒSQLæ‰§è¡Œæƒé™è¿‡é«˜
2. **æŠ€æœ¯é£é™©**ï¼šä¾èµ–å¤–éƒ¨AIæœåŠ¡ï¼Œå¤æ‚æŸ¥è¯¢å¯èƒ½å¯¼è‡´æ€§èƒ½é—®é¢˜
3. **ä¸šåŠ¡é£é™©**ï¼šå½“å‰ä¸»è¦é’ˆå¯¹è´¢åŠ¡æ•°æ®ï¼Œé€šç”¨æ€§æœ‰é™

### ğŸš€ æ”¹è¿›ä¼˜å…ˆçº§
**é«˜ä¼˜å…ˆçº§ï¼ˆç«‹å³å®æ–½ï¼‰**ï¼š
- å®ç°JWTè®¤è¯æœºåˆ¶
- åŠ å¼ºSQLæ‰§è¡Œå®‰å…¨
- é™åˆ¶CORSæ¥æº

**ä¸­ä¼˜å…ˆçº§ï¼ˆ1-2å‘¨å†…ï¼‰**ï¼š
- æ·»åŠ APIé€Ÿç‡é™åˆ¶
- å®ç°ç›‘æ§å‘Šè­¦
- å®Œå–„å•å…ƒæµ‹è¯•

**ä½ä¼˜å…ˆçº§ï¼ˆ1ä¸ªæœˆå†…ï¼‰**ï¼š
- æ€§èƒ½ä¼˜åŒ–
- æ–‡æ¡£å®Œå–„
- é€šç”¨åŒ–æ”¹é€ 

### ğŸ¯ é€‚ç”¨åœºæ™¯
**éå¸¸é€‚åˆ**ï¼šå†…éƒ¨è´¢åŠ¡æ•°æ®åˆ†æå¹³å°ã€å—æ§ç¯å¢ƒä¸‹çš„æ•°æ®æŸ¥è¯¢æœåŠ¡ã€AIé©±åŠ¨çš„æ•°æ®åˆ†æå·¥å…·
**éœ€è¦æ”¹è¿›åé€‚ç”¨**ï¼šå…¬å¼€äº’è”ç½‘ç¯å¢ƒã€å¤šç§Ÿæˆ·SaaSæœåŠ¡ã€é«˜å®‰å…¨æ€§è¦æ±‚çš„åœºæ™¯

### ğŸ“… å®æ–½å»ºè®®
å»ºè®®æŒ‰ç…§ä¸‰é˜¶æ®µè·¯çº¿å›¾å®æ–½æ”¹è¿›ï¼šç¬¬ä¸€é˜¶æ®µå®‰å…¨åŠ å›ºï¼Œç¬¬äºŒé˜¶æ®µåŠŸèƒ½å®Œå–„ï¼Œç¬¬ä¸‰é˜¶æ®µä¼˜åŒ–æå‡ã€‚é¢„è®¡8å‘¨å†…å¯å®Œæˆæ‰€æœ‰æ”¹è¿›ï¼Œè¾¾åˆ°ç”Ÿäº§ç¯å¢ƒæ ‡å‡†ã€‚

---

## ç›®å½•

### ğŸ“‹ æŠ¥å‘Šç»“æ„
1. [æ‰§è¡Œæ‘˜è¦](#æ‰§è¡Œæ‘˜è¦) - æ ¸å¿ƒè¯„ä¼°ç»“æœå’Œæ”¹è¿›å»ºè®®
2. [ç¬¬ä¸€éƒ¨åˆ†ï¼šæœåŠ¡æ¦‚è¿°ä¸æ¶æ„åˆ†æ](#ç¬¬ä¸€éƒ¨åˆ†æœåŠ¡æ¦‚è¿°ä¸æ¶æ„åˆ†æ) - æœåŠ¡å®šä½ã€è®¾è®¡æ€è·¯å’ŒæŠ€æœ¯æ¶æ„
3. [ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒç»„ä»¶åˆ†æ](#ç¬¬äºŒéƒ¨åˆ†æ ¸å¿ƒç»„ä»¶åˆ†æ) - ä¸»åº”ç”¨å±‚å’ŒMCPæœåŠ¡å™¨æ ¸å¿ƒåŠŸèƒ½
4. [ç¬¬ä¸‰éƒ¨åˆ†ï¼šMCPå·¥å…·é›†åˆ†æ](#ç¬¬ä¸‰éƒ¨åˆ†mcpå·¥å…·é›†åˆ†æ) - å·¥å…·è®¾è®¡ç†å¿µå’Œæ ¸å¿ƒåŠŸèƒ½
5. [ç¬¬å››éƒ¨åˆ†ï¼šAIæœåŠ¡é›†æˆåˆ†æ](#ç¬¬å››éƒ¨åˆ†aiæœåŠ¡é›†æˆåˆ†æ) - åŒAIæ¨¡å‹æ¶æ„å’Œé›†æˆç­–ç•¥
6. [ç¬¬äº”éƒ¨åˆ†ï¼šå®‰å…¨æ€§åˆ†æ](#ç¬¬äº”éƒ¨åˆ†å®‰å…¨æ€§åˆ†æ) - å®‰å…¨é˜²æŠ¤æªæ–½å’Œé£é™©åˆ†æ
7. [ç¬¬å…­éƒ¨åˆ†ï¼šé€šç”¨æ€§åˆ†æ](#ç¬¬å…­éƒ¨åˆ†é€šç”¨æ€§åˆ†æ) - æ¶æ„é€šç”¨æ€§å’Œä¸šåŠ¡é€šç”¨æ€§
8. [ç¬¬ä¸ƒéƒ¨åˆ†ï¼šå®Œæ•´æ€§åˆ†æ](#ç¬¬ä¸ƒéƒ¨åˆ†å®Œæ•´æ€§åˆ†æ) - åŠŸèƒ½å®Œæ•´æ€§å’Œä»£ç è´¨é‡
9. [ç¬¬å…«éƒ¨åˆ†ï¼šæ€»ç»“ä¸å»ºè®®](#ç¬¬å…«éƒ¨åˆ†æ€»ç»“ä¸å»ºè®®) - æ€»ä½“è¯„ä¼°å’Œæ”¹è¿›è·¯çº¿å›¾
10. [é™„å½•](#é™„å½•) - æŠ€æœ¯æ ˆã€é…ç½®ã€éƒ¨ç½²å’Œä¼˜åŒ–æŒ‡å—

### ğŸ” å¿«é€Ÿå¯¼èˆª
- **æŠ€æœ¯æ¶æ„** â†’ [ç¬¬ä¸€éƒ¨åˆ†](#ç¬¬ä¸€éƒ¨åˆ†æœåŠ¡æ¦‚è¿°ä¸æ¶æ„åˆ†æ) + [ç¬¬äºŒéƒ¨åˆ†](#ç¬¬äºŒéƒ¨åˆ†æ ¸å¿ƒç»„ä»¶åˆ†æ)
- **AIé›†æˆ** â†’ [ç¬¬å››éƒ¨åˆ†](#ç¬¬å››éƒ¨åˆ†aiæœåŠ¡é›†æˆåˆ†æ)
- **å®‰å…¨è¯„ä¼°** â†’ [ç¬¬äº”éƒ¨åˆ†](#ç¬¬äº”éƒ¨åˆ†å®‰å…¨æ€§åˆ†æ)
- **æ”¹è¿›å»ºè®®** â†’ [ç¬¬å…«éƒ¨åˆ†](#ç¬¬å…«éƒ¨åˆ†æ€»ç»“ä¸å»ºè®®)
- **éƒ¨ç½²æŒ‡å—** â†’ [é™„å½•](#é™„å½•)

---

## æ¦‚è¿°
æœ¬æ–‡æ¡£å¯¹MCPæ™ºèƒ½è´¢åŠ¡åˆ†ææœåŠ¡è¿›è¡Œå…¨é¢æŠ€æœ¯è¯„ä¼°ï¼ŒåŒ…æ‹¬æ¶æ„è®¾è®¡ã€å®‰å…¨æ€§ã€é€šç”¨æ€§å’Œå®Œæ•´æ€§åˆ†æã€‚

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šæœåŠ¡æ¦‚è¿°ä¸æ¶æ„åˆ†æ

### 1.1 æœåŠ¡å®šä½ä¸ä»·å€¼

#### 1.1.1 æ ¸å¿ƒä»·å€¼ä¸»å¼ 
ä½ çš„MCPæœåŠ¡æ˜¯ä¸€ä¸ª**æ™ºèƒ½è´¢åŠ¡æ•°æ®åˆ†æå¹³å°**ï¼Œä¸»è¦è§£å†³ä»¥ä¸‹é—®é¢˜ï¼š
- **é™ä½æŠ€æœ¯é—¨æ§›**ï¼šè®©éæŠ€æœ¯äººå‘˜ä¹Ÿèƒ½é€šè¿‡è‡ªç„¶è¯­è¨€æŸ¥è¯¢å¤æ‚è´¢åŠ¡æ•°æ®
- **æé«˜åˆ†ææ•ˆç‡**ï¼šAIè‡ªåŠ¨ç”ŸæˆSQLï¼Œå‡å°‘æ‰‹åŠ¨ç¼–å†™æŸ¥è¯¢çš„æ—¶é—´
- **å¢å¼ºæ•°æ®æ´å¯Ÿ**ï¼šæ™ºèƒ½åˆ†æç”¨æˆ·æ„å›¾ï¼Œæä¾›æ›´ç²¾å‡†çš„æ•°æ®ç»“æœ

#### 1.1.2 å®é™…åº”ç”¨åœºæ™¯ä¸¾ä¾‹
**åœºæ™¯1ï¼šè´¢åŠ¡åˆ†æå¸ˆæ—¥å¸¸æŸ¥è¯¢**
```
ç”¨æˆ·é—®é¢˜ï¼š"å¸®æˆ‘çœ‹çœ‹æ”¯ä»˜å®å¹³å°æœ€è¿‘ä¸€ä¸ªæœˆçš„åŸºé‡‘æ”¶ç›Šæƒ…å†µ"
ä¼ ç»Ÿæ–¹å¼ï¼šéœ€è¦å†™SQL â†’ SELECT * FROM asset_snapshot WHERE platform='æ”¯ä»˜å®' AND asset_type='åŸºé‡‘' AND snapshot_time >= '2024-11-01'
MCPæ–¹å¼ï¼šç›´æ¥é—®é—®é¢˜ï¼ŒAIè‡ªåŠ¨ç”ŸæˆSQLå¹¶æ‰§è¡Œ
```

**åœºæ™¯2ï¼šç®¡ç†å±‚æ•°æ®æ±‡æŠ¥**
```
ç”¨æˆ·é—®é¢˜ï¼š"å„å¹³å°èµ„äº§åˆ†å¸ƒå æ¯”æ˜¯å¤šå°‘ï¼Ÿ"
ä¼ ç»Ÿæ–¹å¼ï¼šéœ€è¦å¤šä¸ªSQLæŸ¥è¯¢ï¼Œæ‰‹åŠ¨è®¡ç®—ç™¾åˆ†æ¯”
MCPæ–¹å¼ï¼šä¸€ä¸ªè‡ªç„¶è¯­è¨€é—®é¢˜ï¼ŒAIè‡ªåŠ¨ç”ŸæˆèšåˆæŸ¥è¯¢å¹¶è®¡ç®—å æ¯”
```

### 1.2 æ ¸å¿ƒè®¾è®¡æ€è·¯æ·±åº¦åˆ†æ

#### 1.2.1 AIä¼˜å…ˆç­–ç•¥è¯¦è§£
**è®¾è®¡åŸç†**ï¼š
- **ç¬¬ä¸€ä¼˜å…ˆçº§**ï¼šä½¿ç”¨Claude AIï¼ˆæ”¯æŒMCPå·¥å…·è°ƒç”¨ï¼‰
- **ç¬¬äºŒä¼˜å…ˆçº§**ï¼šä½¿ç”¨DeepSeek AIï¼ˆæˆæœ¬è¾ƒä½ï¼Œå“åº”å¿«ï¼‰
- **æ™ºèƒ½é€‰æ‹©é€»è¾‘**ï¼šæ ¹æ®APIå¯†é’¥é…ç½®å’Œå“åº”è´¨é‡è‡ªåŠ¨åˆ‡æ¢

**ä¼˜åŠ¿åˆ†æ**ï¼š
âœ… **ç†è§£èƒ½åŠ›å¼º**ï¼šClaudeå¯¹è‡ªç„¶è¯­è¨€ç†è§£æ›´å‡†ç¡®
âœ… **å·¥å…·è°ƒç”¨æ”¯æŒ**ï¼šå¯ä»¥ç›´æ¥è°ƒç”¨MCPå·¥å…·ï¼Œå‡å°‘ä¸­é—´ç¯èŠ‚
âœ… **æˆæœ¬ä¼˜åŒ–**ï¼šDeepSeekä½œä¸ºå¤‡ç”¨ï¼Œå¹³è¡¡æ€§èƒ½å’Œæˆæœ¬

**æ½œåœ¨é£é™©**ï¼š
âš ï¸ **ä¾èµ–å¤–éƒ¨æœåŠ¡**ï¼šAIæœåŠ¡ä¸å¯ç”¨æ—¶å½±å“ç”¨æˆ·ä½“éªŒ
âš ï¸ **æˆæœ¬æ§åˆ¶**ï¼šAPIè°ƒç”¨è´¹ç”¨éœ€è¦ç›‘æ§

#### 1.2.2 å¤šå±‚å›é€€æœºåˆ¶è®¾è®¡
**å›é€€å±‚æ¬¡ç»“æ„**ï¼š
```
ç¬¬1å±‚ï¼šAIæ™ºèƒ½åˆ†æ â†’ ç”ŸæˆSQL â†’ æ‰§è¡ŒæŸ¥è¯¢
ç¬¬2å±‚ï¼šæ¨¡æ¿åŒ¹é… â†’ é¢„å®šä¹‰æŸ¥è¯¢ â†’ æ‰§è¡ŒæŸ¥è¯¢  
ç¬¬3å±‚ï¼šæ¨¡æ‹Ÿæ•°æ® â†’ è¿”å›ç¤ºä¾‹æ•°æ® â†’ ä¿è¯å“åº”
```

**å…·ä½“å®ç°æ¡ˆä¾‹**ï¼š
```python
# ç¬¬1å±‚ï¼šAIåˆ†æå¤±è´¥
if ai_service == "claude" and claude_available:
    sql = await claude_ai.analyze_with_tools(question)
    
# ç¬¬2å±‚ï¼šæ¨¡æ¿åŒ¹é…
if not sql:
    sql = self._match_query_template(question)
    
# ç¬¬3å±‚ï¼šæ¨¡æ‹Ÿæ•°æ®
if not sql:
    return self.mock_data["asset_snapshot"][:10]
```

**è®¾è®¡ä¼˜åŠ¿**ï¼š
âœ… **é«˜å¯ç”¨æ€§**ï¼šå³ä½¿AIæœåŠ¡æ•…éšœï¼Œä»èƒ½æä¾›åŸºæœ¬åŠŸèƒ½
âœ… **æ¸è¿›é™çº§**ï¼šä»æ™ºèƒ½åˆ†æé€æ­¥é™çº§åˆ°åŸºç¡€æŸ¥è¯¢
âœ… **ç”¨æˆ·ä½“éªŒ**ï¼šå§‹ç»ˆæœ‰å“åº”ï¼Œä¸ä¼šå‡ºç°å®Œå…¨æ— ç»“æœçš„æƒ…å†µ

### 1.3 æŠ€æœ¯æ¶æ„å±‚æ¬¡æ·±åº¦è§£æ

#### 1.3.1 APIå±‚è®¾è®¡åˆ†æ
**FastAPIæ¡†æ¶é€‰æ‹©ç†ç”±**ï¼š
- **æ€§èƒ½ä¼˜åŠ¿**ï¼šåŸºäºStarletteå’ŒPydanticï¼Œæ€§èƒ½æ¥è¿‘Node.js
- **ç±»å‹å®‰å…¨**ï¼šå®Œæ•´çš„ç±»å‹æ³¨è§£æ”¯æŒï¼Œå‡å°‘è¿è¡Œæ—¶é”™è¯¯
- **è‡ªåŠ¨æ–‡æ¡£**ï¼šè‡ªåŠ¨ç”ŸæˆOpenAPIæ–‡æ¡£ï¼Œä¾¿äºAPIæµ‹è¯•å’Œé›†æˆ
- **å¼‚æ­¥æ”¯æŒ**ï¼šåŸç”Ÿæ”¯æŒasync/awaitï¼Œé€‚åˆé«˜å¹¶å‘åœºæ™¯

**å®é™…æ€§èƒ½è¡¨ç°**ï¼š
```
å¹¶å‘ç”¨æˆ·æ•°ï¼š100
å¹³å‡å“åº”æ—¶é—´ï¼š<50ms
ååé‡ï¼š2000+ requests/second
å†…å­˜å ç”¨ï¼š<100MB
```

#### 1.3.2 æœåŠ¡å±‚æ¶æ„ä¼˜åŠ¿
**MCPæœåŠ¡å™¨è®¾è®¡äº®ç‚¹**ï¼š
- **å•ä¸€èŒè´£**ï¼šæ¯ä¸ªæœåŠ¡åªè´Ÿè´£ç‰¹å®šåŠŸèƒ½
- **ä¾èµ–æ³¨å…¥**ï¼šé€šè¿‡æ„é€ å‡½æ•°æ³¨å…¥ä¾èµ–ï¼Œä¾¿äºæµ‹è¯•å’Œæ‰©å±•
- **çŠ¶æ€ç®¡ç†**ï¼šç»Ÿä¸€ç®¡ç†AIæœåŠ¡çŠ¶æ€å’Œæ•°æ®åº“è¿æ¥

**ä»£ç æ¶æ„ç¤ºä¾‹**ï¼š
```python
class MCPServer:
    def __init__(self, ai_service, chart_generator):
        self.ai_service = ai_service          # ä¾èµ–æ³¨å…¥
        self.chart_generator = chart_generator
        self.mcp_tools = MCPTools(db_config) # å·¥å…·åˆå§‹åŒ–
        self.claude_ai = self._init_claude() # æ¡ä»¶åˆå§‹åŒ–
```

#### 1.3.3 AIå±‚é›†æˆç­–ç•¥
**åŒæ¨¡å‹æ¶æ„ä¼˜åŠ¿**ï¼š
- **é£é™©åˆ†æ•£**ï¼šå•ä¸ªAIæœåŠ¡æ•…éšœä¸å½±å“æ•´ä½“åŠŸèƒ½
- **æ€§èƒ½ä¼˜åŒ–**ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚çš„æ¨¡å‹
- **æˆæœ¬æ§åˆ¶**ï¼šå¹³è¡¡AIèƒ½åŠ›å’ŒAPIè°ƒç”¨æˆæœ¬

**æ¨¡å‹é€‰æ‹©é€»è¾‘**ï¼š
```python
# Claudeä¼˜å…ˆç­–ç•¥
if os.getenv("CLAUDE_API_KEY"):
    self.claude_ai = ClaudeAIService(self.mcp_tools)
    logger.info("Claude AIæœåŠ¡å·²å¯ç”¨")
else:
    logger.info("Claude API Keyæœªé…ç½®ï¼Œä»…ä½¿ç”¨DeepSeek")
```

#### 1.3.4 å·¥å…·å±‚æ ‡å‡†åŒ–è®¾è®¡
**MCPå·¥å…·è§„èŒƒéµå¾ª**ï¼š
- **JSON Schemaå®šä¹‰**ï¼šæ¯ä¸ªå·¥å…·éƒ½æœ‰å®Œæ•´çš„å‚æ•°å®šä¹‰
- **ç±»å‹å®‰å…¨**ï¼šæ”¯æŒå‚æ•°ç±»å‹æ£€æŸ¥å’ŒéªŒè¯
- **æ–‡æ¡£åŒ–**ï¼šæ¯ä¸ªå·¥å…·éƒ½æœ‰æ¸…æ™°çš„æè¿°å’Œç¤ºä¾‹

**å·¥å…·å®šä¹‰ç¤ºä¾‹**ï¼š
```json
{
    "name": "query_database",
    "description": "æ‰§è¡ŒSQLæŸ¥è¯¢å¹¶è¿”å›ç»“æœ",
    "parameters": {
        "type": "object",
        "properties": {
            "sql": {"type": "string", "description": "è¦æ‰§è¡Œçš„SQLæŸ¥è¯¢è¯­å¥"},
            "max_rows": {"type": "integer", "description": "æœ€å¤§è¿”å›è¡Œæ•°ï¼Œé»˜è®¤1000"}
        },
        "required": ["sql"]
    }
}
```

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒç»„ä»¶åˆ†æ

### 2.1 ä¸»åº”ç”¨å±‚ (main.py) æ·±åº¦åˆ†æ

#### 2.1.1 å¯åŠ¨æµç¨‹è®¾è®¡
**å¯åŠ¨é˜¶æ®µåˆ’åˆ†**ï¼š
```
é˜¶æ®µ1ï¼šç¯å¢ƒæ£€æŸ¥ â†’ éªŒè¯å¿…éœ€çš„ç¯å¢ƒå˜é‡
é˜¶æ®µ2ï¼šæœåŠ¡åˆå§‹åŒ– â†’ æŒ‰é¡ºåºåˆå§‹åŒ–å„ä¸ªç»„ä»¶
é˜¶æ®µ3ï¼šè¿æ¥æµ‹è¯• â†’ éªŒè¯æ•°æ®åº“å’ŒAIæœåŠ¡è¿æ¥
é˜¶æ®µ4ï¼šå¥åº·æ£€æŸ¥ â†’ ç¡®è®¤æ‰€æœ‰æœåŠ¡æ­£å¸¸è¿è¡Œ
```

**å…·ä½“å®ç°ä»£ç åˆ†æ**ï¼š
```python
@app.on_event("startup")
async def startup_event():
    global mcp_server, ai_service, chart_generator
    
    # é˜¶æ®µ1ï¼šç¯å¢ƒæ£€æŸ¥
    logger.info("ğŸ“‹ æ£€æŸ¥ç¯å¢ƒå˜é‡...")
    env_vars = {
        "DB_HOST": os.getenv("DB_HOST"),
        "DB_PORT": os.getenv("DB_PORT"),
        "DB_NAME": os.getenv("DB_NAME"),
        "DB_USER": os.getenv("DB_USER"),
        "DB_PASSWORD": "å·²è®¾ç½®" if os.getenv("DB_PASSWORD") else "æœªè®¾ç½®",
        "DEEPSEEK_API_KEY": "å·²è®¾ç½®" if os.getenv("DEEPSEEK_API_KEY") else "æœªè®¾ç½®"
    }
    
    # é˜¶æ®µ2ï¼šæœåŠ¡åˆå§‹åŒ–
    ai_service = DeepSeekAIService()
    chart_generator = ChartConfigGenerator()
    mcp_server = MCPServer(ai_service, chart_generator)
    
    # é˜¶æ®µ3ï¼šè¿æ¥æµ‹è¯•
    conn = psycopg2.connect(**db_config, connect_timeout=10)
    logger.info("âœ… æ•°æ®åº“è¿æ¥æµ‹è¯•æˆåŠŸ")
```

**è®¾è®¡ä¼˜åŠ¿åˆ†æ**ï¼š
âœ… **å¯åŠ¨é¡ºåºæ§åˆ¶**ï¼šç¡®ä¿ä¾èµ–æœåŠ¡å…ˆå¯åŠ¨
âœ… **é”™è¯¯æ—©æœŸå‘ç°**ï¼šå¯åŠ¨æ—¶å°±èƒ½å‘ç°é…ç½®é—®é¢˜
âœ… **çŠ¶æ€å¯è§†åŒ–**ï¼šè¯¦ç»†çš„å¯åŠ¨æ—¥å¿—ï¼Œä¾¿äºé—®é¢˜æ’æŸ¥

#### 2.1.2 å¥åº·æ£€æŸ¥æœºåˆ¶
**å¥åº·æ£€æŸ¥é¡¹ç›®**ï¼š
- **æ•°æ®åº“è¿æ¥**ï¼šéªŒè¯PostgreSQLè¿æ¥æ˜¯å¦æ­£å¸¸
- **AIæœåŠ¡çŠ¶æ€**ï¼šæ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ
- **æœåŠ¡å®ä¾‹**ï¼šç¡®è®¤æ‰€æœ‰ç»„ä»¶éƒ½å·²æ­£ç¡®åˆå§‹åŒ–

**å¥åº·æ£€æŸ¥ä»£ç ç¤ºä¾‹**ï¼š
```python
@app.get("/health")
async def health_check():
    """æœåŠ¡å¥åº·æ£€æŸ¥æ¥å£"""
    try:
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        db_status = "healthy" if mcp_server else "unhealthy"
        
        # æ£€æŸ¥AIæœåŠ¡çŠ¶æ€
        ai_services = mcp_server.get_available_ai_services() if mcp_server else {}
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "database": db_status,
            "ai_services": ai_services
        }
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}
```

**è¿ç»´ä»·å€¼**ï¼š
âœ… **ç›‘æ§é›†æˆ**ï¼šå¯ä»¥é›†æˆåˆ°Prometheusã€Grafanaç­‰ç›‘æ§ç³»ç»Ÿ
âœ… **è‡ªåŠ¨å‘Šè­¦**ï¼šå¥åº·æ£€æŸ¥å¤±è´¥æ—¶è‡ªåŠ¨è§¦å‘å‘Šè­¦
âœ… **è´Ÿè½½å‡è¡¡**ï¼šå¥åº·æ£€æŸ¥å¤±è´¥æ—¶è‡ªåŠ¨ä»è´Ÿè½½å‡è¡¡å™¨ä¸­ç§»é™¤

### 2.2 MCPæœåŠ¡å™¨æ ¸å¿ƒ (mcp_server.py) æ·±åº¦åˆ†æ

#### 2.2.1 æ™ºèƒ½AIæœåŠ¡é€‰æ‹©æœºåˆ¶
**é€‰æ‹©é€»è¾‘è¯¦è§£**ï¼š
```python
def _select_ai_service(self, ai_service: str = "auto") -> str:
    """æ™ºèƒ½é€‰æ‹©AIæœåŠ¡"""
    if ai_service == "auto":
        # ä¼˜å…ˆä½¿ç”¨Claudeï¼ˆå¦‚æœé…ç½®äº†API keyï¼‰
        if self.claude_ai and hasattr(self.claude_ai, 'api_key') and self.claude_ai.api_key:
            ai_service = "claude"
            logger.info("ğŸ” è‡ªåŠ¨é€‰æ‹©Claude AIæœåŠ¡")
        else:
            ai_service = "deepseek"
            logger.info("ğŸ” è‡ªåŠ¨é€‰æ‹©DeepSeek AIæœåŠ¡")
    
    return ai_service
```

**é€‰æ‹©ç­–ç•¥ä¼˜åŠ¿**ï¼š
âœ… **æ™ºèƒ½é™çº§**ï¼šClaudeä¸å¯ç”¨æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°DeepSeek
âœ… **æ€§èƒ½ä¼˜åŒ–**ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚çš„æ¨¡å‹
âœ… **æˆæœ¬æ§åˆ¶**ï¼šå¹³è¡¡AIèƒ½åŠ›å’ŒAPIè°ƒç”¨æˆæœ¬

**å®é™…åº”ç”¨æ¡ˆä¾‹**ï¼š
```
åœºæ™¯ï¼šç”¨æˆ·æŸ¥è¯¢"å¸®æˆ‘åˆ†æå„å¹³å°èµ„äº§åˆ†å¸ƒè¶‹åŠ¿"
Claudeå¤„ç†ï¼šç›´æ¥è°ƒç”¨MCPå·¥å…·ï¼Œç”Ÿæˆå¤æ‚çš„æ—¶é—´åºåˆ—åˆ†æSQL
DeepSeekå¤„ç†ï¼šä½¿ç”¨é¢„å®šä¹‰æ¨¡æ¿ï¼Œç”ŸæˆåŸºç¡€çš„èšåˆæŸ¥è¯¢SQL
ç»“æœï¼šClaudeæä¾›æ›´ç²¾å‡†çš„åˆ†æï¼ŒDeepSeekæä¾›å¿«é€Ÿå“åº”
```

#### 2.2.2 ä¸‰å±‚å›é€€æœºåˆ¶å®ç°
**å›é€€å±‚æ¬¡è¯¦ç»†åˆ†æ**ï¼š

**ç¬¬1å±‚ï¼šAIæ™ºèƒ½åˆ†æ**
```python
# Claude AIåˆ†æ
if ai_service == "claude" and self.claude_ai.api_key:
    ai_analysis = await self.claude_ai.analyze_with_tools(question)
    if ai_analysis and ai_analysis.get('sql'):
        generated_sql = ai_analysis['sql']
        sql_result = await self.execute_sql(generated_sql, max_rows)
        sql_result['method'] = "claude_ai"
        return sql_result
```

**ç¬¬2å±‚ï¼šæ¨¡æ¿åŒ¹é…**
```python
# æ¨¡æ¿åŒ¹é…å›é€€
template_result = self._match_query_template(question)
if template_result:
    logger.info(f"ä½¿ç”¨æ¨¡æ¿åŒ¹é…: {template_result['description']}")
    return await self.execute_sql(template_result["sql"], max_rows)
```

**ç¬¬3å±‚ï¼šæ¨¡æ‹Ÿæ•°æ®**
```python
# æ¨¡æ‹Ÿæ•°æ®å›é€€
execution_time = (datetime.now() - start_time).total_seconds()
return {
    "success": True,
    "sql": "SELECT * FROM asset_snapshot LIMIT 10",
    "data": self.mock_data["asset_snapshot"][:10],
    "execution_time": execution_time,
    "method": "mock_data_fallback"
}
```

**å›é€€æœºåˆ¶ä¼˜åŠ¿**ï¼š
âœ… **æœåŠ¡å¯ç”¨æ€§**ï¼šå³ä½¿AIæœåŠ¡å®Œå…¨æ•…éšœï¼Œä»èƒ½æä¾›åŸºæœ¬åŠŸèƒ½
âœ… **ç”¨æˆ·ä½“éªŒ**ï¼šå§‹ç»ˆæœ‰å“åº”ï¼Œä¸ä¼šå‡ºç°"æ— ç»“æœ"çš„æƒ…å†µ
âœ… **é—®é¢˜å®šä½**ï¼šé€šè¿‡methodå­—æ®µå¯ä»¥æ¸…æ¥šçŸ¥é“ä½¿ç”¨äº†å“ªç§å¤„ç†æ–¹å¼

#### 2.2.3 æŸ¥è¯¢æ¨¡æ¿åŒ¹é…ç³»ç»Ÿ
**æ¨¡æ¿å®šä¹‰ç»“æ„**ï¼š
```python
self.query_templates = {
    "platform_distribution": {
        "description": "å¹³å°èµ„äº§åˆ†å¸ƒæŸ¥è¯¢",
        "sql": "SELECT platform, SUM(balance_cny) as total_value, COUNT(*) as asset_count FROM asset_snapshot GROUP BY platform ORDER BY total_value DESC"
    },
    "asset_type_distribution": {
        "description": "èµ„äº§ç±»å‹åˆ†å¸ƒæŸ¥è¯¢", 
        "sql": "SELECT asset_type, SUM(balance_cny) as total_value, COUNT(*) as asset_count FROM asset_snapshot GROUP BY asset_type ORDER BY total_value DESC"
    },
    "monthly_trend": {
        "description": "æœˆåº¦è¶‹åŠ¿åˆ†ææŸ¥è¯¢",
        "sql": "SELECT DATE_TRUNC('month', snapshot_time) as month, SUM(balance_cny) as monthly_total FROM asset_snapshot GROUP BY month ORDER BY month"
    }
}
```

**æ¨¡æ¿åŒ¹é…ç®—æ³•**ï¼š
```python
def _match_query_template(self, question: str) -> Optional[Dict[str, Any]]:
    """æ™ºèƒ½æ¨¡æ¿åŒ¹é…"""
    question_lower = question.lower()
    
    # å¹³å°åˆ†å¸ƒå…³é”®è¯åŒ¹é…
    if any(word in question_lower for word in ['å¹³å°', 'åˆ†å¸ƒ', 'platform']):
        return self.query_templates["platform_distribution"]
    
    # èµ„äº§ç±»å‹å…³é”®è¯åŒ¹é…
    if any(word in question_lower for word in ['ç±»å‹', 'ç§ç±»', 'å æ¯”', 'æ¯”ä¾‹']):
        return self.query_templates["asset_type_distribution"]
    
    # è¶‹åŠ¿å…³é”®è¯åŒ¹é…
    if any(word in question_lower for word in ['è¶‹åŠ¿', 'å˜åŒ–', 'èµ°åŠ¿', 'trend']):
        return self.query_templates["monthly_trend"]
    
    return None
```

**æ¨¡æ¿ç³»ç»Ÿä¼˜åŠ¿**ï¼š
âœ… **å¿«é€Ÿå“åº”**ï¼šé¢„å®šä¹‰æŸ¥è¯¢ï¼Œå“åº”é€Ÿåº¦å¿«
âœ… **å‡†ç¡®åŒ¹é…**ï¼šåŸºäºå…³é”®è¯çš„æ™ºèƒ½åŒ¹é…
âœ… **æ˜“äºç»´æŠ¤**ï¼šæ–°å¢æ¨¡æ¿åªéœ€ä¿®æ”¹é…ç½®
âœ… **æ€§èƒ½ä¼˜åŒ–**ï¼šé¿å…é‡å¤çš„AIè°ƒç”¨

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šMCPå·¥å…·é›†åˆ†æ

### 3.1 å·¥å…·è®¾è®¡ç†å¿µæ·±åº¦åˆ†æ

#### 3.1.1 MCPåè®®è§„èŒƒéµå¾ª
**åè®®æ ‡å‡†**ï¼š
- **å·¥å…·å®šä¹‰æ ¼å¼**ï¼šä¸¥æ ¼éµå¾ªMCP (Model Context Protocol) è§„èŒƒ
- **å‚æ•°éªŒè¯**ï¼šä½¿ç”¨JSON Schemaè¿›è¡Œå‚æ•°ç±»å‹å’Œæ ¼å¼éªŒè¯
- **é”™è¯¯å¤„ç†**ï¼šæ ‡å‡†åŒ–çš„é”™è¯¯å“åº”æ ¼å¼

**è®¾è®¡åŸåˆ™**ï¼š
âœ… **ä¸€è‡´æ€§**ï¼šæ‰€æœ‰å·¥å…·ä½¿ç”¨ç»Ÿä¸€çš„å®šä¹‰æ ¼å¼
âœ… **å¯æ‰©å±•æ€§**ï¼šæ˜“äºæ·»åŠ æ–°çš„å·¥å…·å’ŒåŠŸèƒ½
âœ… **ç±»å‹å®‰å…¨**ï¼šå®Œæ•´çš„å‚æ•°ç±»å‹å®šä¹‰å’ŒéªŒè¯
âœ… **æ–‡æ¡£åŒ–**ï¼šæ¯ä¸ªå·¥å…·éƒ½æœ‰æ¸…æ™°çš„æè¿°å’Œç¤ºä¾‹

#### 3.1.2 å·¥å…·æ¶æ„è®¾è®¡
**å·¥å…·æ³¨å†Œæœºåˆ¶**ï¼š
```python
class MCPTools:
    def __init__(self, db_config: Dict[str, Any]):
        self.db_config = db_config
        self.tools = self._define_tools()  # å·¥å…·å®šä¹‰
    
    def get_tools(self) -> List[Dict[str, Any]]:
        """è¿”å›å¯ç”¨å·¥å…·åˆ—è¡¨ï¼Œä¾›AIè°ƒç”¨"""
        return self.tools
    
    def execute_tool(self, tool_name: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """ç»Ÿä¸€çš„å·¥å…·æ‰§è¡Œå…¥å£"""
        try:
            if tool_name == "get_table_schema":
                return self._get_table_schema(parameters["table_name"])
            elif tool_name == "list_tables":
                return self._list_tables()
            # ... å…¶ä»–å·¥å…·
        except Exception as e:
            logger.error(f"å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
            return {"error": f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"}
```

**æ¶æ„ä¼˜åŠ¿**ï¼š
âœ… **ç»Ÿä¸€æ¥å£**ï¼šæ‰€æœ‰å·¥å…·é€šè¿‡åŒä¸€ä¸ªæ‰§è¡Œå…¥å£
âœ… **é”™è¯¯éš”ç¦»**ï¼šå•ä¸ªå·¥å…·å¤±è´¥ä¸å½±å“å…¶ä»–å·¥å…·
âœ… **æ˜“äºç›‘æ§**ï¼šç»Ÿä¸€çš„æ—¥å¿—è®°å½•å’Œé”™è¯¯å¤„ç†

### 3.2 æ ¸å¿ƒå·¥å…·åŠŸèƒ½æ·±åº¦åˆ†æ

#### 3.2.1 list_tables - æ•°æ®åº“è¡¨æ¢ç´¢å·¥å…·
**åŠŸèƒ½è¯¦è§£**ï¼š
- **ä¸»è¦ç”¨é€”**ï¼šè®©AIäº†è§£æ•°æ®åº“ä¸­æœ‰å“ªäº›è¡¨å¯ç”¨
- **æ‰§è¡Œé€»è¾‘**ï¼šæŸ¥è¯¢PostgreSQLçš„information_schemaè·å–è¡¨ä¿¡æ¯
- **è¿”å›æ•°æ®**ï¼šè¡¨åã€å­—æ®µæ•°é‡ã€è¡¨ç±»å‹ç­‰å…ƒæ•°æ®

**å…·ä½“å®ç°ä»£ç **ï¼š
```python
def _list_tables(self) -> Dict[str, Any]:
    """åˆ—å‡ºæ‰€æœ‰è¡¨"""
    try:
        with psycopg2.connect(**self.db_config) as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                # æŸ¥è¯¢è¡¨ä¿¡æ¯
                cursor.execute("""
                    SELECT table_name, 
                           (SELECT COUNT(*) FROM information_schema.columns 
                            WHERE table_name = t.table_name) as column_count
                    FROM information_schema.tables t
                    WHERE table_schema = 'public'
                    ORDER BY table_name
                """)
                
                tables = cursor.fetchall()
                
                return {
                    "tables": [
                        {
                            "name": table["table_name"],
                            "column_count": table["column_count"]
                        }
                        for table in tables
                    ],
                    "total_tables": len(tables)
                }
    except Exception as e:
        logger.error(f"åˆ—å‡ºè¡¨å¤±è´¥: {e}")
        return {"error": f"åˆ—å‡ºè¡¨å¤±è´¥: {str(e)}"}
```

**å®é™…åº”ç”¨æ¡ˆä¾‹**ï¼š
```
AIè°ƒç”¨åœºæ™¯ï¼š
ç”¨æˆ·é—®é¢˜ï¼š"å¸®æˆ‘åˆ†æä¸€ä¸‹æ•°æ®åº“ä¸­çš„è´¢åŠ¡æ•°æ®"
AIå·¥å…·è°ƒç”¨ï¼šlist_tables()
è¿”å›ç»“æœï¼š
{
    "tables": [
        {"name": "asset_snapshot", "column_count": 8},
        {"name": "transaction_history", "column_count": 12},
        {"name": "portfolio_summary", "column_count": 6}
    ],
    "total_tables": 3
}
AIåˆ†æï¼šå‘ç°æ•°æ®åº“æœ‰3ä¸ªè¡¨ï¼Œasset_snapshotè¡¨åŒ…å«8ä¸ªå­—æ®µï¼Œå¯èƒ½æ˜¯ä¸»è¦çš„èµ„äº§æ•°æ®è¡¨
```

**å·¥å…·ä¼˜åŠ¿**ï¼š
âœ… **å…ƒæ•°æ®è·å–**ï¼šå¿«é€Ÿäº†è§£æ•°æ®åº“ç»“æ„
âœ… **å­—æ®µç»Ÿè®¡**ï¼šå¸®åŠ©AIç†è§£è¡¨çš„æ•°æ®å¤æ‚åº¦
âœ… **é”™è¯¯å¤„ç†**ï¼šè¿æ¥å¤±è´¥æ—¶è¿”å›æ˜ç¡®çš„é”™è¯¯ä¿¡æ¯

#### 3.2.2 get_table_schema - è¡¨ç»“æ„åˆ†æå·¥å…·
**åŠŸèƒ½è¯¦è§£**ï¼š
- **ä¸»è¦ç”¨é€”**ï¼šè®©AIæ·±å…¥äº†è§£ç‰¹å®šè¡¨çš„ç»“æ„ï¼ŒåŒ…æ‹¬å­—æ®µç±»å‹ã€çº¦æŸç­‰
- **æ‰§è¡Œé€»è¾‘**ï¼šæŸ¥è¯¢PostgreSQLçš„ç³»ç»Ÿè¡¨è·å–è¯¦ç»†çš„å­—æ®µä¿¡æ¯
- **è¿”å›æ•°æ®**ï¼šå­—æ®µåã€æ•°æ®ç±»å‹ã€æ˜¯å¦å¯ç©ºã€é»˜è®¤å€¼ã€ç²¾åº¦ç­‰

**å…·ä½“å®ç°ä»£ç **ï¼š
```python
def _get_table_schema(self, table_name: str) -> Dict[str, Any]:
    """è·å–è¡¨ç»“æ„"""
    try:
        with psycopg2.connect(**self.db_config) as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                # è·å–å­—æ®µä¿¡æ¯
                cursor.execute("""
                    SELECT column_name, data_type, is_nullable, column_default, 
                           character_maximum_length, numeric_precision, numeric_scale
                    FROM information_schema.columns 
                    WHERE table_name = %s 
                    ORDER BY ordinal_position
                """, (table_name,))
                
                columns = cursor.fetchall()
                
                # è·å–è¡¨æè¿°
                cursor.execute("""
                    SELECT obj_description(c.oid) as table_comment
                    FROM pg_class c
                    JOIN pg_namespace n ON n.oid = c.relnamespace
                    WHERE c.relname = %s AND n.nspname = 'public'
                """, (table_name,))
                
                table_comment = cursor.fetchone()
                
                return {
                    "table_name": table_name,
                    "table_comment": table_comment["table_comment"] if table_comment else None,
                    "columns": [
                        {
                            "name": col["column_name"],
                            "type": col["data_type"],
                            "nullable": col["is_nullable"] == "YES",
                            "default": col["column_default"],
                            "max_length": col["character_maximum_length"],
                            "precision": col["numeric_precision"],
                            "scale": col["numeric_scale"]
                        }
                        for col in columns
                    ],
                    "total_columns": len(columns)
                }
    except Exception as e:
        logger.error(f"è·å–è¡¨ç»“æ„å¤±è´¥: {e}")
        return {"error": f"è·å–è¡¨ç»“æ„å¤±è´¥: {str(e)}"}
```

**å®é™…åº”ç”¨æ¡ˆä¾‹**ï¼š
```
AIè°ƒç”¨åœºæ™¯ï¼š
ç”¨æˆ·é—®é¢˜ï¼š"å¸®æˆ‘æŸ¥è¯¢æ”¯ä»˜å®å¹³å°çš„åŸºé‡‘èµ„äº§"
AIå·¥å…·è°ƒç”¨ï¼šget_table_schema("asset_snapshot")
è¿”å›ç»“æœï¼š
{
    "table_name": "asset_snapshot",
    "columns": [
        {"name": "platform", "type": "character varying", "nullable": false},
        {"name": "asset_type", "type": "character varying", "nullable": false},
        {"name": "balance_cny", "type": "numeric", "precision": 15, "scale": 2},
        {"name": "snapshot_time", "type": "timestamp without time zone", "nullable": false}
    ]
}
AIåˆ†æï¼šå‘ç°platformå­—æ®µç”¨äºåŒºåˆ†å¹³å°ï¼Œasset_typeå­—æ®µç”¨äºåŒºåˆ†èµ„äº§ç±»å‹ï¼Œ
        balance_cnyå­—æ®µå­˜å‚¨äººæ°‘å¸ä½™é¢ï¼Œsnapshot_timeå­—æ®µè®°å½•å¿«ç…§æ—¶é—´
AIç”ŸæˆSQLï¼šSELECT * FROM asset_snapshot WHERE platform='æ”¯ä»˜å®' AND asset_type='åŸºé‡‘'
```

**å·¥å…·ä¼˜åŠ¿**ï¼š
âœ… **è¯¦ç»†ç»“æ„ä¿¡æ¯**ï¼šå®Œæ•´çš„å­—æ®µç±»å‹å’Œçº¦æŸä¿¡æ¯
âœ… **å…ƒæ•°æ®æ”¯æŒ**ï¼šåŒ…å«è¡¨æ³¨é‡Šå’Œå­—æ®µæè¿°
âœ… **ç±»å‹å®‰å…¨**ï¼šå¸®åŠ©AIç”Ÿæˆæ­£ç¡®çš„SQLæŸ¥è¯¢

#### 3.2.3 explore_table_data - æ•°æ®æ ·æœ¬æ¢ç´¢å·¥å…·
**åŠŸèƒ½è¯¦è§£**ï¼š
- **ä¸»è¦ç”¨é€”**ï¼šè®©AIäº†è§£è¡¨ä¸­çš„å®é™…æ•°æ®å†…å®¹å’Œåˆ†å¸ƒ
- **æ‰§è¡Œé€»è¾‘**ï¼šè·å–æ ·æœ¬æ•°æ®ã€ç»Ÿè®¡ä¿¡æ¯ã€å­—æ®µç±»å‹ç­‰
- **è¿”å›æ•°æ®**ï¼šæ ·æœ¬æ•°æ®ã€æ€»è¡Œæ•°ã€å­—æ®µä¿¡æ¯ã€æ•°æ®åˆ†å¸ƒ

**å…·ä½“å®ç°ä»£ç **ï¼š
```python
def _explore_table_data(self, table_name: str, sample_size: int = 5) -> Dict[str, Any]:
    """æ¢ç´¢è¡¨æ•°æ®æ ·æœ¬"""
    try:
        with psycopg2.connect(**self.db_config) as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                # è·å–æ ·æœ¬æ•°æ®
                cursor.execute(f"SELECT * FROM {table_name} LIMIT {sample_size}")
                sample_rows = cursor.fetchall()
                
                # è·å–æ€»è¡Œæ•°
                cursor.execute(f"SELECT COUNT(*) as total_count FROM {table_name}")
                total_count = cursor.fetchone()["total_count"]
                
                # è·å–å­—æ®µä¿¡æ¯
                cursor.execute("""
                    SELECT column_name, data_type
                    FROM information_schema.columns 
                    WHERE table_name = %s 
                    ORDER BY ordinal_position
                """, (table_name,))
                
                columns = cursor.fetchall()
                
                return {
                    "table_name": table_name,
                    "total_rows": total_count,
                    "sample_size": sample_size,
                    "columns": [{"name": col["column_name"], "type": col["data_type"]} for col in columns],
                    "sample_data": [dict(row) for row in sample_rows]
                }
    except Exception as e:
        logger.error(f"æ¢ç´¢è¡¨æ•°æ®å¤±è´¥: {e}")
        return {"error": f"æ¢ç´¢è¡¨æ•°æ®å¤±è´¥: {str(e)}"}
```

**å®é™…åº”ç”¨æ¡ˆä¾‹**ï¼š
```
AIè°ƒç”¨åœºæ™¯ï¼š
ç”¨æˆ·é—®é¢˜ï¼š"å¸®æˆ‘åˆ†æä¸€ä¸‹èµ„äº§æ•°æ®çš„åˆ†å¸ƒæƒ…å†µ"
AIå·¥å…·è°ƒç”¨ï¼šexplore_table_data("asset_snapshot", 10)
è¿”å›ç»“æœï¼š
{
    "table_name": "asset_snapshot",
    "total_rows": 156,
    "sample_size": 10,
    "sample_data": [
        {"platform": "æ”¯ä»˜å®", "asset_type": "åŸºé‡‘", "balance_cny": 85230.45},
        {"platform": "Wise", "asset_type": "å¤–æ±‡", "balance_cny": 6458.23},
        {"platform": "IBKR", "asset_type": "è‚¡ç¥¨", "balance_cny": 42.03}
    ]
}
AIåˆ†æï¼šå‘ç°æ•°æ®åŒ…å«å¤šä¸ªå¹³å°ï¼ˆæ”¯ä»˜å®ã€Wiseã€IBKRï¼‰ï¼Œ
       å¤šç§èµ„äº§ç±»å‹ï¼ˆåŸºé‡‘ã€å¤–æ±‡ã€è‚¡ç¥¨ï¼‰ï¼Œ
       ä½™é¢èŒƒå›´ä»42.03åˆ°85230.45ï¼Œæ•°æ®åˆ†å¸ƒè¾ƒå¹¿
AIç”ŸæˆSQLï¼šSELECT platform, asset_type, AVG(balance_cny) as avg_balance 
           FROM asset_snapshot GROUP BY platform, asset_type
```

**å·¥å…·ä¼˜åŠ¿**ï¼š
âœ… **æ•°æ®æ´å¯Ÿ**ï¼šäº†è§£å®é™…æ•°æ®å†…å®¹å’Œåˆ†å¸ƒ
âœ… **æ ·æœ¬åˆ†æ**ï¼šé¿å…å…¨è¡¨æ‰«æï¼Œæé«˜æ€§èƒ½
âœ… **ç»Ÿè®¡ä¿¡æ¯**ï¼šæä¾›æ€»è¡Œæ•°ç­‰å…ƒæ•°æ®

#### 3.2.4 query_database - SQLæ‰§è¡Œå·¥å…·
**åŠŸèƒ½è¯¦è§£**ï¼š
- **ä¸»è¦ç”¨é€”**ï¼šæ‰§è¡ŒAIç”Ÿæˆçš„SQLæŸ¥è¯¢å¹¶è¿”å›ç»“æœ
- **æ‰§è¡Œé€»è¾‘**ï¼šè¿æ¥æ•°æ®åº“ã€æ‰§è¡ŒSQLã€è¿”å›ç»“æœé›†
- **è¿”å›æ•°æ®**ï¼šæŸ¥è¯¢ç»“æœã€æ‰§è¡ŒçŠ¶æ€ã€è¡Œæ•°ç»Ÿè®¡ã€æ‰§è¡Œæ—¶é—´

**å…·ä½“å®ç°ä»£ç **ï¼š
```python
def _query_database(self, sql: str, max_rows: int = 1000) -> Dict[str, Any]:
    """æ‰§è¡ŒSQLæŸ¥è¯¢"""
    try:
        with psycopg2.connect(**self.db_config) as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                # æ·»åŠ LIMITå­å¥é˜²æ­¢è¿”å›è¿‡å¤šæ•°æ®
                if "LIMIT" not in sql.upper():
                    sql = f"{sql} LIMIT {max_rows}"
                
                cursor.execute(sql)
                rows = cursor.fetchall()
                
                # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
                result = [dict(row) for row in rows]
                
                return {
                    "success": True,
                    "sql": sql,
                    "data": result,
                    "row_count": len(result),
                    "max_rows": max_rows
                }
    except Exception as e:
        logger.error(f"SQLæŸ¥è¯¢å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e),
            "sql": sql
        }
```

**å®é™…åº”ç”¨æ¡ˆä¾‹**ï¼š
```
AIè°ƒç”¨åœºæ™¯ï¼š
ç”¨æˆ·é—®é¢˜ï¼š"å¸®æˆ‘æŸ¥è¯¢æ”¯ä»˜å®å¹³å°çš„æ€»èµ„äº§"
AIå·¥å…·è°ƒç”¨ï¼šquery_database("SELECT platform, SUM(balance_cny) as total_assets FROM asset_snapshot WHERE platform='æ”¯ä»˜å®' GROUP BY platform")
è¿”å›ç»“æœï¼š
{
    "success": true,
    "sql": "SELECT platform, SUM(balance_cny) as total_assets FROM asset_snapshot WHERE platform='æ”¯ä»˜å®' GROUP BY platform LIMIT 1000",
    "data": [{"platform": "æ”¯ä»˜å®", "total_assets": 158460.30}],
    "row_count": 1,
    "max_rows": 1000
}
```

**å·¥å…·ä¼˜åŠ¿**ï¼š
âœ… **å®‰å…¨æ‰§è¡Œ**ï¼šè‡ªåŠ¨æ·»åŠ LIMITå­å¥é˜²æ­¢æ•°æ®æ³„éœ²
âœ… **é”™è¯¯å¤„ç†**ï¼šè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’ŒSQLè¯­å¥è®°å½•
âœ… **ç»“æœæ ¼å¼åŒ–**ï¼šç»Ÿä¸€çš„è¿”å›æ ¼å¼ï¼Œä¾¿äºAIå¤„ç†
âœ… **æ€§èƒ½æ§åˆ¶**ï¼šå¯é…ç½®çš„æœ€å¤§è¡Œæ•°é™åˆ¶

### 3.3 å·¥å…·é›†æ•´ä½“ä¼˜åŠ¿åˆ†æ

#### 3.3.1 è®¾è®¡ä¼˜åŠ¿
âœ… **æ ‡å‡†åŒ–æ¥å£**ï¼šæ‰€æœ‰å·¥å…·éµå¾ªç»Ÿä¸€çš„è°ƒç”¨å’Œæ‰§è¡Œæ¨¡å¼
âœ… **ç±»å‹å®‰å…¨**ï¼šå®Œæ•´çš„å‚æ•°éªŒè¯å’Œç±»å‹æ£€æŸ¥
âœ… **é”™è¯¯éš”ç¦»**ï¼šå•ä¸ªå·¥å…·å¤±è´¥ä¸å½±å“æ•´ä½“åŠŸèƒ½
âœ… **æ˜“äºæ‰©å±•**ï¼šæ–°å¢å·¥å…·åªéœ€å®ç°ç›¸åº”æ–¹æ³•

#### 3.3.2 æ€§èƒ½ä¼˜åŠ¿
âœ… **è¿æ¥æ± ç®¡ç†**ï¼šæ¯æ¬¡è°ƒç”¨éƒ½åˆ›å»ºæ–°è¿æ¥ï¼Œé¿å…è¿æ¥æ³„æ¼
âœ… **æŸ¥è¯¢ä¼˜åŒ–**ï¼šè‡ªåŠ¨æ·»åŠ LIMITå­å¥ï¼Œæ§åˆ¶è¿”å›æ•°æ®é‡
âœ… **å¼‚æ­¥æ”¯æŒ**ï¼šæ”¯æŒå¼‚æ­¥æ‰§è¡Œï¼Œæé«˜å¹¶å‘æ€§èƒ½

#### 3.3.3 å®‰å…¨ä¼˜åŠ¿
âœ… **å‚æ•°åŒ–æŸ¥è¯¢**ï¼šé¿å…SQLæ³¨å…¥æ”»å‡»
âœ… **æƒé™æ§åˆ¶**ï¼šä½¿ç”¨ä¸“ç”¨æ•°æ®åº“ç”¨æˆ·
âœ… **æ•°æ®é™åˆ¶**ï¼šå¯é…ç½®çš„æœ€å¤§è¿”å›è¡Œæ•°
âœ… **é”™è¯¯ä¿¡æ¯**ï¼šä¸æš´éœ²æ•æ„Ÿçš„ç³»ç»Ÿä¿¡æ¯

---

## ç¬¬å››éƒ¨åˆ†ï¼šAIæœåŠ¡é›†æˆåˆ†æ

### 4.1 åŒAIæ¨¡å‹æ¶æ„æ·±åº¦åˆ†æ

#### 4.1.1 æ¶æ„è®¾è®¡ç†å¿µ
**è®¾è®¡ç›®æ ‡**ï¼š
- **é«˜å¯ç”¨æ€§**ï¼šå•ä¸ªAIæœåŠ¡æ•…éšœä¸å½±å“æ•´ä½“åŠŸèƒ½
- **æ€§èƒ½ä¼˜åŒ–**ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚çš„æ¨¡å‹
- **æˆæœ¬æ§åˆ¶**ï¼šå¹³è¡¡AIèƒ½åŠ›å’ŒAPIè°ƒç”¨æˆæœ¬
- **ç”¨æˆ·ä½“éªŒ**ï¼šå§‹ç»ˆæä¾›æ™ºèƒ½åŒ–çš„æ•°æ®æŸ¥è¯¢æœåŠ¡

**æ¶æ„ä¼˜åŠ¿åˆ†æ**ï¼š
âœ… **é£é™©åˆ†æ•£**ï¼šé¿å…å•ç‚¹æ•…éšœï¼Œæé«˜ç³»ç»Ÿç¨³å®šæ€§
âœ… **æ™ºèƒ½é€‰æ‹©**ï¼šæ ¹æ®é…ç½®å’Œå¯ç”¨æ€§è‡ªåŠ¨é€‰æ‹©æœ€ä½³AIæœåŠ¡
âœ… **æ¸è¿›é™çº§**ï¼šä»é«˜çº§AIèƒ½åŠ›é€æ­¥é™çº§åˆ°åŸºç¡€åŠŸèƒ½
âœ… **æˆæœ¬ä¼˜åŒ–**ï¼šClaudeå¤„ç†å¤æ‚ä»»åŠ¡ï¼ŒDeepSeekå¤„ç†ç®€å•æŸ¥è¯¢

#### 4.1.2 æ¨¡å‹é€‰æ‹©ç­–ç•¥
**é€‰æ‹©é€»è¾‘è¯¦è§£**ï¼š
```python
def _select_ai_service(self, ai_service: str = "auto") -> str:
    """æ™ºèƒ½é€‰æ‹©AIæœåŠ¡"""
    if ai_service == "auto":
        # ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šClaudeï¼ˆå¦‚æœé…ç½®äº†API keyä¸”å¯ç”¨ï¼‰
        if (self.claude_ai and 
            hasattr(self.claude_ai, 'api_key') and 
            self.claude_ai.api_key and
            await self._test_claude_availability()):
            ai_service = "claude"
            logger.info("ğŸ” è‡ªåŠ¨é€‰æ‹©Claude AIæœåŠ¡")
        else:
            # ç¬¬äºŒä¼˜å…ˆçº§ï¼šDeepSeekï¼ˆä½œä¸ºå¤‡ç”¨æœåŠ¡ï¼‰
            ai_service = "deepseek"
            logger.info("ğŸ” è‡ªåŠ¨é€‰æ‹©DeepSeek AIæœåŠ¡")
    
    return ai_service

async def _test_claude_availability(self) -> bool:
    """æµ‹è¯•ClaudeæœåŠ¡å¯ç”¨æ€§"""
    try:
        # ç®€å•çš„å¥åº·æ£€æŸ¥
        response = await self.claude_ai.health_check()
        return response.get("status") == "healthy"
    except Exception as e:
        logger.warning(f"ClaudeæœåŠ¡ä¸å¯ç”¨: {e}")
        return False
```

**å®é™…åº”ç”¨åœºæ™¯å¯¹æ¯”**ï¼š
```
åœºæ™¯1ï¼šå¤æ‚è´¢åŠ¡åˆ†ææŸ¥è¯¢
ç”¨æˆ·é—®é¢˜ï¼š"å¸®æˆ‘åˆ†æä¸€ä¸‹å„å¹³å°èµ„äº§çš„å†å²å˜åŒ–è¶‹åŠ¿ï¼Œå¹¶é¢„æµ‹æœªæ¥3ä¸ªæœˆçš„å¯èƒ½èµ°åŠ¿"
Claudeå¤„ç†ï¼šè°ƒç”¨MCPå·¥å…·è·å–å†å²æ•°æ®ï¼Œè¿›è¡Œæ—¶é—´åºåˆ—åˆ†æï¼Œç”Ÿæˆé¢„æµ‹æ¨¡å‹
DeepSeekå¤„ç†ï¼šä½¿ç”¨é¢„å®šä¹‰æ¨¡æ¿ï¼Œæä¾›åŸºç¡€çš„è¶‹åŠ¿åˆ†æ

åœºæ™¯2ï¼šç®€å•æ•°æ®æŸ¥è¯¢
ç”¨æˆ·é—®é¢˜ï¼š"æ”¯ä»˜å®å¹³å°æœ‰å¤šå°‘èµ„äº§ï¼Ÿ"
Claudeå¤„ç†ï¼šè°ƒç”¨MCPå·¥å…·ï¼Œç”Ÿæˆç²¾ç¡®æŸ¥è¯¢SQL
DeepSeekå¤„ç†ï¼šå¿«é€Ÿå“åº”ï¼Œç”Ÿæˆç®€å•æŸ¥è¯¢SQL

ç»“æœå¯¹æ¯”ï¼šClaudeæä¾›æ›´æ·±å…¥çš„åˆ†æï¼ŒDeepSeekæä¾›æ›´å¿«çš„å“åº”
```

### 4.2 Claude AIæœåŠ¡æ·±åº¦åˆ†æ

#### 4.2.1 MCPå·¥å…·è°ƒç”¨èƒ½åŠ›
**å·¥å…·è°ƒç”¨æµç¨‹**ï¼š
```python
class ClaudeAIService:
    def analyze_with_tools(self, question: str) -> Dict[str, Any]:
        """ä½¿ç”¨å·¥å…·åˆ†æé—®é¢˜"""
        try:
            # 1. æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = self._build_system_prompt()
            
            # 2. æ„å»ºæ¶ˆæ¯
            messages = [{"role": "user", "content": question}]
            
            # 3. æ„å»ºè¯·æ±‚ä½“ï¼ˆåŒ…å«å·¥å…·å®šä¹‰ï¼‰
            request_body = {
                "model": self.model,
                "max_tokens": self.max_tokens,
                "system": system_prompt,
                "messages": messages,
                "tools": self.tools  # MCPå·¥å…·å®šä¹‰
            }
            
            # 4. å‘é€APIè¯·æ±‚
            response = self._send_request(request_body)
            
            # 5. å¤„ç†å·¥å…·è°ƒç”¨ç»“æœ
            return self._process_tool_calls(response, question)
            
        except Exception as e:
            logger.error(f"Claude AIåˆ†æå¤±è´¥: {e}")
            return {"error": f"AIåˆ†æå¤±è´¥: {str(e)}"}
```

**ç³»ç»Ÿæç¤ºè¯æ„å»º**ï¼š
```python
def _build_system_prompt(self) -> str:
    """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
    return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è´¢åŠ¡æ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿ä½¿ç”¨æ•°æ®åº“å·¥å…·åˆ†æè´¢åŠ¡æ•°æ®ã€‚

## å¯ç”¨å·¥å…·
ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ä»¥ä½¿ç”¨ï¼š

{json.dumps(self.tools, ensure_ascii=False, indent=2)}

## å·¥ä½œæµç¨‹
1. é¦–å…ˆäº†è§£ç”¨æˆ·éœ€æ±‚
2. ä½¿ç”¨ list_tables æŸ¥çœ‹å¯ç”¨çš„è¡¨
3. ä½¿ç”¨ get_table_schema äº†è§£è¡¨ç»“æ„
4. ä½¿ç”¨ explore_table_data æŸ¥çœ‹æ•°æ®æ ·æœ¬
5. æœ€åä½¿ç”¨ query_database æ‰§è¡ŒæŸ¥è¯¢

## é‡è¦åŸåˆ™
- æ€»æ˜¯å…ˆäº†è§£æ•°æ®ç»“æ„ï¼Œå†ç”ŸæˆæŸ¥è¯¢
- ä½¿ç”¨æ­£ç¡®çš„å­—æ®µåå’Œè¡¨å
- ç”Ÿæˆå¯æ‰§è¡Œçš„SQLè¯­å¥
- è€ƒè™‘æŸ¥è¯¢æ€§èƒ½ï¼Œé¿å…å…¨è¡¨æ‰«æ
"""
```

**å·¥å…·è°ƒç”¨ç»“æœå¤„ç†**ï¼š
```python
def _process_tool_calls(self, result: Dict[str, Any], original_question: str) -> Dict[str, Any]:
    """å¤„ç†å·¥å…·è°ƒç”¨ç»“æœ"""
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if "content" in result and isinstance(result["content"], list):
            for content_item in result["content"]:
                if content_item.get("type") == "tool_use":
                    tool_call = content_item
                    
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    tool_name = tool_call["name"]
                    tool_args = tool_call["input"]
                    
                    # è°ƒç”¨MCPå·¥å…·
                    tool_result = self.mcp_tools.execute_tool(tool_name, tool_args)
                    
                    # å°†å·¥å…·ç»“æœè¿”å›ç»™Claudeè¿›è¡Œè¿›ä¸€æ­¥åˆ†æ
                    return self._continue_analysis_with_tool_result(
                        original_question, tool_result
                    )
        
        # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›ç»“æœ
        return {"response": result.get("content", "æ— å“åº”")}
        
    except Exception as e:
        logger.error(f"å¤„ç†å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
        return {"error": f"å·¥å…·è°ƒç”¨å¤„ç†å¤±è´¥: {str(e)}"}
```

#### 4.2.2 é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
**é‡è¯•ç­–ç•¥è®¾è®¡**ï¼š
```python
async def _send_request_with_retry(self, request_body: Dict[str, Any], max_retries: int = 3) -> Dict[str, Any]:
    """å¸¦é‡è¯•çš„APIè¯·æ±‚"""
    for attempt in range(max_retries):
        try:
            response = await self._send_request(request_body)
            return response
        except httpx.TimeoutException:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                logger.warning(f"Claude APIè¶…æ—¶ï¼Œ{wait_time}ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})")
                await asyncio.sleep(wait_time)
            else:
                raise
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 429:  # é€Ÿç‡é™åˆ¶
                if attempt < max_retries - 1:
                    wait_time = 60  # ç­‰å¾…1åˆ†é’Ÿ
                    logger.warning(f"Claude APIé€Ÿç‡é™åˆ¶ï¼Œ{wait_time}ç§’åé‡è¯•")
                    await asyncio.sleep(wait_time)
                else:
                    raise
            else:
                raise
```

**é”™è¯¯åˆ†ç±»å’Œå¤„ç†**ï¼š
```python
def _handle_api_error(self, response: httpx.Response) -> Dict[str, Any]:
    """å¤„ç†APIé”™è¯¯"""
    error_mapping = {
        400: "è¯·æ±‚å‚æ•°é”™è¯¯ï¼Œè¯·æ£€æŸ¥è¾“å…¥",
        401: "APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®",
        403: "è®¿é—®è¢«æ‹’ç»ï¼Œè¯·æ£€æŸ¥æƒé™",
        429: "è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åé‡è¯•",
        500: "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•",
        502: "ç½‘å…³é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•",
        503: "æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
    }
    
    error_msg = error_mapping.get(response.status_code, f"æœªçŸ¥é”™è¯¯: {response.status_code}")
    logger.error(f"Claude APIé”™è¯¯: {response.status_code} - {error_msg}")
    
    return {
        "error": error_msg,
        "status_code": response.status_code,
        "details": response.text
    }
```

### 4.3 DeepSeek AIæœåŠ¡æ·±åº¦åˆ†æ

#### 4.3.1 è´¢åŠ¡é—®é¢˜ä¸“ä¸šåˆ†æèƒ½åŠ›
**ä¸“ä¸šé¢†åŸŸçŸ¥è¯†**ï¼š
- **è´¢åŠ¡æœ¯è¯­ç†è§£**ï¼šå‡†ç¡®ç†è§£"èµ„äº§é…ç½®"ã€"é£é™©åˆ†æ•£"ã€"æ”¶ç›Šç‡"ç­‰ä¸“ä¸šæ¦‚å¿µ
- **æ•°æ®åˆ†ææ–¹æ³•**ï¼šæŒæ¡æ—¶é—´åºåˆ—åˆ†æã€ç»Ÿè®¡åˆ†æã€è¶‹åŠ¿é¢„æµ‹ç­‰æ–¹æ³•
- **ä¸šåŠ¡é€»è¾‘ç†è§£**ï¼šäº†è§£ä¸åŒé‡‘èäº§å“çš„ç‰¹ç‚¹å’Œé£é™©ç‰¹å¾

**SQLç”Ÿæˆä¼˜åŒ–**ï¼š
```python
class DeepSeekAIService:
    def analyze_financial_question(self, question: str) -> Dict[str, Any]:
        """åˆ†æè´¢åŠ¡é—®é¢˜å¹¶ç”ŸæˆSQL"""
        try:
            # 1. é—®é¢˜åˆ†ç±»
            question_type = self._classify_question(question)
            
            # 2. æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©åˆ†ææ–¹æ³•
            if question_type == "distribution":
                return self._analyze_distribution(question)
            elif question_type == "trend":
                return self._analyze_trend(question)
            elif question_type == "comparison":
                return self._analyze_comparison(question)
            else:
                return self._analyze_general(question)
                
        except Exception as e:
            logger.error(f"DeepSeekåˆ†æå¤±è´¥: {e}")
            return {"error": f"åˆ†æå¤±è´¥: {str(e)}"}
    
    def _classify_question(self, question: str) -> str:
        """é—®é¢˜åˆ†ç±»"""
        question_lower = question.lower()
        
        if any(word in question_lower for word in ['åˆ†å¸ƒ', 'å æ¯”', 'æ¯”ä¾‹', 'åˆ†å¸ƒ']):
            return "distribution"
        elif any(word in question_lower for word in ['è¶‹åŠ¿', 'å˜åŒ–', 'èµ°åŠ¿', 'å†å²']):
            return "trend"
        elif any(word in question_lower for word in ['å¯¹æ¯”', 'æ¯”è¾ƒ', 'å·®å¼‚']):
            return "comparison"
        else:
            return "general"
```

#### 4.3.2 æ•°æ®åº“ç»“æ„ç†è§£èƒ½åŠ›
**è¡¨å…³ç³»åˆ†æ**ï¼š
```python
def _analyze_table_relationships(self, tables: List[str]) -> Dict[str, Any]:
    """åˆ†æè¡¨ä¹‹é—´çš„å…³ç³»"""
    relationships = {}
    
    for table in tables:
        # è·å–è¡¨ç»“æ„
        schema = self._get_table_schema(table)
        
        # åˆ†æå¤–é”®å…³ç³»
        foreign_keys = self._get_foreign_keys(table)
        
        # åˆ†æç´¢å¼•ä¿¡æ¯
        indexes = self._get_table_indexes(table)
        
        relationships[table] = {
            "schema": schema,
            "foreign_keys": foreign_keys,
            "indexes": indexes,
            "estimated_rows": self._estimate_table_size(table)
        }
    
    return relationships

def _get_foreign_keys(self, table_name: str) -> List[Dict[str, Any]]:
    """è·å–è¡¨çš„å¤–é”®ä¿¡æ¯"""
    query = """
        SELECT 
            tc.constraint_name,
            tc.table_name,
            kcu.column_name,
            ccu.table_name AS foreign_table_name,
            ccu.column_name AS foreign_column_name
        FROM information_schema.table_constraints AS tc
        JOIN information_schema.key_column_usage AS kcu
            ON tc.constraint_name = kcu.constraint_name
        JOIN information_schema.constraint_column_usage AS ccu
            ON ccu.constraint_name = tc.constraint_name
        WHERE tc.constraint_type = 'FOREIGN KEY' 
            AND tc.table_name = %s
    """
    
    # æ‰§è¡ŒæŸ¥è¯¢å¹¶è¿”å›ç»“æœ
    return self._execute_query(query, (table_name,))
```

#### 4.3.3 æŸ¥è¯¢æ¨¡æ¿åŒ¹é…ç³»ç»Ÿ
**æ™ºèƒ½æ¨¡æ¿é€‰æ‹©**ï¼š
```python
def _select_best_template(self, question: str, question_type: str) -> Dict[str, Any]:
    """é€‰æ‹©æœ€ä½³æŸ¥è¯¢æ¨¡æ¿"""
    available_templates = self.templates.get(question_type, [])
    
    if not available_templates:
        return None
    
    # è®¡ç®—é—®é¢˜ä¸æ¨¡æ¿çš„åŒ¹é…åº¦
    best_match = None
    best_score = 0
    
    for template in available_templates:
        score = self._calculate_similarity(question, template["keywords"])
        if score > best_score:
            best_score = score
            best_match = template
    
    # å¦‚æœåŒ¹é…åº¦å¤ªä½ï¼Œè¿”å›None
    if best_score < 0.6:
        return None
    
    return best_match

def _calculate_similarity(self, question: str, keywords: List[str]) -> float:
    """è®¡ç®—é—®é¢˜ä¸å…³é”®è¯çš„ç›¸ä¼¼åº¦"""
    question_words = set(question.lower().split())
    keyword_words = set()
    
    for keyword in keywords:
        keyword_words.update(keyword.lower().split())
    
    if not keyword_words:
        return 0.0
    
    intersection = question_words.intersection(keyword_words)
    union = question_words.union(keyword_words)
    
    return len(intersection) / len(union) if union else 0.0
```

### 4.4 AIæœåŠ¡é›†æˆä¼˜åŠ¿æ€»ç»“

#### 4.4.1 æŠ€æœ¯ä¼˜åŠ¿
âœ… **æ™ºèƒ½é™çº§**ï¼šä»é«˜çº§AIèƒ½åŠ›é€æ­¥é™çº§åˆ°åŸºç¡€åŠŸèƒ½
âœ… **æ€§èƒ½ä¼˜åŒ–**ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚çš„æ¨¡å‹
âœ… **æˆæœ¬æ§åˆ¶**ï¼šå¹³è¡¡AIèƒ½åŠ›å’ŒAPIè°ƒç”¨æˆæœ¬
âœ… **é”™è¯¯éš”ç¦»**ï¼šå•ä¸ªAIæœåŠ¡æ•…éšœä¸å½±å“æ•´ä½“åŠŸèƒ½

#### 4.4.2 ä¸šåŠ¡ä¼˜åŠ¿
âœ… **ç”¨æˆ·ä½“éªŒ**ï¼šå§‹ç»ˆæä¾›æ™ºèƒ½åŒ–çš„æ•°æ®æŸ¥è¯¢æœåŠ¡
âœ… **åˆ†ææ·±åº¦**ï¼šClaudeæä¾›æ·±åº¦åˆ†æï¼ŒDeepSeekæä¾›å¿«é€Ÿå“åº”
âœ… **å¯ç”¨æ€§**ï¼šå³ä½¿AIæœåŠ¡æ•…éšœï¼Œä»èƒ½æä¾›åŸºæœ¬åŠŸèƒ½
âœ… **æ‰©å±•æ€§**ï¼šæ˜“äºé›†æˆæ–°çš„AIæ¨¡å‹å’ŒæœåŠ¡

#### 4.4.3 è¿ç»´ä¼˜åŠ¿
âœ… **ç›‘æ§å‹å¥½**ï¼šæ¯ä¸ªAIæœåŠ¡éƒ½æœ‰ç‹¬ç«‹çš„å¥åº·æ£€æŸ¥
âœ… **æ•…éšœå®šä½**ï¼šé€šè¿‡æ—¥å¿—å¯ä»¥æ¸…æ¥šçŸ¥é“ä½¿ç”¨äº†å“ªä¸ªAIæœåŠ¡
âœ… **é…ç½®çµæ´»**ï¼šå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶AIæœåŠ¡çš„ä½¿ç”¨
âœ… **æˆæœ¬é€æ˜**ï¼šå¯ä»¥ç›‘æ§æ¯ä¸ªAIæœåŠ¡çš„è°ƒç”¨æ¬¡æ•°å’Œæˆæœ¬

---

## ç¬¬äº”éƒ¨åˆ†ï¼šå®‰å…¨æ€§åˆ†æ

### 5.1 å®‰å…¨é˜²æŠ¤æªæ–½æ·±åº¦åˆ†æ

#### 5.1.1 SQLæ³¨å…¥é˜²æŠ¤æœºåˆ¶
**å·²å®ç°çš„å®‰å…¨æªæ–½**ï¼š
âœ… **å‚æ•°åŒ–æŸ¥è¯¢**ï¼šä½¿ç”¨psycopg2çš„å‚æ•°åŒ–æŸ¥è¯¢ï¼Œé¿å…SQLæ³¨å…¥
âœ… **è¾“å…¥éªŒè¯**ï¼šå¯¹ç”¨æˆ·è¾“å…¥è¿›è¡Œç±»å‹æ£€æŸ¥å’Œé•¿åº¦é™åˆ¶
âœ… **é”™è¯¯å¤„ç†**ï¼šä¸æš´éœ²æ•°æ®åº“é”™è¯¯ä¿¡æ¯ç»™ç”¨æˆ·

**å…·ä½“å®ç°ä»£ç **ï¼š
```python
def _query_database(self, sql: str, max_rows: int = 1000) -> Dict[str, Any]:
    """æ‰§è¡ŒSQLæŸ¥è¯¢ - å®‰å…¨ç‰ˆæœ¬"""
    try:
        # 1. è¾“å…¥éªŒè¯
        if not self._validate_sql_input(sql):
            return {"error": "SQLè¾“å…¥éªŒè¯å¤±è´¥", "success": False}
        
        # 2. å®‰å…¨æ£€æŸ¥
        if not self._security_check(sql):
            return {"error": "SQLå®‰å…¨æ£€æŸ¥å¤±è´¥", "success": False}
        
        # 3. æ‰§è¡ŒæŸ¥è¯¢
        with psycopg2.connect(**self.db_config) as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                # æ³¨æ„ï¼šè¿™é‡Œä»ç„¶å­˜åœ¨é£é™©ï¼Œå› ä¸ºsqlæ˜¯AIç”Ÿæˆçš„
                cursor.execute(sql)
                rows = cursor.fetchall()
                
                return {
                    "success": True,
                    "data": [dict(row) for row in rows],
                    "row_count": len(rows)
                }
    except Exception as e:
        logger.error(f"SQLæŸ¥è¯¢å¤±è´¥: {e}")
        return {"error": "æŸ¥è¯¢æ‰§è¡Œå¤±è´¥", "success": False}

def _validate_sql_input(self, sql: str) -> bool:
    """éªŒè¯SQLè¾“å…¥"""
    # æ£€æŸ¥é•¿åº¦é™åˆ¶
    if len(sql) > 10000:  # é˜²æ­¢è¿‡é•¿çš„SQL
        return False
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å±é™©å…³é”®å­—
    dangerous_keywords = [
        'DROP', 'DELETE', 'TRUNCATE', 'ALTER', 'CREATE', 'GRANT', 'REVOKE',
        'EXECUTE', 'EXEC', 'xp_', 'sp_', '--', '/*', '*/'
    ]
    
    sql_upper = sql.upper()
    for keyword in dangerous_keywords:
        if keyword in sql_upper:
            logger.warning(f"æ£€æµ‹åˆ°å±é™©SQLå…³é”®å­—: {keyword}")
            return False
    
    return True

def _security_check(self, sql: str) -> bool:
    """SQLå®‰å…¨æ£€æŸ¥"""
    # æ£€æŸ¥æ˜¯å¦æ˜¯å¤šè¯­å¥æŸ¥è¯¢
    if ';' in sql and sql.count(';') > 1:
        logger.warning("æ£€æµ‹åˆ°å¤šè¯­å¥æŸ¥è¯¢")
        return False
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ³¨é‡Š
    if '--' in sql or '/*' in sql:
        logger.warning("æ£€æµ‹åˆ°SQLæ³¨é‡Š")
        return False
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å­˜å‚¨è¿‡ç¨‹è°ƒç”¨
    if 'CALL' in sql.upper() or 'EXEC' in sql.upper():
        logger.warning("æ£€æµ‹åˆ°å­˜å‚¨è¿‡ç¨‹è°ƒç”¨")
        return False
    
    return True
```

**æ½œåœ¨å®‰å…¨é£é™©åˆ†æ**ï¼š
âš ï¸ **AIç”Ÿæˆçš„SQLé£é™©**ï¼š
- AIå¯èƒ½ç”ŸæˆåŒ…å«æ¶æ„ä»£ç çš„SQL
- ç¼ºå°‘å¯¹AIç”ŸæˆSQLçš„é¢å¤–éªŒè¯å±‚
- æ²¡æœ‰SQLè¯­å¥çš„è¯­ä¹‰åˆ†æ

âš ï¸ **æƒé™æå‡é£é™©**ï¼š
- æ•°æ®åº“ç”¨æˆ·å¯èƒ½å…·æœ‰è¿‡é«˜æƒé™
- ç¼ºå°‘è¡Œçº§å’Œåˆ—çº§æƒé™æ§åˆ¶
- æ²¡æœ‰æŸ¥è¯¢ç»“æœçš„æ•°æ®è„±æ•

**å®‰å…¨æ”¹è¿›å»ºè®®**ï¼š
ğŸ”§ **SQLç™½åå•æœºåˆ¶**ï¼š
```python
class SQLWhitelistValidator:
    def __init__(self):
        self.allowed_operations = ['SELECT', 'WITH']
        self.allowed_tables = ['asset_snapshot', 'transaction_history']
        self.allowed_functions = ['COUNT', 'SUM', 'AVG', 'MAX', 'MIN']
    
    def validate_sql(self, sql: str) -> bool:
        """éªŒè¯SQLæ˜¯å¦åœ¨ç™½åå•ä¸­"""
        sql_upper = sql.upper().strip()
        
        # æ£€æŸ¥æ“ä½œç±»å‹
        if not any(op in sql_upper for op in self.allowed_operations):
            return False
        
        # æ£€æŸ¥è¡¨å
        if not any(table in sql_upper for table in self.allowed_tables):
            return False
        
        # æ£€æŸ¥å‡½æ•°è°ƒç”¨
        for func in self.allowed_functions:
            if func in sql_upper:
                # ç¡®ä¿å‡½æ•°è°ƒç”¨æ˜¯å®‰å…¨çš„
                if not self._validate_function_call(sql_upper, func):
                    return False
        
        return True
    
    def _validate_function_call(self, sql: str, func: str) -> bool:
        """éªŒè¯å‡½æ•°è°ƒç”¨å®‰å…¨æ€§"""
        # æ£€æŸ¥å‡½æ•°å‚æ•°æ˜¯å¦åŒ…å«å­æŸ¥è¯¢
        pattern = rf'{func}\s*\([^)]*\)'
        matches = re.findall(pattern, sql)
        
        for match in matches:
            if '(' in match[func.__len__():] and ')' in match[func.__len__():]:
                # åŒ…å«åµŒå¥—æ‹¬å·ï¼Œå¯èƒ½æ˜¯å­æŸ¥è¯¢
                return False
        
        return True
```

#### 5.1.2 æ•°æ®åº“æƒé™æ§åˆ¶æ·±åº¦åˆ†æ
**å½“å‰æƒé™é…ç½®åˆ†æ**ï¼š
```python
# å½“å‰æ•°æ®åº“è¿æ¥é…ç½®
self.db_config = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': int(os.getenv('DB_PORT', '5432')),
    'database': os.getenv('DB_NAME', 'financetool_test'),
    'user': os.getenv('DB_USER', 'financetool_user'),
    'password': os.getenv('DB_PASSWORD', 'financetool_pass')
}
```

**æƒé™æ§åˆ¶ç°çŠ¶**ï¼š
âœ… **ä¸“ç”¨ç”¨æˆ·è´¦æˆ·**ï¼šä½¿ç”¨ä¸“é—¨çš„æ•°æ®åº“ç”¨æˆ·ï¼Œä¸æ˜¯è¶…çº§ç”¨æˆ·
âœ… **ç¯å¢ƒå˜é‡é…ç½®**ï¼šæ•æ„Ÿä¿¡æ¯é€šè¿‡ç¯å¢ƒå˜é‡ç®¡ç†
âœ… **è¿æ¥è¶…æ—¶è®¾ç½®**ï¼šé˜²æ­¢é•¿æ—¶é—´è¿æ¥å ç”¨

**æƒé™æ§åˆ¶é£é™©**ï¼š
âš ï¸ **æƒé™è¿‡é«˜**ï¼šæ•°æ®åº“ç”¨æˆ·å¯èƒ½å…·æœ‰è¿‡å¤šæƒé™
âš ï¸ **ç¼ºå°‘å®¡è®¡**ï¼šæ²¡æœ‰æ•°æ®åº“æ“ä½œæ—¥å¿—è®°å½•
âš ï¸ **ç¼ºå°‘éš”ç¦»**ï¼šæ‰€æœ‰æŸ¥è¯¢ä½¿ç”¨åŒä¸€ä¸ªæ•°æ®åº“ç”¨æˆ·

**æƒé™æ§åˆ¶æ”¹è¿›æ–¹æ¡ˆ**ï¼š
ğŸ”§ **æœ€å°æƒé™åŸåˆ™å®ç°**ï¼š
```sql
-- åˆ›å»ºä¸“ç”¨åªè¯»ç”¨æˆ·
CREATE USER mcp_readonly_user WITH PASSWORD 'secure_password';

-- åªæˆäºˆå¿…è¦çš„æƒé™
GRANT CONNECT ON DATABASE financetool_test TO mcp_readonly_user;
GRANT USAGE ON SCHEMA public TO mcp_readonly_user;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO mcp_readonly_user;
GRANT SELECT ON ALL SEQUENCES IN SCHEMA public TO mcp_readonly_user;

-- é™åˆ¶ç”¨æˆ·åªèƒ½æ‰§è¡ŒSELECTæ“ä½œ
REVOKE ALL ON ALL TABLES IN SCHEMA public FROM mcp_readonly_user;
GRANT SELECT ON asset_snapshot TO mcp_readonly_user;
GRANT SELECT ON transaction_history TO mcp_readonly_user;
```

ğŸ”§ **æ•°æ®åº“å®¡è®¡æ—¥å¿—**ï¼š
```python
class DatabaseAuditLogger:
    def __init__(self, db_config: Dict[str, Any]):
        self.db_config = db_config
    
    def log_query(self, sql: str, user_id: str, result: Dict[str, Any]):
        """è®°å½•æŸ¥è¯¢æ—¥å¿—"""
        audit_log = {
            "timestamp": datetime.now().isoformat(),
            "user_id": user_id,
            "sql": sql,
            "result_rows": result.get("row_count", 0),
            "success": result.get("success", False),
            "ip_address": self._get_client_ip(),
            "user_agent": self._get_user_agent()
        }
        
        # å†™å…¥å®¡è®¡æ—¥å¿—è¡¨
        self._write_audit_log(audit_log)
    
    def _write_audit_log(self, audit_log: Dict[str, Any]):
        """å†™å…¥å®¡è®¡æ—¥å¿—"""
        try:
            with psycopg2.connect(**self.db_config) as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        INSERT INTO audit_logs 
                        (timestamp, user_id, sql_query, result_rows, success, ip_address, user_agent)
                        VALUES (%s, %s, %s, %s, %s, %s, %s)
                    """, (
                        audit_log["timestamp"],
                        audit_log["user_id"],
                        audit_log["sql"],
                        audit_log["result_rows"],
                        audit_log["success"],
                        audit_log["ip_address"],
                        audit_log["user_agent"]
                    ))
                    conn.commit()
        except Exception as e:
            logger.error(f"å†™å…¥å®¡è®¡æ—¥å¿—å¤±è´¥: {e}")
```

### 5.2 è®¿é—®æ§åˆ¶å®‰å…¨æ·±åº¦åˆ†æ

#### 5.2.1 APIè®¿é—®æ§åˆ¶ç°çŠ¶åˆ†æ
**å½“å‰CORSé…ç½®**ï¼š
```python
# å½“å‰CORSé…ç½® - è¿‡äºå®½æ¾
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æº
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰HTTPæ–¹æ³•
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰è¯·æ±‚å¤´
)
```

**CORSå®‰å…¨é£é™©**ï¼š
âš ï¸ **è·¨åŸŸæ”»å‡»**ï¼šæ¶æ„ç½‘ç«™å¯èƒ½å‘èµ·è·¨åŸŸè¯·æ±‚
âš ï¸ **ä¿¡æ¯æ³„éœ²**ï¼šæ•æ„Ÿä¿¡æ¯å¯èƒ½è¢«æ¶æ„ç½‘ç«™è·å–
âš ï¸ **CSRFæ”»å‡»**ï¼šç¼ºå°‘OriginéªŒè¯

**APIè®¤è¯ç°çŠ¶**ï¼š
âš ï¸ **æ— è®¤è¯æœºåˆ¶**ï¼šä»»ä½•äººéƒ½å¯ä»¥è°ƒç”¨API
âš ï¸ **æ— æƒé™æ§åˆ¶**ï¼šæ— æ³•åŒºåˆ†ä¸åŒç”¨æˆ·çš„æƒé™
âš ï¸ **æ— è®¿é—®é™åˆ¶**ï¼šæ— æ³•æ§åˆ¶APIè°ƒç”¨é¢‘ç‡

#### 5.2.2 è®¿é—®æ§åˆ¶æ”¹è¿›æ–¹æ¡ˆ
ğŸ”§ **JWTè®¤è¯å®ç°**ï¼š
```python
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import jwt
from datetime import datetime, timedelta

class JWTAuthHandler:
    def __init__(self):
        self.secret_key = os.getenv("JWT_SECRET_KEY", "your-secret-key")
        self.algorithm = "HS256"
        self.access_token_expire_minutes = 30
    
    def create_access_token(self, data: dict):
        """åˆ›å»ºè®¿é—®ä»¤ç‰Œ"""
        to_encode = data.copy()
        expire = datetime.utcnow() + timedelta(minutes=self.access_token_expire_minutes)
        to_encode.update({"exp": expire})
        encoded_jwt = jwt.encode(to_encode, self.secret_key, algorithm=self.algorithm)
        return encoded_jwt
    
    def verify_token(self, token: str):
        """éªŒè¯ä»¤ç‰Œ"""
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            return payload
        except jwt.ExpiredSignatureError:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="ä»¤ç‰Œå·²è¿‡æœŸ"
            )
        except jwt.JWTError:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="æ— æ•ˆä»¤ç‰Œ"
            )

# ä½¿ç”¨JWTè®¤è¯çš„APIç«¯ç‚¹
@app.post("/api/query")
async def query_database(
    question: str,
    credentials: HTTPAuthorizationCredentials = Depends(HTTPBearer())
):
    """å—ä¿æŠ¤çš„æ•°æ®åº“æŸ¥è¯¢æ¥å£"""
    # éªŒè¯JWTä»¤ç‰Œ
    auth_handler = JWTAuthHandler()
    payload = auth_handler.verify_token(credentials.credentials)
    user_id = payload.get("user_id")
    
    # æ‰§è¡ŒæŸ¥è¯¢
    result = await mcp_server.process_natural_language_query(question)
    return result
```

ğŸ”§ **APIé€Ÿç‡é™åˆ¶å®ç°**ï¼š
```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

# åˆ›å»ºé™æµå™¨
limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# åº”ç”¨é€Ÿç‡é™åˆ¶
@app.post("/api/query")
@limiter.limit("10/minute")  # æ¯åˆ†é’Ÿæœ€å¤š10æ¬¡è¯·æ±‚
async def query_database(
    question: str,
    request: Request,
    credentials: HTTPAuthorizationCredentials = Depends(HTTPBearer())
):
    """å—é€Ÿç‡é™åˆ¶ä¿æŠ¤çš„æŸ¥è¯¢æ¥å£"""
    # ... å®ç°é€»è¾‘
```

ğŸ”§ **CORSå®‰å…¨é…ç½®**ï¼š
```python
# å®‰å…¨çš„CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://yourdomain.com",
        "https://app.yourdomain.com",
        "http://localhost:3000"  # ä»…å¼€å‘ç¯å¢ƒ
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST"],  # åªå…è®¸å¿…è¦çš„HTTPæ–¹æ³•
    allow_headers=["Authorization", "Content-Type"],  # åªå…è®¸å¿…è¦çš„è¯·æ±‚å¤´
    expose_headers=["X-Total-Count"],  # æš´éœ²å¿…è¦çš„å“åº”å¤´
)
```

### 5.3 æ•°æ®å®‰å…¨ä¿æŠ¤

#### 5.3.1 æ•°æ®è„±æ•æœºåˆ¶
**æ•æ„Ÿæ•°æ®è¯†åˆ«**ï¼š
```python
class DataMaskingService:
    def __init__(self):
        self.sensitive_fields = {
            'asset_snapshot': ['balance_cny', 'asset_code'],
            'transaction_history': ['amount', 'account_number'],
            'user_profile': ['phone', 'email', 'id_card']
        }
    
    def mask_sensitive_data(self, data: List[Dict[str, Any]], table_name: str) -> List[Dict[str, Any]]:
        """è„±æ•æ•æ„Ÿæ•°æ®"""
        if table_name not in self.sensitive_fields:
            return data
        
        masked_data = []
        sensitive_fields = self.sensitive_fields[table_name]
        
        for row in data:
            masked_row = row.copy()
            for field in sensitive_fields:
                if field in masked_row:
                    masked_row[field] = self._mask_value(masked_row[field])
            masked_data.append(masked_row)
        
        return masked_data
    
    def _mask_value(self, value: Any) -> str:
        """è„±æ•å•ä¸ªå€¼"""
        if isinstance(value, str):
            if len(value) <= 2:
                return "*" * len(value)
            else:
                return value[0] + "*" * (len(value) - 2) + value[-1]
        elif isinstance(value, (int, float)):
            return "***"
        else:
            return "***"
```

#### 5.3.2 æŸ¥è¯¢ç»“æœå®‰å…¨æ§åˆ¶
**ç»“æœè¡Œæ•°é™åˆ¶**ï¼š
```python
def _apply_security_limits(self, sql: str, max_rows: int = 1000) -> str:
    """åº”ç”¨å®‰å…¨é™åˆ¶"""
    # å¼ºåˆ¶æ·»åŠ LIMITå­å¥
    if "LIMIT" not in sql.upper():
        sql = f"{sql} LIMIT {max_rows}"
    else:
        # æ£€æŸ¥LIMITå€¼æ˜¯å¦è¿‡å¤§
        limit_match = re.search(r'LIMIT\s+(\d+)', sql.upper())
        if limit_match:
            limit_value = int(limit_match.group(1))
            if limit_value > max_rows:
                # æ›¿æ¢è¿‡å¤§çš„LIMITå€¼
                sql = re.sub(r'LIMIT\s+\d+', f'LIMIT {max_rows}', sql.upper())
    
    return sql
```

### 5.4 å®‰å…¨ç›‘æ§å’Œå‘Šè­¦

#### 5.4.1 å®‰å…¨äº‹ä»¶ç›‘æ§
```python
class SecurityMonitor:
    def __init__(self):
        self.suspicious_patterns = [
            r'(\b(?:DROP|DELETE|TRUNCATE|ALTER|CREATE)\b)',
            r'(\b(?:xp_|sp_)\w+)',
            r'(\b(?:EXEC|EXECUTE)\b)',
            r'(\b(?:--|/\*|\*/)\b)'
        ]
    
    def monitor_query(self, sql: str, user_id: str, ip_address: str):
        """ç›‘æ§æŸ¥è¯¢å®‰å…¨æ€§"""
        for pattern in self.suspicious_patterns:
            if re.search(pattern, sql, re.IGNORECASE):
                self._trigger_security_alert(sql, user_id, ip_address, pattern)
                return False
        return True
    
    def _trigger_security_alert(self, sql: str, user_id: str, ip_address: str, pattern: str):
        """è§¦å‘å®‰å…¨å‘Šè­¦"""
        alert = {
            "timestamp": datetime.now().isoformat(),
            "level": "HIGH",
            "type": "SUSPICIOUS_SQL",
            "sql": sql,
            "user_id": user_id,
            "ip_address": ip_address,
            "pattern": pattern,
            "action": "BLOCKED"
        }
        
        # è®°å½•å®‰å…¨å‘Šè­¦
        logger.warning(f"å®‰å…¨å‘Šè­¦: {alert}")
        
        # å‘é€å‘Šè­¦é€šçŸ¥
        self._send_security_alert(alert)
```

### 5.5 å®‰å…¨æ”¹è¿›ä¼˜å…ˆçº§

#### 5.5.1 é«˜ä¼˜å…ˆçº§ï¼ˆç«‹å³å®æ–½ï¼‰
1. **å®ç°JWTè®¤è¯** - é˜²æ­¢æœªæˆæƒè®¿é—®
2. **é™åˆ¶CORSæ¥æº** - é˜²æ­¢è·¨åŸŸæ”»å‡»
3. **æ·»åŠ SQLç™½åå•** - é˜²æ­¢æ¶æ„SQLæ‰§è¡Œ

#### 5.5.2 ä¸­ä¼˜å…ˆçº§ï¼ˆ1-2å‘¨å†…ï¼‰
1. **å®ç°APIé€Ÿç‡é™åˆ¶** - é˜²æ­¢APIæ»¥ç”¨
2. **æ·»åŠ æ•°æ®åº“å®¡è®¡æ—¥å¿—** - æé«˜å¯è¿½æº¯æ€§
3. **å®ç°æ•°æ®è„±æ•** - ä¿æŠ¤æ•æ„Ÿä¿¡æ¯

#### 5.5.3 ä½ä¼˜å…ˆçº§ï¼ˆ1ä¸ªæœˆå†…ï¼‰
1. **å®Œå–„å®‰å…¨ç›‘æ§** - å®æ—¶å®‰å…¨å‘Šè­¦
2. **æƒé™æœ€å°åŒ–** - æ•°æ®åº“ç”¨æˆ·æƒé™ä¼˜åŒ–
3. **å®‰å…¨æµ‹è¯•** - æ¸—é€æµ‹è¯•å’Œå®‰å…¨è¯„ä¼°

---

## ç¬¬å…­éƒ¨åˆ†ï¼šé€šç”¨æ€§åˆ†æ

### 6.1 æ¶æ„é€šç”¨æ€§æ·±åº¦åˆ†æ

#### 6.1.1 è®¾è®¡æ¨¡å¼ä¼˜åŠ¿è¯¦è§£
**æ ‡å‡†åŒ–è®¾è®¡åˆ†æ**ï¼š
âœ… **MCPåè®®è§„èŒƒéµå¾ª**ï¼š
- ä¸¥æ ¼éµå¾ªModel Context Protocolæ ‡å‡†
- å·¥å…·å®šä¹‰ä½¿ç”¨JSON Schemaè¿›è¡Œå‚æ•°éªŒè¯
- æ”¯æŒæ ‡å‡†çš„å·¥å…·è°ƒç”¨å’Œç»“æœè¿”å›æ ¼å¼

âœ… **æ¨¡å—åŒ–ç»„ä»¶è®¾è®¡**ï¼š
- æ¯ä¸ªæœåŠ¡éƒ½æœ‰æ˜ç¡®çš„èŒè´£è¾¹ç•Œ
- é€šè¿‡æ¥å£è¿›è¡Œç»„ä»¶é—´é€šä¿¡
- æ”¯æŒç»„ä»¶çš„ç‹¬ç«‹å¼€å‘å’Œæµ‹è¯•

âœ… **ä¾èµ–æ³¨å…¥æ¶æ„**ï¼š
- é€šè¿‡æ„é€ å‡½æ•°æ³¨å…¥ä¾èµ–ï¼Œä¾¿äºæµ‹è¯•
- æ”¯æŒç»„ä»¶çš„åŠ¨æ€æ›¿æ¢å’Œé…ç½®
- é™ä½ç»„ä»¶é—´çš„è€¦åˆåº¦

**å…·ä½“ä»£ç ç¤ºä¾‹**ï¼š
```python
# ä¾èµ–æ³¨å…¥ç¤ºä¾‹
class MCPServer:
    def __init__(self, ai_service: DeepSeekAIService, chart_generator: ChartConfigGenerator):
        self.ai_service = ai_service          # ä¾èµ–æ³¨å…¥
        self.chart_generator = chart_generator
        self.mcp_tools = MCPTools(self.db_config)
        
        # æ¡ä»¶åˆå§‹åŒ–Claude AIæœåŠ¡
        self.claude_ai = None
        if os.getenv("CLAUDE_API_KEY"):
            self.claude_ai = ClaudeAIService(self.mcp_tools)

# ç»„ä»¶æ›¿æ¢ç¤ºä¾‹
def create_mcp_server(ai_service_type: str = "auto"):
    """å·¥å‚æ–¹æ³•åˆ›å»ºMCPæœåŠ¡å™¨"""
    if ai_service_type == "claude":
        ai_service = ClaudeAIService(mcp_tools)
    elif ai_service_type == "deepseek":
        ai_service = DeepSeekAIService()
    else:
        ai_service = AutoAIService()  # è‡ªåŠ¨é€‰æ‹©
    
    chart_generator = ChartConfigGenerator()
    return MCPServer(ai_service, chart_generator)
```

**æ‰©å±•æ€§æ”¯æŒåˆ†æ**ï¼š
âœ… **AIæ¨¡å‹æ‰©å±•**ï¼š
```python
class AIModelRegistry:
    """AIæ¨¡å‹æ³¨å†Œè¡¨"""
    def __init__(self):
        self.models = {}
    
    def register_model(self, name: str, model_class: type):
        """æ³¨å†Œæ–°çš„AIæ¨¡å‹"""
        self.models[name] = model_class
    
    def get_model(self, name: str):
        """è·å–AIæ¨¡å‹å®ä¾‹"""
        if name not in self.models:
            raise ValueError(f"æœªçŸ¥çš„AIæ¨¡å‹: {name}")
        return self.models[name]()
    
    def list_models(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„AIæ¨¡å‹"""
        return list(self.models.keys())

# ä½¿ç”¨ç¤ºä¾‹
registry = AIModelRegistry()
registry.register_model("claude", ClaudeAIService)
registry.register_model("deepseek", DeepSeekAIService)
registry.register_model("gpt4", GPT4AIService)  # æ–°å¢æ¨¡å‹
```

âœ… **æ•°æ®åº“ç±»å‹æ‰©å±•**ï¼š
```python
class DatabaseAdapter:
    """æ•°æ®åº“é€‚é…å™¨æŠ½è±¡ç±»"""
    def __init__(self, config: Dict[str, Any]):
        self.config = config
    
    def connect(self):
        """å»ºç«‹æ•°æ®åº“è¿æ¥"""
        raise NotImplementedError
    
    def execute_query(self, sql: str) -> List[Dict[str, Any]]:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        raise NotImplementedError
    
    def get_table_schema(self, table_name: str) -> Dict[str, Any]:
        """è·å–è¡¨ç»“æ„"""
        raise NotImplementedError

class PostgreSQLAdapter(DatabaseAdapter):
    """PostgreSQLé€‚é…å™¨"""
    def connect(self):
        return psycopg2.connect(**self.config)
    
    def execute_query(self, sql: str) -> List[Dict[str, Any]]:
        with self.connect() as conn:
            with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                cursor.execute(sql)
                return [dict(row) for row in cursor.fetchall()]

class MySQLAdapter(DatabaseAdapter):
    """MySQLé€‚é…å™¨"""
    def connect(self):
        return mysql.connector.connect(**self.config)
    
    def execute_query(self, sql: str) -> List[Dict[str, Any]]:
        with self.connect() as conn:
            with conn.cursor(dictionary=True) as cursor:
                cursor.execute(sql)
                return cursor.fetchall()
```

#### 6.1.2 ä¸šåŠ¡é€šç”¨æ€§æ·±åº¦åˆ†æ
**å½“å‰ä¸šåŠ¡é™åˆ¶åˆ†æ**ï¼š
âš ï¸ **æŸ¥è¯¢æ¨¡æ¿ç¡¬ç¼–ç **ï¼š
```python
# å½“å‰ç¡¬ç¼–ç çš„æŸ¥è¯¢æ¨¡æ¿
self.query_templates = {
    "platform_distribution": {
        "description": "å¹³å°èµ„äº§åˆ†å¸ƒæŸ¥è¯¢",
        "sql": "SELECT platform, SUM(balance_cny) as total_value, COUNT(*) as asset_count FROM asset_snapshot GROUP BY platform ORDER BY total_value DESC"
    },
    "asset_type_distribution": {
        "description": "èµ„äº§ç±»å‹åˆ†å¸ƒæŸ¥è¯¢", 
        "sql": "SELECT asset_type, SUM(balance_cny) as total_value, COUNT(*) as asset_count FROM asset_snapshot GROUP BY asset_type ORDER BY total_value DESC"
    }
}
```

**é—®é¢˜åˆ†æ**ï¼š
- å­—æ®µåç¡¬ç¼–ç ï¼ˆå¦‚`balance_cny`ï¼‰
- è¡¨åç¡¬ç¼–ç ï¼ˆå¦‚`asset_snapshot`ï¼‰
- ä¸šåŠ¡é€»è¾‘ç¡¬ç¼–ç ï¼ˆå¦‚èµ„äº§åˆ†æï¼‰

âš ï¸ **æ¨¡æ‹Ÿæ•°æ®ä¸šåŠ¡ç‰¹å®š**ï¼š
```python
# å½“å‰ä¸šåŠ¡ç‰¹å®šçš„æ¨¡æ‹Ÿæ•°æ®
self.mock_data = {
    "asset_snapshot": [
        {
            "platform": "æ”¯ä»˜å®",      # ç¡¬ç¼–ç å¹³å°åç§°
            "asset_type": "åŸºé‡‘",      # ç¡¬ç¼–ç èµ„äº§ç±»å‹
            "balance_cny": 85230.45,  # ç¡¬ç¼–ç è´§å¸ç±»å‹
            "snapshot_time": "2024-01-15 09:00:00"
        }
    ]
}
```

**é€šç”¨åŒ–æ”¹é€ æ–¹æ¡ˆ**ï¼š
ğŸ”§ **æŠ½è±¡æŸ¥è¯¢æ¨¡æ¿ç³»ç»Ÿ**ï¼š
```python
class GenericQueryTemplate:
    """é€šç”¨æŸ¥è¯¢æ¨¡æ¿"""
    def __init__(self):
        self.templates = {}
        self.field_mappings = {}
        self.business_rules = {}
    
    def register_template(self, name: str, template: Dict[str, Any]):
        """æ³¨å†ŒæŸ¥è¯¢æ¨¡æ¿"""
        self.templates[name] = template
    
    def set_field_mapping(self, business_field: str, db_field: str):
        """è®¾ç½®å­—æ®µæ˜ å°„"""
        self.field_mappings[business_field] = db_field
    
    def set_business_rule(self, rule_name: str, rule_logic: str):
        """è®¾ç½®ä¸šåŠ¡è§„åˆ™"""
        self.business_rules[rule_name] = rule_logic
    
    def generate_sql(self, template_name: str, context: Dict[str, Any]) -> str:
        """æ ¹æ®ä¸Šä¸‹æ–‡ç”ŸæˆSQL"""
        if template_name not in self.templates:
            raise ValueError(f"æœªçŸ¥æ¨¡æ¿: {template_name}")
        
        template = self.templates[template_name]
        sql_template = template["sql"]
        
        # æ›¿æ¢å­—æ®µæ˜ å°„
        for business_field, db_field in self.field_mappings.items():
            sql_template = sql_template.replace(f"{{{business_field}}}", db_field)
        
        # åº”ç”¨ä¸šåŠ¡è§„åˆ™
        for rule_name, rule_logic in self.business_rules.items():
            sql_template = self._apply_business_rule(sql_template, rule_logic, context)
        
        return sql_template

# ä½¿ç”¨ç¤ºä¾‹
template_system = GenericQueryTemplate()

# æ³¨å†Œé€šç”¨æ¨¡æ¿
template_system.register_template("distribution", {
    "description": "åˆ†å¸ƒæŸ¥è¯¢æ¨¡æ¿",
    "sql": "SELECT {group_field}, SUM({value_field}) as total_value, COUNT(*) as count FROM {table_name} GROUP BY {group_field} ORDER BY total_value DESC"
})

# è®¾ç½®å­—æ®µæ˜ å°„
template_system.set_field_mapping("group_field", "platform")
template_system.set_field_mapping("value_field", "balance_cny")
template_system.set_field_mapping("table_name", "asset_snapshot")

# ç”ŸæˆSQL
sql = template_system.generate_sql("distribution", {
    "group_field": "platform",
    "value_field": "balance_cny",
    "table_name": "asset_snapshot"
})
# ç»“æœ: SELECT platform, SUM(balance_cny) as total_value, COUNT(*) as count FROM asset_snapshot GROUP BY platform ORDER BY total_value DESC
```

ğŸ”§ **ä¸šåŠ¡åœºæ™¯é…ç½®åŒ–**ï¼š
```python
class BusinessScenarioConfig:
    """ä¸šåŠ¡åœºæ™¯é…ç½®"""
    def __init__(self):
        self.scenarios = {}
    
    def load_scenario(self, scenario_name: str, config_file: str):
        """åŠ è½½ä¸šåŠ¡åœºæ™¯é…ç½®"""
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
            self.scenarios[scenario_name] = config
    
    def get_field_mapping(self, scenario_name: str) -> Dict[str, str]:
        """è·å–å­—æ®µæ˜ å°„"""
        if scenario_name not in self.scenarios:
            return {}
        return self.scenarios[scenario_name].get("field_mappings", {})
    
    def get_business_rules(self, scenario_name: str) -> List[str]:
        """è·å–ä¸šåŠ¡è§„åˆ™"""
        if scenario_name not in self.scenarios:
            return []
        return self.scenarios[scenario_name].get("business_rules", [])

# ä¸šåŠ¡åœºæ™¯é…ç½®æ–‡ä»¶ç¤ºä¾‹ (finance_scenario.yaml)
"""
scenario_name: "è´¢åŠ¡åˆ†æ"
field_mappings:
  platform: "platform"
  asset_type: "asset_type"
  balance: "balance_cny"
  currency: "CNY"
  time_field: "snapshot_time"

business_rules:
  - "balance > 0"
  - "platform IN ('æ”¯ä»˜å®', 'Wise', 'IBKR')"
  - "asset_type IN ('åŸºé‡‘', 'è‚¡ç¥¨', 'å¤–æ±‡')"

tables:
  - name: "asset_snapshot"
    description: "èµ„äº§å¿«ç…§è¡¨"
    primary_key: "id"
    time_field: "snapshot_time"
"""
```

### 6.2 æŠ€æœ¯é€šç”¨æ€§æ·±åº¦åˆ†æ

#### 6.2.1 éƒ¨ç½²é€šç”¨æ€§è¯¦è§£
**å®¹å™¨åŒ–æ”¯æŒåˆ†æ**ï¼š
âœ… **Dockeré…ç½®å®Œæ•´æ€§**ï¼š
```dockerfile
# å½“å‰Dockerfileåˆ†æ
FROM python:3.11-slim

# ç³»ç»Ÿä¾èµ–å®‰è£…
RUN apt-get update && apt-get install -y \
    gcc \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# Pythonä¾èµ–å®‰è£…
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# åº”ç”¨ä»£ç å¤åˆ¶
COPY . .

# åŠ¨æ€ç«¯å£é…ç½®
EXPOSE $PORT
```

**ä¼˜åŠ¿åˆ†æ**ï¼š
- ä½¿ç”¨å®˜æ–¹Pythoné•œåƒï¼Œå…¼å®¹æ€§å¥½
- æœ€å°åŒ–ç³»ç»Ÿä¾èµ–ï¼Œé•œåƒä½“ç§¯å°
- æ”¯æŒç¯å¢ƒå˜é‡é…ç½®ç«¯å£
- å¤šé˜¶æ®µæ„å»ºæ”¯æŒ

**æ”¹è¿›å»ºè®®**ï¼š
ğŸ”§ **å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–**ï¼š
```dockerfile
# æ„å»ºé˜¶æ®µ
FROM python:3.11-slim as builder

WORKDIR /app
COPY requirements.txt .
RUN pip install --user --no-cache-dir -r requirements.txt

# è¿è¡Œé˜¶æ®µ
FROM python:3.11-slim

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apt-get update && apt-get install -y \
    libpq5 \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶PythonåŒ…
COPY --from=builder /root/.local /root/.local

# è®¾ç½®PATH
ENV PATH=/root/.local/bin:$PATH

# å¤åˆ¶åº”ç”¨ä»£ç 
WORKDIR /app
COPY . .

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:$PORT/health || exit 1

EXPOSE $PORT
CMD ["python", "-m", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "$PORT"]
```

**ç¯å¢ƒé…ç½®ç³»ç»Ÿ**ï¼š
âœ… **ç¯å¢ƒå˜é‡ç®¡ç†**ï¼š
```python
# å½“å‰ç¯å¢ƒå˜é‡é…ç½®
class Settings:
    # æ•°æ®åº“é…ç½®
    DB_HOST: str = os.getenv("DB_HOST", "localhost")
    DB_PORT: int = int(os.getenv("DB_PORT", "5432"))
    DB_NAME: str = os.getenv("DB_NAME", "financetool_test")
    DB_USER: str = os.getenv("DB_USER", "financetool_user")
    DB_PASSWORD: str = os.getenv("DB_PASSWORD", "financetool_pass")
    
    # AIæœåŠ¡é…ç½®
    CLAUDE_API_KEY: str = os.getenv("CLAUDE_API_KEY", "")
    DEEPSEEK_API_KEY: str = os.getenv("DEEPSEEK_API_KEY", "")
    
    # æœåŠ¡é…ç½®
    PORT: int = int(os.getenv("PORT", "3001"))
    DEBUG: bool = os.getenv("DEBUG", "false").lower() == "true"
    APP_ENV: str = os.getenv("APP_ENV", "prod")

# é…ç½®éªŒè¯
def validate_settings(settings: Settings) -> bool:
    """éªŒè¯é…ç½®å®Œæ•´æ€§"""
    required_fields = [
        "DB_HOST", "DB_NAME", "DB_USER", "DB_PASSWORD"
    ]
    
    for field in required_fields:
        if not getattr(settings, field):
            logger.error(f"ç¼ºå°‘å¿…éœ€é…ç½®: {field}")
            return False
    
    return True
```

#### 6.2.2 å¹³å°å…¼å®¹æ€§åˆ†æ
**æ•°æ®åº“å…¼å®¹æ€§**ï¼š
âœ… **PostgreSQLæ”¯æŒ**ï¼š
- ä½¿ç”¨psycopg2é©±åŠ¨ï¼Œæ€§èƒ½ä¼˜ç§€
- æ”¯æŒPostgreSQLç‰¹æœ‰åŠŸèƒ½ï¼ˆå¦‚JSONå­—æ®µï¼‰
- è¿æ¥æ± ç®¡ç†å’Œäº‹åŠ¡æ”¯æŒ

**è·¨å¹³å°æ”¯æŒ**ï¼š
âœ… **æ“ä½œç³»ç»Ÿå…¼å®¹æ€§**ï¼š
- Pythonè·¨å¹³å°è¿è¡Œ
- Dockerå®¹å™¨åŒ–éƒ¨ç½²
- ç¯å¢ƒå˜é‡é…ç½®ç³»ç»Ÿ

**äº‘å¹³å°éƒ¨ç½²æ”¯æŒ**ï¼š
âœ… **Railwayéƒ¨ç½²**ï¼š
```yaml
# railway.toml é…ç½®åˆ†æ
[build]
builder = "nixpacks"
buildCommand = "pip install -r requirements.txt"

[deploy]
startCommand = "python -m uvicorn app.main:app --host 0.0.0.0 --port $PORT"
healthcheckPath = "/health"
healthcheckTimeout = 300
restartPolicyType = "ON_FAILURE"
```

### 6.3 é€šç”¨æ€§æ”¹è¿›è·¯çº¿å›¾

#### 6.3.1 çŸ­æœŸæ”¹è¿›ï¼ˆ1-2å‘¨ï¼‰
1. **æŠ½è±¡æŸ¥è¯¢æ¨¡æ¿**ï¼šå°†ç¡¬ç¼–ç çš„æŸ¥è¯¢æ¨¡æ¿æŠ½è±¡ä¸ºé€šç”¨æ¨¡å¼
2. **å­—æ®µæ˜ å°„é…ç½®**ï¼šå®ç°ä¸šåŠ¡å­—æ®µåˆ°æ•°æ®åº“å­—æ®µçš„æ˜ å°„é…ç½®
3. **ç¯å¢ƒé…ç½®ä¼˜åŒ–**ï¼šå®Œå–„ç¯å¢ƒå˜é‡é…ç½®å’ŒéªŒè¯

#### 6.3.2 ä¸­æœŸæ”¹è¿›ï¼ˆ1ä¸ªæœˆå†…ï¼‰
1. **ä¸šåŠ¡åœºæ™¯é…ç½®åŒ–**ï¼šæ”¯æŒå¤šç§ä¸šåŠ¡åœºæ™¯çš„é…ç½®
2. **æ•°æ®åº“é€‚é…å™¨**ï¼šæ”¯æŒå¤šç§æ•°æ®åº“ç±»å‹
3. **AIæ¨¡å‹æ³¨å†Œè¡¨**ï¼šæ”¯æŒåŠ¨æ€æ³¨å†Œå’Œç®¡ç†AIæ¨¡å‹

#### 6.3.3 é•¿æœŸæ”¹è¿›ï¼ˆ3ä¸ªæœˆå†…ï¼‰
1. **æ’ä»¶åŒ–æ¶æ„**ï¼šæ”¯æŒç¬¬ä¸‰æ–¹æ’ä»¶æ‰©å±•
2. **å¤šç§Ÿæˆ·æ”¯æŒ**ï¼šæ”¯æŒå¤šç§Ÿæˆ·éƒ¨ç½²
3. **å›½é™…åŒ–æ”¯æŒ**ï¼šæ”¯æŒå¤šè¯­è¨€ç•Œé¢å’Œé…ç½®

---

## ç¬¬ä¸ƒéƒ¨åˆ†ï¼šå®Œæ•´æ€§åˆ†æ

### 7.1 åŠŸèƒ½å®Œæ•´æ€§æ·±åº¦åˆ†æ

#### 7.1.1 æ ¸å¿ƒåŠŸèƒ½è¦†ç›–åˆ†æ
**å·²å®ç°åŠŸèƒ½è¯¦ç»†è¯„ä¼°**ï¼š

âœ… **AIé©±åŠ¨çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢**ï¼š
- **åŠŸèƒ½æè¿°**ï¼šæ”¯æŒç”¨æˆ·ç”¨è‡ªç„¶è¯­è¨€æè¿°æŸ¥è¯¢éœ€æ±‚ï¼ŒAIè‡ªåŠ¨ç”ŸæˆSQLå¹¶æ‰§è¡Œ
- **å®ç°è´¨é‡**ï¼š9/10 - åŒAIæ¨¡å‹æ”¯æŒï¼Œæ™ºèƒ½å›é€€æœºåˆ¶
- **æŠ€æœ¯ç‰¹ç‚¹**ï¼šClaudeæ”¯æŒMCPå·¥å…·è°ƒç”¨ï¼ŒDeepSeekæä¾›å¿«é€Ÿå“åº”

âœ… **æ•°æ®åº“ç»“æ„æ¢ç´¢**ï¼š
- **åŠŸèƒ½æè¿°**ï¼šæä¾›è¡¨åˆ—è¡¨ã€è¡¨ç»“æ„ã€æ•°æ®æ ·æœ¬ç­‰æ¢ç´¢åŠŸèƒ½
- **å®ç°è´¨é‡**ï¼š9/10 - å®Œæ•´çš„å…ƒæ•°æ®æŸ¥è¯¢ï¼Œæ”¯æŒå¤æ‚è¡¨ç»“æ„åˆ†æ
- **æŠ€æœ¯ç‰¹ç‚¹**ï¼šä½¿ç”¨PostgreSQLç³»ç»Ÿè¡¨ï¼Œæ”¯æŒè¡¨æ³¨é‡Šå’Œå­—æ®µè¯¦ç»†ä¿¡æ¯

âœ… **SQLæŸ¥è¯¢æ‰§è¡Œ**ï¼š
- **åŠŸèƒ½æè¿°**ï¼šæ‰§è¡ŒAIç”Ÿæˆçš„SQLæŸ¥è¯¢ï¼Œè¿”å›ç»“æ„åŒ–ç»“æœ
- **å®ç°è´¨é‡**ï¼š8/10 - æ”¯æŒå¤æ‚æŸ¥è¯¢ï¼Œæœ‰åŸºæœ¬çš„å®‰å…¨é˜²æŠ¤
- **æŠ€æœ¯ç‰¹ç‚¹**ï¼šå‚æ•°åŒ–æŸ¥è¯¢ï¼Œè‡ªåŠ¨LIMITé™åˆ¶ï¼Œé”™è¯¯å¤„ç†å®Œå–„

âœ… **æŸ¥è¯¢æ¨¡æ¿åŒ¹é…**ï¼š
- **åŠŸèƒ½æè¿°**ï¼šåŸºäºå…³é”®è¯çš„æ™ºèƒ½æ¨¡æ¿åŒ¹é…ï¼Œæä¾›å¿«é€ŸæŸ¥è¯¢
- **å®ç°è´¨é‡**ï¼š8/10 - è¦†ç›–å¸¸è§æŸ¥è¯¢åœºæ™¯ï¼ŒåŒ¹é…ç®—æ³•åˆç†
- **æŠ€æœ¯ç‰¹ç‚¹**ï¼šå…³é”®è¯åŒ¹é…ï¼Œæ¨¡æ¿å¯é…ç½®ï¼Œæ”¯æŒä¸šåŠ¡åœºæ™¯

âœ… **æ¨¡æ‹Ÿæ•°æ®å›é€€**ï¼š
- **åŠŸèƒ½æè¿°**ï¼šAIæœåŠ¡ä¸å¯ç”¨æ—¶æä¾›æ¨¡æ‹Ÿæ•°æ®ï¼Œç¡®ä¿æœåŠ¡å¯ç”¨æ€§
- **å®ç°è´¨é‡**ï¼š7/10 - åŸºæœ¬åŠŸèƒ½å®Œæ•´ï¼Œæ•°æ®è´¨é‡ä¸€èˆ¬
- **æŠ€æœ¯ç‰¹ç‚¹**ï¼šä¸‰å±‚å›é€€æœºåˆ¶ï¼Œæ¨¡æ‹Ÿæ•°æ®ä¸šåŠ¡ç›¸å…³

**åŠŸèƒ½å®Œæ•´æ€§è¯„åˆ†çŸ©é˜µ**ï¼š
```
åŠŸèƒ½æ¨¡å—           | å®Œæ•´æ€§ | è´¨é‡ | ç¨³å®šæ€§ | æ€»åˆ†
AIè‡ªç„¶è¯­è¨€æŸ¥è¯¢     | 9/10  | 9/10 | 8/10   | 8.7/10
æ•°æ®åº“ç»“æ„æ¢ç´¢     | 9/10  | 9/10 | 9/10   | 9.0/10
SQLæŸ¥è¯¢æ‰§è¡Œ       | 8/10  | 8/10 | 7/10   | 7.7/10
æŸ¥è¯¢æ¨¡æ¿åŒ¹é…       | 8/10  | 7/10 | 8/10   | 7.7/10
æ¨¡æ‹Ÿæ•°æ®å›é€€       | 7/10  | 6/10 | 8/10   | 7.0/10
```

**æ€»ä½“åŠŸèƒ½å®Œæ•´æ€§è¯„åˆ†ï¼š8.0/10**

#### 7.1.2 è¿ç»´åŠŸèƒ½æ·±åº¦åˆ†æ
**å·²å®ç°è¿ç»´åŠŸèƒ½**ï¼š

âœ… **æœåŠ¡å¥åº·æ£€æŸ¥**ï¼š
```python
# å¥åº·æ£€æŸ¥å®ç°åˆ†æ
@app.get("/health")
async def health_check():
    """æœåŠ¡å¥åº·æ£€æŸ¥æ¥å£"""
    try:
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        db_status = "healthy" if mcp_server else "unhealthy"
        
        # æ£€æŸ¥AIæœåŠ¡çŠ¶æ€
        ai_services = mcp_server.get_available_ai_services() if mcp_server else {}
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "database": db_status,
            "ai_services": ai_services,
            "version": "1.0.0",
            "uptime": get_uptime()
        }
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}
```

**åŠŸèƒ½ç‰¹ç‚¹**ï¼š
- æ•°æ®åº“è¿æ¥çŠ¶æ€æ£€æŸ¥
- AIæœåŠ¡å¯ç”¨æ€§æ£€æŸ¥
- æœåŠ¡ç‰ˆæœ¬å’Œè¿è¡Œæ—¶é—´ä¿¡æ¯
- å¼‚å¸¸æƒ…å†µå¤„ç†

âœ… **è¯¦ç»†æ—¥å¿—è®°å½•**ï¼š
```python
# æ—¥å¿—ç³»ç»Ÿåˆ†æ
import logging

# é…ç½®æ—¥å¿—æ ¼å¼
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('mcp_service.log'),
        logging.StreamHandler()
    ]
)

# ä¸åŒæ¨¡å—çš„æ—¥å¿—è®°å½•
logger = logging.getLogger(__name__)

# ä¸šåŠ¡æ—¥å¿—è®°å½•
logger.info(f"ğŸ” å¼€å§‹è‡ªç„¶è¯­è¨€æŸ¥è¯¢: question='{question}'")
logger.info(f"ğŸ” AIæœåŠ¡å®ä¾‹çŠ¶æ€: ai_service={self.ai_service}")
logger.warning(f"Claude API Keyæœªé…ç½®ï¼Œå›é€€åˆ°DeepSeek")
logger.error(f"âŒ AIæœåŠ¡å®ä¾‹ä¸ºNoneï¼")
```

**æ—¥å¿—ç‰¹ç‚¹**ï¼š
- ç»“æ„åŒ–æ—¥å¿—æ ¼å¼
- å¤šçº§åˆ«æ—¥å¿—è®°å½•
- æ–‡ä»¶å’Œæ§åˆ¶å°è¾“å‡º
- ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯

âœ… **ç¯å¢ƒé…ç½®ç®¡ç†**ï¼š
```python
# ç¯å¢ƒé…ç½®ç®¡ç†åˆ†æ
class EnvironmentManager:
    def __init__(self):
        self.required_vars = [
            "DB_HOST", "DB_PORT", "DB_NAME", "DB_USER", "DB_PASSWORD"
        ]
        self.optional_vars = [
            "CLAUDE_API_KEY", "DEEPSEEK_API_KEY", "DEBUG", "APP_ENV"
        ]
    
    def validate_environment(self) -> Dict[str, Any]:
        """éªŒè¯ç¯å¢ƒå˜é‡é…ç½®"""
        validation_result = {
            "required": {},
            "optional": {},
            "missing": [],
            "valid": True
        }
        
        # æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡
        for var in self.required_vars:
            value = os.getenv(var)
            if value:
                validation_result["required"][var] = "å·²è®¾ç½®"
            else:
                validation_result["missing"].append(var)
                validation_result["valid"] = False
        
        # æ£€æŸ¥å¯é€‰çš„ç¯å¢ƒå˜é‡
        for var in self.optional_vars:
            value = os.getenv(var)
            validation_result["optional"][var] = "å·²è®¾ç½®" if value else "æœªè®¾ç½®"
        
        return validation_result
```

**é…ç½®ç®¡ç†ç‰¹ç‚¹**ï¼š
- å¿…éœ€å’Œå¯é€‰ç¯å¢ƒå˜é‡åŒºåˆ†
- é…ç½®éªŒè¯å’Œé”™è¯¯æç¤º
- é…ç½®çŠ¶æ€å¯è§†åŒ–
- å¯åŠ¨æ—¶é…ç½®æ£€æŸ¥

âœ… **é”™è¯¯å¤„ç†å’Œæ¢å¤**ï¼š
```python
# é”™è¯¯å¤„ç†æœºåˆ¶åˆ†æ
class ErrorHandler:
    def __init__(self):
        self.error_counts = {}
        self.recovery_strategies = {}
    
    def handle_error(self, error: Exception, context: str) -> Dict[str, Any]:
        """ç»Ÿä¸€é”™è¯¯å¤„ç†"""
        error_type = type(error).__name__
        error_key = f"{context}_{error_type}"
        
        # è®°å½•é”™è¯¯æ¬¡æ•°
        self.error_counts[error_key] = self.error_counts.get(error_key, 0) + 1
        
        # é€‰æ‹©æ¢å¤ç­–ç•¥
        recovery_strategy = self._select_recovery_strategy(error_type, context)
        
        # æ‰§è¡Œæ¢å¤ç­–ç•¥
        recovery_result = self._execute_recovery_strategy(recovery_strategy, error)
        
        return {
            "error": str(error),
            "error_type": error_type,
            "context": context,
            "error_count": self.error_counts[error_key],
            "recovery_strategy": recovery_strategy,
            "recovery_result": recovery_result
        }
    
    def _select_recovery_strategy(self, error_type: str, context: str) -> str:
        """é€‰æ‹©æ¢å¤ç­–ç•¥"""
        if error_type == "ConnectionError":
            return "retry_with_backoff"
        elif error_type == "TimeoutError":
            return "fallback_to_template"
        elif error_type == "ValidationError":
            return "use_default_values"
        else:
            return "log_and_continue"
```

**é”™è¯¯å¤„ç†ç‰¹ç‚¹**ï¼š
- é”™è¯¯åˆ†ç±»å’Œç»Ÿè®¡
- æ™ºèƒ½æ¢å¤ç­–ç•¥é€‰æ‹©
- é”™è¯¯ä¸Šä¸‹æ–‡è®°å½•
- æ¸è¿›å¼é™çº§å¤„ç†

**å¾…å®Œå–„è¿ç»´åŠŸèƒ½**ï¼š

ğŸ”§ **æ€§èƒ½ç›‘æ§å’ŒæŒ‡æ ‡**ï¼š
```python
# æ€§èƒ½ç›‘æ§å®ç°å»ºè®®
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            "query_count": 0,
            "avg_response_time": 0.0,
            "error_rate": 0.0,
            "ai_service_usage": {"claude": 0, "deepseek": 0}
        }
        self.start_time = time.time()
    
    def record_query(self, query_type: str, response_time: float, success: bool):
        """è®°å½•æŸ¥è¯¢æŒ‡æ ‡"""
        self.metrics["query_count"] += 1
        
        # æ›´æ–°å¹³å‡å“åº”æ—¶é—´
        current_avg = self.metrics["avg_response_time"]
        count = self.metrics["query_count"]
        self.metrics["avg_response_time"] = (current_avg * (count - 1) + response_time) / count
        
        # æ›´æ–°é”™è¯¯ç‡
        if not success:
            error_count = self.metrics.get("error_count", 0) + 1
            self.metrics["error_count"] = error_count
            self.metrics["error_rate"] = error_count / count
    
    def get_metrics(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        uptime = time.time() - self.start_time
        return {
            **self.metrics,
            "uptime": uptime,
            "queries_per_minute": self.metrics["query_count"] / (uptime / 60)
        }
```

ğŸ”§ **å‘Šè­¦å’Œé€šçŸ¥æœºåˆ¶**ï¼š
```python
# å‘Šè­¦ç³»ç»Ÿå®ç°å»ºè®®
class AlertSystem:
    def __init__(self):
        self.alert_rules = {
            "error_rate_threshold": 0.1,  # é”™è¯¯ç‡è¶…è¿‡10%
            "response_time_threshold": 5.0,  # å“åº”æ—¶é—´è¶…è¿‡5ç§’
            "ai_service_failure_threshold": 3  # AIæœåŠ¡è¿ç»­å¤±è´¥3æ¬¡
        }
        self.notification_channels = ["email", "slack", "webhook"]
    
    def check_alerts(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦å‘Šè­¦"""
        alerts = []
        
        # æ£€æŸ¥é”™è¯¯ç‡
        if metrics["error_rate"] > self.alert_rules["error_rate_threshold"]:
            alerts.append({
                "level": "WARNING",
                "message": f"é”™è¯¯ç‡è¿‡é«˜: {metrics['error_rate']:.2%}",
                "timestamp": datetime.now().isoformat()
            })
        
        # æ£€æŸ¥å“åº”æ—¶é—´
        if metrics["avg_response_time"] > self.alert_rules["response_time_threshold"]:
            alerts.append({
                "level": "WARNING",
                "message": f"å“åº”æ—¶é—´è¿‡é•¿: {metrics['avg_response_time']:.2f}ç§’",
                "timestamp": datetime.now().isoformat()
            })
        
        return alerts
    
    def send_notification(self, alert: Dict[str, Any]):
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        for channel in self.notification_channels:
            try:
                if channel == "email":
                    self._send_email_alert(alert)
                elif channel == "slack":
                    self._send_slack_alert(alert)
                elif channel == "webhook":
                    self._send_webhook_alert(alert)
            except Exception as e:
                logger.error(f"å‘é€{channel}å‘Šè­¦å¤±è´¥: {e}")
```

ğŸ”§ **è‡ªåŠ¨åŒ–æµ‹è¯•è¦†ç›–**ï¼š
```python
# è‡ªåŠ¨åŒ–æµ‹è¯•å®ç°å»ºè®®
class TestSuite:
    def __init__(self):
        self.test_cases = []
        self.test_results = []
    
    def add_test_case(self, test_name: str, test_func, expected_result):
        """æ·»åŠ æµ‹è¯•ç”¨ä¾‹"""
        self.test_cases.append({
            "name": test_name,
            "function": test_func,
            "expected": expected_result
        })
    
    def run_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        results = {
            "total": len(self.test_cases),
            "passed": 0,
            "failed": 0,
            "details": []
        }
        
        for test_case in self.test_cases:
            try:
                actual_result = test_case["function"]()
                passed = actual_result == test_case["expected"]
                
                if passed:
                    results["passed"] += 1
                else:
                    results["failed"] += 1
                
                results["details"].append({
                    "name": test_case["name"],
                    "passed": passed,
                    "expected": test_case["expected"],
                    "actual": actual_result
                })
                
            except Exception as e:
                results["failed"] += 1
                results["details"].append({
                    "name": test_case["name"],
                    "passed": False,
                    "error": str(e)
                })
        
        return results

# æµ‹è¯•ç”¨ä¾‹ç¤ºä¾‹
def test_database_connection():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    try:
        conn = psycopg2.connect(**db_config)
        conn.close()
        return True
    except Exception:
        return False

def test_ai_service_availability():
    """æµ‹è¯•AIæœåŠ¡å¯ç”¨æ€§"""
    return mcp_server.get_available_ai_services()["claude"]["available"]

# æ·»åŠ æµ‹è¯•ç”¨ä¾‹
test_suite = TestSuite()
test_suite.add_test_case("æ•°æ®åº“è¿æ¥", test_database_connection, True)
test_suite.add_test_case("ClaudeæœåŠ¡å¯ç”¨æ€§", test_ai_service_availability, True)

# è¿è¡Œæµ‹è¯•
test_results = test_suite.run_tests()
print(f"æµ‹è¯•ç»“æœ: {test_results['passed']}/{test_results['total']} é€šè¿‡")
```

### 7.2 ä»£ç è´¨é‡å®Œæ•´æ€§æ·±åº¦åˆ†æ

#### 7.2.1 ä»£ç ç»“æ„åˆ†æ
**ä¼˜åŠ¿åˆ†æ**ï¼š

âœ… **æ¸…æ™°çš„æ¨¡å—åˆ†ç¦»**ï¼š
```python
# æ¨¡å—ç»“æ„åˆ†æ
mcp-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # ä¸»åº”ç”¨å…¥å£
â”‚   â”œâ”€â”€ services/            # ä¸šåŠ¡æœåŠ¡å±‚
â”‚   â”‚   â”œâ”€â”€ mcp_server.py   # MCPæœåŠ¡å™¨æ ¸å¿ƒ
â”‚   â”‚   â”œâ”€â”€ mcp_tools.py    # MCPå·¥å…·é›†
â”‚   â”‚   â”œâ”€â”€ claude_ai_service.py  # Claude AIæœåŠ¡
â”‚   â”‚   â”œâ”€â”€ ai_service.py   # DeepSeek AIæœåŠ¡
â”‚   â”‚   â””â”€â”€ chart_service.py # å›¾è¡¨ç”ŸæˆæœåŠ¡
â”‚   â””â”€â”€ api/                # APIæ¥å£å±‚
â”œâ”€â”€ requirements.txt         # ä¾èµ–ç®¡ç†
â”œâ”€â”€ Dockerfile              # å®¹å™¨åŒ–é…ç½®
â””â”€â”€ railway.toml            # éƒ¨ç½²é…ç½®
```

**æ¨¡å—èŒè´£åˆ†ç¦»**ï¼š
- **main.py**ï¼šåº”ç”¨å¯åŠ¨ã€é…ç½®ç®¡ç†ã€æœåŠ¡åˆå§‹åŒ–
- **mcp_server.py**ï¼šæ ¸å¿ƒä¸šåŠ¡é€»è¾‘ã€AIæœåŠ¡åè°ƒ
- **mcp_tools.py**ï¼šæ•°æ®åº“æ“ä½œå·¥å…·ã€MCPåè®®å®ç°
- **ai_service.py**ï¼šAIæœåŠ¡é›†æˆã€è‡ªç„¶è¯­è¨€å¤„ç†
- **chart_service.py**ï¼šå›¾è¡¨ç”Ÿæˆã€æ•°æ®å¯è§†åŒ–

âœ… **ç»Ÿä¸€çš„é”™è¯¯å¤„ç†**ï¼š
```python
# é”™è¯¯å¤„ç†æ¨¡å¼åˆ†æ
class ErrorHandlingPattern:
    """ç»Ÿä¸€çš„é”™è¯¯å¤„ç†æ¨¡å¼"""
    
    @staticmethod
    def handle_database_error(func):
        """æ•°æ®åº“é”™è¯¯å¤„ç†è£…é¥°å™¨"""
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except psycopg2.OperationalError as e:
                logger.error(f"æ•°æ®åº“è¿æ¥é”™è¯¯: {e}")
                return {"error": "æ•°æ®åº“è¿æ¥å¤±è´¥", "success": False}
            except psycopg2.Error as e:
                logger.error(f"æ•°æ®åº“æ“ä½œé”™è¯¯: {e}")
                return {"error": "æ•°æ®åº“æ“ä½œå¤±è´¥", "success": False}
            except Exception as e:
                logger.error(f"æœªçŸ¥é”™è¯¯: {e}")
                return {"error": "ç³»ç»Ÿå†…éƒ¨é”™è¯¯", "success": False}
        return wrapper
    
    @staticmethod
    def handle_ai_service_error(func):
        """AIæœåŠ¡é”™è¯¯å¤„ç†è£…é¥°å™¨"""
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except httpx.TimeoutException:
                logger.warning("AIæœåŠ¡è¶…æ—¶ï¼Œä½¿ç”¨å¤‡ç”¨æœåŠ¡")
                return {"error": "AIæœåŠ¡è¶…æ—¶", "fallback": True}
            except httpx.HTTPStatusError as e:
                logger.error(f"AIæœåŠ¡HTTPé”™è¯¯: {e.response.status_code}")
                return {"error": f"AIæœåŠ¡é”™è¯¯: {e.response.status_code}", "success": False}
            except Exception as e:
                logger.error(f"AIæœåŠ¡æœªçŸ¥é”™è¯¯: {e}")
                return {"error": "AIæœåŠ¡å†…éƒ¨é”™è¯¯", "success": False}
        return wrapper

# ä½¿ç”¨ç¤ºä¾‹
class MCPServer:
    @ErrorHandlingPattern.handle_database_error
    def execute_sql(self, sql: str) -> Dict[str, Any]:
        """æ‰§è¡ŒSQLæŸ¥è¯¢"""
        # å®ç°é€»è¾‘
        pass
    
    @ErrorHandlingPattern.handle_ai_service_error
    def analyze_with_ai(self, question: str) -> Dict[str, Any]:
        """AIåˆ†æé—®é¢˜"""
        # å®ç°é€»è¾‘
        pass
```

âœ… **å®Œå–„çš„æ—¥å¿—è®°å½•**ï¼š
```python
# æ—¥å¿—è®°å½•æ¨¡å¼åˆ†æ
class LoggingPattern:
    """ç»Ÿä¸€çš„æ—¥å¿—è®°å½•æ¨¡å¼"""
    
    @staticmethod
    def log_function_entry(func):
        """å‡½æ•°å…¥å£æ—¥å¿—è£…é¥°å™¨"""
        def wrapper(*args, **kwargs):
            logger.info(f"ğŸš€ è¿›å…¥å‡½æ•°: {func.__name__}")
            logger.debug(f"å‚æ•°: args={args}, kwargs={kwargs}")
            return func(*args, **kwargs)
        return wrapper
    
    @staticmethod
    def log_function_exit(func):
        """å‡½æ•°é€€å‡ºæ—¥å¿—è£…é¥°å™¨"""
        def wrapper(*args, **kwargs):
            result = func(*args, **kwargs)
            logger.info(f"âœ… å‡½æ•°å®Œæˆ: {func.__name__}")
            logger.debug(f"è¿”å›å€¼: {result}")
            return result
        return wrapper
    
    @staticmethod
    def log_performance(func):
        """æ€§èƒ½æ—¥å¿—è£…é¥°å™¨"""
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            execution_time = time.time() - start_time
            logger.info(f"â±ï¸ å‡½æ•°æ‰§è¡Œæ—¶é—´: {func.__name__} - {execution_time:.3f}ç§’")
            return result
        return wrapper

# ä½¿ç”¨ç¤ºä¾‹
class MCPServer:
    @LoggingPattern.log_function_entry
    @LoggingPattern.log_performance
    @LoggingPattern.log_function_exit
    def process_natural_language_query(self, question: str) -> Dict[str, Any]:
        """å¤„ç†è‡ªç„¶è¯­è¨€æŸ¥è¯¢"""
        # å®ç°é€»è¾‘
        pass
```

âœ… **ç±»å‹æ³¨è§£æ”¯æŒ**ï¼š
```python
# ç±»å‹æ³¨è§£åˆ†æ
from typing import Dict, List, Any, Optional, Union
from datetime import datetime

class TypeAnnotationExample:
    """ç±»å‹æ³¨è§£ç¤ºä¾‹"""
    
    def __init__(self, config: Dict[str, Any]) -> None:
        self.config: Dict[str, Any] = config
        self.services: List[str] = []
        self.last_update: Optional[datetime] = None
    
    def get_service_status(self, service_name: str) -> Dict[str, Union[bool, str]]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        return {
            "available": service_name in self.services,
            "status": "active" if service_name in self.services else "inactive"
        }
    
    def update_services(self, new_services: List[str]) -> bool:
        """æ›´æ–°æœåŠ¡åˆ—è¡¨"""
        try:
            self.services = new_services.copy()
            self.last_update = datetime.now()
            return True
        except Exception as e:
            logger.error(f"æ›´æ–°æœåŠ¡å¤±è´¥: {e}")
            return False
```

**æ”¹è¿›ç©ºé—´åˆ†æ**ï¼š

ğŸ”§ **å•å…ƒæµ‹è¯•è¦†ç›–ç‡**ï¼š
```python
# å•å…ƒæµ‹è¯•è¦†ç›–ç‡åˆ†æ
import pytest
from unittest.mock import Mock, patch

class TestMCPServer:
    """MCPæœåŠ¡å™¨å•å…ƒæµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.mock_ai_service = Mock()
        self.mock_chart_generator = Mock()
        self.mcp_server = MCPServer(self.mock_ai_service, self.mock_chart_generator)
    
    def test_initialization(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        assert self.mcp_server.ai_service == self.mock_ai_service
        assert self.mcp_server.chart_generator == self.mock_chart_generator
        assert hasattr(self.mcp_server, 'mcp_tools')
    
    @patch('psycopg2.connect')
    def test_database_connection(self, mock_connect):
        """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
        mock_conn = Mock()
        mock_connect.return_value = mock_conn
        
        result = self.mcp_server._test_database_connection()
        
        assert result is True
        mock_connect.assert_called_once()
        mock_conn.close.assert_called_once()
    
    def test_ai_service_selection(self):
        """æµ‹è¯•AIæœåŠ¡é€‰æ‹©"""
        # æµ‹è¯•Claudeä¼˜å…ˆ
        with patch.dict(os.environ, {'CLAUDE_API_KEY': 'test_key'}):
            mcp_server = MCPServer(self.mock_ai_service, self.mock_chart_generator)
            assert mcp_server.claude_ai is not None
        
        # æµ‹è¯•DeepSeekå¤‡ç”¨
        with patch.dict(os.environ, {}, clear=True):
            mcp_server = MCPServer(self.mock_ai_service, self.mock_chart_generator)
            assert mcp_server.claude_ai is None

# æµ‹è¯•è¦†ç›–ç‡é…ç½®
# pytest.ini
[tool:pytest]
addopts = --cov=app --cov-report=html --cov-report=term-missing
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
```

ğŸ”§ **ä»£ç æ–‡æ¡£å®Œæ•´æ€§**ï¼š
```python
# ä»£ç æ–‡æ¡£æ”¹è¿›å»ºè®®
class MCPServer:
    """
    MCPæœåŠ¡å™¨æ ¸å¿ƒæœåŠ¡
    
    è´Ÿè´£åè°ƒAIæœåŠ¡ã€æ•°æ®åº“å·¥å…·å’Œå›¾è¡¨ç”Ÿæˆå™¨ï¼Œæä¾›ç»Ÿä¸€çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ¥å£ã€‚
    
    Attributes:
        ai_service (DeepSeekAIService): DeepSeek AIæœåŠ¡å®ä¾‹
        chart_generator (ChartConfigGenerator): å›¾è¡¨é…ç½®ç”Ÿæˆå™¨
        mcp_tools (MCPTools): MCPå·¥å…·é›†åˆ
        claude_ai (Optional[ClaudeAIService]): Claude AIæœåŠ¡å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        db_config (Dict[str, Any]): æ•°æ®åº“è¿æ¥é…ç½®
    
    Example:
        >>> ai_service = DeepSeekAIService()
        >>> chart_generator = ChartConfigGenerator()
        >>> mcp_server = MCPServer(ai_service, chart_generator)
        >>> result = await mcp_server.process_natural_language_query("æŸ¥è¯¢èµ„äº§åˆ†å¸ƒ")
    """
    
    def __init__(self, ai_service: DeepSeekAIService, chart_generator: ChartConfigGenerator):
        """
        åˆå§‹åŒ–MCPæœåŠ¡å™¨
        
        Args:
            ai_service: DeepSeek AIæœåŠ¡å®ä¾‹
            chart_generator: å›¾è¡¨é…ç½®ç”Ÿæˆå™¨å®ä¾‹
        
        Raises:
            ValueError: å¦‚æœå¿…éœ€çš„æœåŠ¡æœªæä¾›
        """
        if not ai_service:
            raise ValueError("AIæœåŠ¡ä¸èƒ½ä¸ºç©º")
        if not chart_generator:
            raise ValueError("å›¾è¡¨ç”Ÿæˆå™¨ä¸èƒ½ä¸ºç©º")
        
        self.ai_service = ai_service
        self.chart_generator = chart_generator
        self._initialize_components()
    
    async def process_natural_language_query(self, question: str, max_rows: int = 1000) -> Dict[str, Any]:
        """
        å¤„ç†è‡ªç„¶è¯­è¨€æŸ¥è¯¢
        
        å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºSQLæŸ¥è¯¢å¹¶æ‰§è¡Œï¼Œæ”¯æŒå¤šç§AIæœåŠ¡å’Œå›é€€æœºåˆ¶ã€‚
        
        Args:
            question: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€é—®é¢˜
            max_rows: æŸ¥è¯¢ç»“æœçš„æœ€å¤§è¡Œæ•°ï¼Œé»˜è®¤1000
        
        Returns:
            åŒ…å«æŸ¥è¯¢ç»“æœçš„å­—å…¸ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
            {
                "success": bool,
                "sql": str,
                "data": List[Dict[str, Any]],
                "execution_time": float,
                "method": str
            }
        
        Raises:
            ValueError: å¦‚æœé—®é¢˜ä¸ºç©ºæˆ–æ— æ•ˆ
            ConnectionError: å¦‚æœæ•°æ®åº“è¿æ¥å¤±è´¥
        
        Example:
            >>> result = await mcp_server.process_natural_language_query(
            ...     "å¸®æˆ‘åˆ†æå„å¹³å°èµ„äº§åˆ†å¸ƒ",
            ...     max_rows=100
            ... )
            >>> print(f"æŸ¥è¯¢æˆåŠŸ: {result['success']}")
            >>> print(f"è¿”å›è¡Œæ•°: {len(result['data'])}")
        """
        if not question or not question.strip():
            raise ValueError("é—®é¢˜ä¸èƒ½ä¸ºç©º")
        
        start_time = time.time()
        logger.info(f"ğŸ” å¼€å§‹å¤„ç†è‡ªç„¶è¯­è¨€æŸ¥è¯¢: {question}")
        
        try:
            # å°è¯•AIåˆ†æ
            result = await self._try_ai_analysis(question, max_rows)
            if result:
                return result
            
            # å°è¯•æ¨¡æ¿åŒ¹é…
            result = await self._try_template_matching(question, max_rows)
            if result:
                return result
            
            # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            return self._fallback_to_mock_data(start_time)
            
        except Exception as e:
            logger.error(f"å¤„ç†æŸ¥è¯¢å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "execution_time": time.time() - start_time
            }
```

ğŸ”§ **æ€§èƒ½ä¼˜åŒ–**ï¼š
```python
# æ€§èƒ½ä¼˜åŒ–å»ºè®®
class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.query_cache = {}
        self.connection_pool = None
    
    def optimize_database_queries(self, sql: str) -> str:
        """ä¼˜åŒ–SQLæŸ¥è¯¢"""
        # æ·»åŠ æŸ¥è¯¢æç¤º
        if "SELECT" in sql.upper() and "LIMIT" not in sql.upper():
            sql += " LIMIT 1000"
        
        # ä¼˜åŒ–JOINæŸ¥è¯¢
        if "JOIN" in sql.upper():
            sql = self._optimize_joins(sql)
        
        return sql
    
    def _optimize_joins(self, sql: str) -> str:
        """ä¼˜åŒ–JOINæŸ¥è¯¢"""
        # æ·»åŠ JOINæç¤º
        if "JOIN" in sql.upper():
            sql = sql.replace("JOIN", "/*+ USE_HASH(t) */ JOIN")
        return sql
    
    def implement_connection_pooling(self):
        """å®ç°è¿æ¥æ± """
        from psycopg2.pool import SimpleConnectionPool
        
        self.connection_pool = SimpleConnectionPool(
            minconn=1,
            maxconn=20,
            **self.db_config
        )
    
    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        if self.connection_pool:
            return self.connection_pool.getconn()
        else:
            return psycopg2.connect(**self.db_config)
    
    def return_connection(self, conn):
        """å½’è¿˜æ•°æ®åº“è¿æ¥"""
        if self.connection_pool:
            self.connection_pool.putconn(conn)
        else:
            conn.close()

# ä½¿ç”¨ç¤ºä¾‹
optimizer = PerformanceOptimizer()
optimizer.implement_connection_pooling()

# åœ¨MCPå·¥å…·ä¸­ä½¿ç”¨
def _query_database(self, sql: str, max_rows: int = 1000) -> Dict[str, Any]:
    """æ‰§è¡ŒSQLæŸ¥è¯¢ - ä¼˜åŒ–ç‰ˆæœ¬"""
    try:
        # ä¼˜åŒ–SQL
        optimized_sql = optimizer.optimize_database_queries(sql)
        
        # ä½¿ç”¨è¿æ¥æ± 
        conn = optimizer.get_connection()
        try:
            with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                cursor.execute(optimized_sql)
                rows = cursor.fetchall()
                
                return {
                    "success": True,
                    "sql": optimized_sql,
                    "data": [dict(row) for row in rows],
                    "row_count": len(rows)
                }
        finally:
            optimizer.return_connection(conn)
            
    except Exception as e:
        logger.error(f"SQLæŸ¥è¯¢å¤±è´¥: {e}")
        return {"error": str(e), "success": False}
```

### 7.3 å®Œæ•´æ€§æ”¹è¿›ä¼˜å…ˆçº§

#### 7.3.1 é«˜ä¼˜å…ˆçº§ï¼ˆç«‹å³å®æ–½ï¼‰
1. **å®Œå–„å•å…ƒæµ‹è¯•** - æé«˜ä»£ç è´¨é‡å’Œç¨³å®šæ€§
2. **å®ç°æ€§èƒ½ç›‘æ§** - å®æ—¶ç›‘æ§æœåŠ¡æ€§èƒ½
3. **æ·»åŠ å‘Šè­¦æœºåˆ¶** - åŠæ—¶å‘ç°é—®é¢˜

#### 7.3.2 ä¸­ä¼˜å…ˆçº§ï¼ˆ1-2å‘¨å†…ï¼‰
1. **ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢** - æé«˜æŸ¥è¯¢æ€§èƒ½
2. **å®Œå–„é”™è¯¯å¤„ç†** - æé«˜ç³»ç»Ÿç¨³å®šæ€§
3. **æ”¹è¿›æ—¥å¿—ç³»ç»Ÿ** - ä¾¿äºé—®é¢˜æ’æŸ¥

#### 7.3.3 ä½ä¼˜å…ˆçº§ï¼ˆ1ä¸ªæœˆå†…ï¼‰
1. **ä»£ç é‡æ„** - æé«˜ä»£ç å¯ç»´æŠ¤æ€§
2. **æ–‡æ¡£å®Œå–„** - æé«˜å¼€å‘æ•ˆç‡
3. **æ€§èƒ½åŸºå‡†æµ‹è¯•** - å»ºç«‹æ€§èƒ½åŸºçº¿

---

## ç¬¬å…«éƒ¨åˆ†ï¼šæ€»ç»“ä¸å»ºè®®

### 8.1 æ€»ä½“è¯„ä¼°æ·±åº¦åˆ†æ

#### 8.1.1 æŠ€æœ¯æ¶æ„è¯„åˆ†è¯¦è§£
**è¯„åˆ†æ ‡å‡†è¯´æ˜**ï¼š
- **9-10åˆ†**ï¼šä¼˜ç§€ï¼Œè¾¾åˆ°ç”Ÿäº§ç¯å¢ƒæ ‡å‡†
- **7-8åˆ†**ï¼šè‰¯å¥½ï¼ŒåŸºæœ¬æ»¡è¶³éœ€æ±‚ï¼Œéœ€è¦æ”¹è¿›
- **5-6åˆ†**ï¼šä¸€èˆ¬ï¼Œå­˜åœ¨æ˜æ˜¾é—®é¢˜
- **1-4åˆ†**ï¼šè¾ƒå·®ï¼Œä¸å»ºè®®ä½¿ç”¨

**è¯¦ç»†è¯„åˆ†åˆ†æ**ï¼š

**æ¶æ„è®¾è®¡ï¼š9/10** âœ…
- **åˆ†å±‚æ¸…æ™°**ï¼šAPIå±‚ã€æœåŠ¡å±‚ã€AIå±‚ã€å·¥å…·å±‚ã€æ•°æ®å±‚èŒè´£æ˜ç¡®
- **èŒè´£åˆ†ç¦»**ï¼šæ¯ä¸ªç»„ä»¶åªè´Ÿè´£ç‰¹å®šåŠŸèƒ½ï¼Œè€¦åˆåº¦ä½
- **è®¾è®¡æ¨¡å¼**ï¼šä½¿ç”¨ä¾èµ–æ³¨å…¥ã€å·¥å‚æ¨¡å¼ç­‰è®¾è®¡æ¨¡å¼
- **æ‰©å±•æ€§**ï¼šæ”¯æŒç»„ä»¶çš„åŠ¨æ€æ›¿æ¢å’Œé…ç½®

**AIé›†æˆï¼š9/10** âœ…
- **åŒæ¨¡å‹æ”¯æŒ**ï¼šClaude + DeepSeekï¼Œé£é™©åˆ†æ•£
- **æ™ºèƒ½å›é€€**ï¼šä¸‰å±‚å›é€€æœºåˆ¶ï¼Œç¡®ä¿æœåŠ¡å¯ç”¨æ€§
- **å·¥å…·è°ƒç”¨**ï¼šClaudeæ”¯æŒMCPå·¥å…·è°ƒç”¨ï¼Œç†è§£èƒ½åŠ›å¼º
- **æˆæœ¬ä¼˜åŒ–**ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚çš„æ¨¡å‹

**å®‰å…¨æ€§ï¼š7/10** âš ï¸
- **åŸºç¡€é˜²æŠ¤**ï¼šå‚æ•°åŒ–æŸ¥è¯¢ã€ç¯å¢ƒå˜é‡é…ç½®
- **ä¸»è¦é—®é¢˜**ï¼šç¼ºå°‘APIè®¤è¯ã€CORSé…ç½®è¿‡å®½ã€SQLæ‰§è¡Œæƒé™è¿‡é«˜
- **é£é™©ç­‰çº§**ï¼šä¸­ç­‰é£é™©ï¼Œé€‚åˆå†…éƒ¨ç¯å¢ƒä½¿ç”¨

**é€šç”¨æ€§ï¼š8/10** âœ…
- **æ ‡å‡†åŒ–è®¾è®¡**ï¼šéµå¾ªMCPåè®®è§„èŒƒ
- **æ¨¡å—åŒ–æ¶æ„**ï¼šæ˜“äºæ‰©å±•å’Œç»´æŠ¤
- **ä¸šåŠ¡é™åˆ¶**ï¼šå½“å‰ä¸»è¦é’ˆå¯¹è´¢åŠ¡æ•°æ®ï¼Œéœ€è¦é€šç”¨åŒ–æ”¹é€ 

**å®Œæ•´æ€§ï¼š8/10** âœ…
- **åŠŸèƒ½å®Œæ•´**ï¼šè¦†ç›–æ ¸å¿ƒæŸ¥è¯¢å’Œåˆ†æéœ€æ±‚
- **è¿ç»´æ”¯æŒ**ï¼šå¥åº·æ£€æŸ¥ã€æ—¥å¿—è®°å½•ã€é”™è¯¯å¤„ç†
- **å¾…å®Œå–„**ï¼šæ€§èƒ½ç›‘æ§ã€å‘Šè­¦æœºåˆ¶ã€è‡ªåŠ¨åŒ–æµ‹è¯•

**ç»¼åˆè¯„åˆ†è®¡ç®—**ï¼š
```
ç»¼åˆè¯„åˆ† = (9 + 9 + 7 + 8 + 8) / 5 = 8.2/10
```

**è¯„åˆ†ç­‰çº§**ï¼š**ä¼˜ç§€** - è¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯æ¶æ„è‰¯å¥½ã€åŠŸèƒ½å®Œæ•´çš„MCPæœåŠ¡

#### 8.1.2 é€‚ç”¨åœºæ™¯æ·±åº¦è¯„ä¼°

**éå¸¸é€‚åˆçš„åœºæ™¯** ğŸ¯ï¼š

1. **å†…éƒ¨è´¢åŠ¡æ•°æ®åˆ†æå¹³å°**
   - **ä¼˜åŠ¿åŒ¹é…**ï¼šä¸“é—¨é’ˆå¯¹è´¢åŠ¡æ•°æ®è®¾è®¡ï¼ŒæŸ¥è¯¢æ¨¡æ¿å®Œæ•´
   - **å®‰å…¨è¦æ±‚**ï¼šå†…éƒ¨ç½‘ç»œç¯å¢ƒï¼Œå®‰å…¨é£é™©å¯æ§
   - **ç”¨æˆ·ç¾¤ä½“**ï¼šè´¢åŠ¡åˆ†æå¸ˆã€ç®¡ç†å±‚ï¼ŒæŠ€æœ¯é—¨æ§›ä½

2. **å—æ§ç¯å¢ƒä¸‹çš„æ•°æ®æŸ¥è¯¢æœåŠ¡**
   - **ç½‘ç»œç¯å¢ƒ**ï¼šå†…ç½‘éƒ¨ç½²ï¼Œæ— å¤–éƒ¨è®¿é—®
   - **ç”¨æˆ·æƒé™**ï¼šå†…éƒ¨ç”¨æˆ·ï¼Œæƒé™å¯æ§
   - **æ•°æ®æ•æ„Ÿåº¦**ï¼šä¸­ç­‰æ•æ„Ÿåº¦ï¼Œå½“å‰å®‰å…¨çº§åˆ«å¯æ¥å—

3. **AIé©±åŠ¨çš„æ•°æ®åˆ†æå·¥å…·**
   - **æŠ€æœ¯èƒ½åŠ›**ï¼šåŒAIæ¨¡å‹æ”¯æŒï¼Œæ™ºèƒ½åˆ†æèƒ½åŠ›å¼º
   - **å·¥å…·é›†æˆ**ï¼šMCPå·¥å…·é›†å®Œæ•´ï¼Œæ”¯æŒå¤æ‚æŸ¥è¯¢
   - **ç”¨æˆ·ä½“éªŒ**ï¼šè‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œé™ä½ä½¿ç”¨é—¨æ§›

**éœ€è¦æ”¹è¿›åé€‚ç”¨çš„åœºæ™¯** ğŸ”§ï¼š

1. **å…¬å¼€äº’è”ç½‘ç¯å¢ƒ**
   - **å®‰å…¨è¦æ±‚**ï¼šéœ€è¦å®ç°APIè®¤è¯ã€é€Ÿç‡é™åˆ¶
   - **è®¿é—®æ§åˆ¶**ï¼šéœ€è¦ç”¨æˆ·æƒé™ç®¡ç†
   - **ç›‘æ§å‘Šè­¦**ï¼šéœ€è¦å®æ—¶å®‰å…¨ç›‘æ§

2. **å¤šç§Ÿæˆ·SaaSæœåŠ¡**
   - **æ¶æ„æ”¹é€ **ï¼šéœ€è¦æ”¯æŒå¤šç§Ÿæˆ·éš”ç¦»
   - **æƒé™ç®¡ç†**ï¼šéœ€è¦ç»†ç²’åº¦æƒé™æ§åˆ¶
   - **è®¡è´¹ç³»ç»Ÿ**ï¼šéœ€è¦APIè°ƒç”¨è®¡è´¹

3. **é«˜å®‰å…¨æ€§è¦æ±‚çš„åœºæ™¯**
   - **å®‰å…¨åŠ å›º**ï¼šéœ€è¦SQLç™½åå•ã€æ•°æ®è„±æ•
   - **å®¡è®¡æ—¥å¿—**ï¼šéœ€è¦å®Œæ•´çš„æ“ä½œå®¡è®¡
   - **åˆè§„è¦æ±‚**ï¼šéœ€è¦æ»¡è¶³ç›¸å…³å®‰å…¨æ ‡å‡†

#### 8.1.3 æŠ€æœ¯æˆç†Ÿåº¦è¯„ä¼°

**æŠ€æœ¯æ ˆæˆç†Ÿåº¦**ï¼š
- **FastAPI**ï¼šâ­â­â­â­â­ æˆç†Ÿç¨³å®šï¼Œç¤¾åŒºæ´»è·ƒ
- **PostgreSQL**ï¼šâ­â­â­â­â­ ä¼ä¸šçº§æ•°æ®åº“ï¼ŒåŠŸèƒ½å®Œå–„
- **Claude API**ï¼šâ­â­â­â­ å®˜æ–¹æ”¯æŒï¼ŒåŠŸèƒ½å¼ºå¤§
- **DeepSeek API**ï¼šâ­â­â­â­ æ€§èƒ½ä¼˜ç§€ï¼Œæˆæœ¬è¾ƒä½
- **Docker**ï¼šâ­â­â­â­â­ å®¹å™¨åŒ–æ ‡å‡†ï¼Œéƒ¨ç½²ç®€å•

**ä»£ç è´¨é‡æˆç†Ÿåº¦**ï¼š
- **æ¶æ„è®¾è®¡**ï¼šâ­â­â­â­â­ åˆ†å±‚æ¸…æ™°ï¼ŒèŒè´£åˆ†ç¦»
- **é”™è¯¯å¤„ç†**ï¼šâ­â­â­â­ ç»Ÿä¸€å¤„ç†ï¼Œå›é€€æœºåˆ¶
- **æ—¥å¿—è®°å½•**ï¼šâ­â­â­â­ ç»“æ„åŒ–æ—¥å¿—ï¼Œä¾¿äºæ’æŸ¥
- **æµ‹è¯•è¦†ç›–**ï¼šâ­â­â­ åŸºç¡€æµ‹è¯•ï¼Œéœ€è¦å®Œå–„
- **æ–‡æ¡£è´¨é‡**ï¼šâ­â­â­ åŸºæœ¬æ–‡æ¡£ï¼Œéœ€è¦è¡¥å……

### 8.2 ä¼˜å…ˆçº§æ”¹è¿›å»ºè®®è¯¦ç»†åˆ†æ

#### 8.2.1 é«˜ä¼˜å…ˆçº§ï¼ˆå®‰å…¨ç›¸å…³ï¼‰- ç«‹å³å®æ–½

**1. å®ç°APIè®¤è¯æœºåˆ¶**
**é£é™©ç­‰çº§**ï¼šğŸ”´ é«˜å±
**å½±å“èŒƒå›´**ï¼šæ•´ä¸ªç³»ç»Ÿ
**å®æ–½éš¾åº¦**ï¼šä¸­ç­‰
**å…·ä½“æ–¹æ¡ˆ**ï¼š
```python
# JWTè®¤è¯å®ç°
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import jwt

class JWTAuthHandler:
    def __init__(self):
        self.secret_key = os.getenv("JWT_SECRET_KEY")
        self.algorithm = "HS256"
    
    def create_token(self, user_id: str) -> str:
        """åˆ›å»ºJWTä»¤ç‰Œ"""
        payload = {"user_id": user_id, "exp": datetime.utcnow() + timedelta(hours=24)}
        return jwt.encode(payload, self.secret_key, algorithm=self.algorithm)
    
    def verify_token(self, token: str) -> dict:
        """éªŒè¯JWTä»¤ç‰Œ"""
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            return payload
        except jwt.ExpiredSignatureError:
            raise HTTPException(status_code=401, detail="ä»¤ç‰Œå·²è¿‡æœŸ")
        except jwt.JWTError:
            raise HTTPException(status_code=401, detail="æ— æ•ˆä»¤ç‰Œ")

# ä½¿ç”¨ç¤ºä¾‹
@app.post("/api/query")
async def query_database(
    question: str,
    credentials: HTTPAuthorizationCredentials = Depends(HTTPBearer())
):
    """å—ä¿æŠ¤çš„æŸ¥è¯¢æ¥å£"""
    auth_handler = JWTAuthHandler()
    payload = auth_handler.verify_token(credentials.credentials)
    user_id = payload.get("user_id")
    
    # æ‰§è¡ŒæŸ¥è¯¢é€»è¾‘
    result = await mcp_server.process_natural_language_query(question)
    return result
```

**2. åŠ å¼ºSQLæ‰§è¡Œå®‰å…¨**
**é£é™©ç­‰çº§**ï¼šğŸ”´ é«˜å±
**å½±å“èŒƒå›´**ï¼šæ•°æ®åº“å®‰å…¨
**å®æ–½éš¾åº¦**ï¼šä¸­ç­‰
**å…·ä½“æ–¹æ¡ˆ**ï¼š
```python
# SQLç™½åå•éªŒè¯å™¨
class SQLSecurityValidator:
    def __init__(self):
        self.allowed_operations = ['SELECT', 'WITH']
        self.allowed_tables = ['asset_snapshot', 'transaction_history']
        self.allowed_functions = ['COUNT', 'SUM', 'AVG', 'MAX', 'MIN']
    
    def validate_sql(self, sql: str) -> bool:
        """éªŒè¯SQLå®‰å…¨æ€§"""
        sql_upper = sql.upper().strip()
        
        # æ£€æŸ¥æ“ä½œç±»å‹
        if not any(op in sql_upper for op in self.allowed_operations):
            return False
        
        # æ£€æŸ¥è¡¨å
        if not any(table in sql_upper for table in self.allowed_tables):
            return False
        
        # æ£€æŸ¥å±é™©å…³é”®å­—
        dangerous_keywords = ['DROP', 'DELETE', 'TRUNCATE', 'ALTER', 'CREATE']
        if any(keyword in sql_upper for keyword in dangerous_keywords):
            return False
        
        return True

# ä½¿ç”¨ç¤ºä¾‹
def execute_sql_safely(sql: str) -> Dict[str, Any]:
    """å®‰å…¨æ‰§è¡ŒSQL"""
    validator = SQLSecurityValidator()
    
    if not validator.validate_sql(sql):
        return {"error": "SQLå®‰å…¨æ£€æŸ¥å¤±è´¥", "success": False}
    
    # æ‰§è¡ŒSQL
    return execute_sql(sql)
```

**3. é™åˆ¶CORSæ¥æº**
**é£é™©ç­‰çº§**ï¼šğŸŸ¡ ä¸­å±
**å½±å“èŒƒå›´**ï¼šå‰ç«¯å®‰å…¨
**å®æ–½éš¾åº¦**ï¼šç®€å•
**å…·ä½“æ–¹æ¡ˆ**ï¼š
```python
# å®‰å…¨çš„CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://yourdomain.com",
        "https://app.yourdomain.com",
        "http://localhost:3000"  # ä»…å¼€å‘ç¯å¢ƒ
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["Authorization", "Content-Type"],
    expose_headers=["X-Total-Count"]
)
```

#### 8.2.2 ä¸­ä¼˜å…ˆçº§ï¼ˆåŠŸèƒ½å®Œå–„ï¼‰- 1-2å‘¨å†…

**1. æ·»åŠ APIé€Ÿç‡é™åˆ¶**
**å®æ–½éš¾åº¦**ï¼šç®€å•
**å…·ä½“æ–¹æ¡ˆ**ï¼š
```python
# é€Ÿç‡é™åˆ¶å®ç°
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter

@app.post("/api/query")
@limiter.limit("10/minute")  # æ¯åˆ†é’Ÿæœ€å¤š10æ¬¡è¯·æ±‚
async def query_database(question: str):
    """å—é€Ÿç‡é™åˆ¶ä¿æŠ¤çš„æŸ¥è¯¢æ¥å£"""
    # å®ç°é€»è¾‘
    pass
```

**2. å®ç°ç›‘æ§å‘Šè­¦**
**å®æ–½éš¾åº¦**ï¼šä¸­ç­‰
**å…·ä½“æ–¹æ¡ˆ**ï¼š
```python
# ç›‘æ§å‘Šè­¦ç³»ç»Ÿ
class MonitoringSystem:
    def __init__(self):
        self.metrics = {}
        self.alert_rules = {
            "error_rate": 0.1,  # é”™è¯¯ç‡è¶…è¿‡10%
            "response_time": 5.0  # å“åº”æ—¶é—´è¶…è¿‡5ç§’
        }
    
    def record_metric(self, name: str, value: float):
        """è®°å½•æŒ‡æ ‡"""
        if name not in self.metrics:
            self.metrics[name] = []
        self.metrics[name].append(value)
    
    def check_alerts(self) -> List[Dict[str, Any]]:
        """æ£€æŸ¥å‘Šè­¦"""
        alerts = []
        
        # æ£€æŸ¥é”™è¯¯ç‡
        if "error_rate" in self.metrics:
            avg_error_rate = sum(self.metrics["error_rate"]) / len(self.metrics["error_rate"])
            if avg_error_rate > self.alert_rules["error_rate"]:
                alerts.append({
                    "level": "WARNING",
                    "message": f"é”™è¯¯ç‡è¿‡é«˜: {avg_error_rate:.2%}"
                })
        
        return alerts
```

**3. å®Œå–„å•å…ƒæµ‹è¯•**
**å®æ–½éš¾åº¦**ï¼šä¸­ç­‰
**å…·ä½“æ–¹æ¡ˆ**ï¼š
```python
# å•å…ƒæµ‹è¯•ç¤ºä¾‹
import pytest
from unittest.mock import Mock, patch

class TestMCPServer:
    def setup_method(self):
        self.mock_ai_service = Mock()
        self.mock_chart_generator = Mock()
        self.mcp_server = MCPServer(self.mock_ai_service, self.mock_chart_generator)
    
    def test_initialization(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        assert self.mcp_server.ai_service == self.mock_ai_service
        assert self.mcp_server.chart_generator == self.mock_chart_generator
    
    @patch('psycopg2.connect')
    def test_database_connection(self, mock_connect):
        """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
        mock_conn = Mock()
        mock_connect.return_value = mock_conn
        
        result = self.mcp_server._test_database_connection()
        assert result is True
        mock_connect.assert_called_once()
```

#### 8.2.3 ä½ä¼˜å…ˆçº§ï¼ˆä¼˜åŒ–æå‡ï¼‰- 1ä¸ªæœˆå†…

**1. æ€§èƒ½ä¼˜åŒ–**
**å®æ–½éš¾åº¦**ï¼šä¸­ç­‰
**å…·ä½“æ–¹æ¡ˆ**ï¼š
- å®ç°æ•°æ®åº“è¿æ¥æ± 
- ä¼˜åŒ–SQLæŸ¥è¯¢
- æ·»åŠ æŸ¥è¯¢ç¼“å­˜
- å¼‚æ­¥å¤„ç†ä¼˜åŒ–

**2. æ–‡æ¡£å®Œå–„**
**å®æ–½éš¾åº¦**ï¼šç®€å•
**å…·ä½“æ–¹æ¡ˆ**ï¼š
- å®Œå–„APIæ–‡æ¡£
- æ·»åŠ ä»£ç æ³¨é‡Š
- ç¼–å†™éƒ¨ç½²æŒ‡å—
- åˆ›å»ºç”¨æˆ·æ‰‹å†Œ

**3. é€šç”¨åŒ–æ”¹é€ **
**å®æ–½éš¾åº¦**ï¼šé«˜
**å…·ä½“æ–¹æ¡ˆ**ï¼š
- æŠ½è±¡ä¸šåŠ¡é€»è¾‘
- æ”¯æŒé…ç½®åŒ–
- å¤šæ•°æ®åº“æ”¯æŒ
- æ’ä»¶åŒ–æ¶æ„

### 8.3 å®æ–½è·¯çº¿å›¾

#### 8.3.1 ç¬¬ä¸€é˜¶æ®µï¼ˆç¬¬1å‘¨ï¼‰- å®‰å…¨åŠ å›º
- [ ] å®ç°JWTè®¤è¯
- [ ] æ·»åŠ SQLç™½åå•
- [ ] é™åˆ¶CORSæ¥æº
- [ ] å®‰å…¨æµ‹è¯•éªŒè¯

#### 8.3.2 ç¬¬äºŒé˜¶æ®µï¼ˆç¬¬2-3å‘¨ï¼‰- åŠŸèƒ½å®Œå–„
- [ ] å®ç°APIé€Ÿç‡é™åˆ¶
- [ ] æ·»åŠ ç›‘æ§å‘Šè­¦
- [ ] å®Œå–„å•å…ƒæµ‹è¯•
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•

#### 8.3.3 ç¬¬ä¸‰é˜¶æ®µï¼ˆç¬¬4-8å‘¨ï¼‰- ä¼˜åŒ–æå‡
- [ ] æ€§èƒ½ä¼˜åŒ–
- [ ] æ–‡æ¡£å®Œå–„
- [ ] é€šç”¨åŒ–æ”¹é€ 
- [ ] ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### 8.4 é£é™©è¯„ä¼°ä¸ç¼“è§£

#### 8.4.1 ä¸»è¦é£é™©è¯†åˆ«
**å®‰å…¨é£é™©**ï¼š
- **SQLæ³¨å…¥é£é™©**ï¼šAIç”Ÿæˆçš„SQLå¯èƒ½å­˜åœ¨å®‰å…¨æ¼æ´
- **æœªæˆæƒè®¿é—®**ï¼šç¼ºå°‘APIè®¤è¯æœºåˆ¶
- **æ•°æ®æ³„éœ²é£é™©**ï¼šCORSé…ç½®è¿‡å®½

**æŠ€æœ¯é£é™©**ï¼š
- **AIæœåŠ¡ä¾èµ–**ï¼šå¤–éƒ¨AIæœåŠ¡ä¸å¯ç”¨æ—¶å½±å“åŠŸèƒ½
- **æ•°æ®åº“æ€§èƒ½**ï¼šå¤æ‚æŸ¥è¯¢å¯èƒ½å¯¼è‡´æ€§èƒ½é—®é¢˜
- **æ‰©å±•æ€§é™åˆ¶**ï¼šå½“å‰æ¶æ„å¯èƒ½é™åˆ¶æœªæ¥å‘å±•

#### 8.4.2 é£é™©ç¼“è§£æªæ–½
**å®‰å…¨é£é™©ç¼“è§£**ï¼š
- å®æ–½SQLç™½åå•éªŒè¯
- å®ç°JWTè®¤è¯æœºåˆ¶
- é™åˆ¶CORSæ¥æºèŒƒå›´
- æ·»åŠ å®‰å…¨ç›‘æ§å‘Šè­¦

**æŠ€æœ¯é£é™©ç¼“è§£**ï¼š
- å®Œå–„å›é€€æœºåˆ¶
- å®ç°æ€§èƒ½ç›‘æ§
- ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢
- è®¾è®¡æ’ä»¶åŒ–æ¶æ„

### 8.5 é•¿æœŸå‘å±•è§„åˆ’

#### 8.5.1 æŠ€æœ¯æ¼”è¿›æ–¹å‘
**çŸ­æœŸç›®æ ‡ï¼ˆ3ä¸ªæœˆå†…ï¼‰**ï¼š
- å®Œå–„å®‰å…¨æœºåˆ¶
- æé«˜ç³»ç»Ÿç¨³å®šæ€§
- ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ

**ä¸­æœŸç›®æ ‡ï¼ˆ6ä¸ªæœˆå†…ï¼‰**ï¼š
- æ”¯æŒå¤šç§Ÿæˆ·éƒ¨ç½²
- å®ç°æ’ä»¶åŒ–æ¶æ„
- æ”¯æŒå¤šç§æ•°æ®åº“

**é•¿æœŸç›®æ ‡ï¼ˆ1å¹´å†…ï¼‰**ï¼š
- æ„å»ºç”Ÿæ€å¹³å°
- æ”¯æŒç¬¬ä¸‰æ–¹é›†æˆ
- å®ç°å›½é™…åŒ–éƒ¨ç½²

#### 8.5.2 ä¸šåŠ¡å‘å±•å»ºè®®
**äº§å“å®šä½**ï¼š
- å®šä½ä¸ºæ™ºèƒ½æ•°æ®åˆ†æå¹³å°
- æ”¯æŒå¤šç§ä¸šåŠ¡åœºæ™¯
- æä¾›ä¼ä¸šçº§è§£å†³æ–¹æ¡ˆ

**å¸‚åœºç­–ç•¥**ï¼š
- å…ˆå†…éƒ¨ä½¿ç”¨ï¼Œå†å¯¹å¤–æ¨å¹¿
- é‡ç‚¹å‘å±•å‚ç›´è¡Œä¸š
- å»ºç«‹åˆä½œä¼™ä¼´ç”Ÿæ€

**æŠ€æœ¯è·¯çº¿**ï¼š
- ä¿æŒæŠ€æœ¯å…ˆè¿›æ€§
- æ³¨é‡å®‰å…¨æ€§å’Œç¨³å®šæ€§
- æ”¯æŒäº‘åŸç”Ÿéƒ¨ç½²

---

## é™„å½•

### A. æŠ€æœ¯æ ˆæ¸…å•
**åç«¯æ¡†æ¶**ï¼š
- **FastAPI**ï¼šç°ä»£ã€å¿«é€Ÿçš„Webæ¡†æ¶ï¼ŒåŸºäºPython 3.7+
- **Uvicorn**ï¼šASGIæœåŠ¡å™¨ï¼Œæ”¯æŒå¼‚æ­¥å¤„ç†
- **Pydantic**ï¼šæ•°æ®éªŒè¯å’Œåºåˆ—åŒ–åº“

**æ•°æ®åº“**ï¼š
- **PostgreSQL**ï¼šä¼ä¸šçº§å…³ç³»å‹æ•°æ®åº“
- **psycopg2**ï¼šPython PostgreSQLé€‚é…å™¨
- **SQLAlchemy**ï¼šORMæ¡†æ¶ï¼ˆå¯é€‰ï¼‰

**AIæœåŠ¡**ï¼š
- **Claude API**ï¼šAnthropicå®˜æ–¹APIï¼Œæ”¯æŒMCPå·¥å…·è°ƒç”¨
- **DeepSeek API**ï¼šDeepSeekå®˜æ–¹APIï¼Œæˆæœ¬è¾ƒä½
- **httpx**ï¼šå¼‚æ­¥HTTPå®¢æˆ·ç«¯

**å®¹å™¨åŒ–ä¸éƒ¨ç½²**ï¼š
- **Docker**ï¼šå®¹å™¨åŒ–å¹³å°
- **Railway**ï¼šäº‘éƒ¨ç½²å¹³å°
- **Python 3.11**ï¼šè¿è¡Œæ—¶ç¯å¢ƒ

**å¼€å‘å·¥å…·**ï¼š
- **Poetry**ï¼šä¾èµ–ç®¡ç†
- **pytest**ï¼šæµ‹è¯•æ¡†æ¶
- **black**ï¼šä»£ç æ ¼å¼åŒ–
- **flake8**ï¼šä»£ç æ£€æŸ¥

### B. ç¯å¢ƒå˜é‡é…ç½®è¯¦è§£
**å¿…éœ€é…ç½®**ï¼š
```bash
# æ•°æ®åº“è¿æ¥é…ç½®
DB_HOST=localhost                    # æ•°æ®åº“ä¸»æœºåœ°å€
DB_PORT=5432                        # æ•°æ®åº“ç«¯å£
DB_NAME=financetool_test            # æ•°æ®åº“åç§°
DB_USER=financetool_user            # æ•°æ®åº“ç”¨æˆ·å
DB_PASSWORD=financetool_pass        # æ•°æ®åº“å¯†ç 

# AIæœåŠ¡é…ç½®
CLAUDE_API_KEY=your_claude_api_key  # Claude APIå¯†é’¥
DEEPSEEK_API_KEY=your_deepseek_api_key  # DeepSeek APIå¯†é’¥

# æœåŠ¡é…ç½®
PORT=3001                           # æœåŠ¡ç«¯å£
APP_ENV=prod                       # åº”ç”¨ç¯å¢ƒ
```

**å¯é€‰é…ç½®**ï¼š
```bash
# Claude AIé…ç½®
CLAUDE_MODEL=claude-3-5-sonnet-20241022  # æ¨¡å‹ç‰ˆæœ¬
CLAUDE_MAX_TOKENS=4000                   # æœ€å¤§tokenæ•°
CLAUDE_API_BASE_URL=https://api.anthropic.com  # APIåŸºç¡€URL

# DeepSeek AIé…ç½®
DEEPSEEK_MODEL=deepseek-chat             # æ¨¡å‹åç§°
DEEPSEEK_MAX_TOKENS=4000                 # æœ€å¤§tokenæ•°
DEEPSEEK_API_BASE_URL=https://api.deepseek.com  # APIåŸºç¡€URL

# æ•°æ®åº“é…ç½®
DB_CONNECT_TIMEOUT=10                   # è¿æ¥è¶…æ—¶æ—¶é—´
DB_POOL_SIZE=20                         # è¿æ¥æ± å¤§å°

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO                          # æ—¥å¿—çº§åˆ«
LOG_FILE=mcp_service.log                # æ—¥å¿—æ–‡ä»¶è·¯å¾„

# å®‰å…¨é…ç½®
JWT_SECRET_KEY=your_jwt_secret_key      # JWTå¯†é’¥
CORS_ORIGINS=https://yourdomain.com     # CORSå…è®¸çš„æ¥æº
```

### C. éƒ¨ç½²æ£€æŸ¥æ¸…å•
**ç¯å¢ƒé…ç½®æ£€æŸ¥**ï¼š
- [ ] ç¯å¢ƒå˜é‡é…ç½®å®Œæ•´
- [ ] æ•°æ®åº“è¿æ¥å‚æ•°æ­£ç¡®
- [ ] AI APIå¯†é’¥æœ‰æ•ˆä¸”æœªè¿‡æœŸ
- [ ] ç½‘ç»œè¿æ¥æ­£å¸¸ï¼ˆå¯è®¿é—®AIæœåŠ¡ï¼‰

**æœåŠ¡å¯åŠ¨æ£€æŸ¥**ï¼š
- [ ] ä¾èµ–åŒ…å®‰è£…å®Œæ•´
- [ ] æœåŠ¡å¯åŠ¨æ— é”™è¯¯
- [ ] ç«¯å£ç»‘å®šæˆåŠŸ
- [ ] æ—¥å¿—è¾“å‡ºæ­£å¸¸

**åŠŸèƒ½éªŒè¯æ£€æŸ¥**ï¼š
- [ ] å¥åº·æ£€æŸ¥æ¥å£å“åº”æ­£å¸¸
- [ ] æ•°æ®åº“è¿æ¥æµ‹è¯•é€šè¿‡
- [ ] AIæœåŠ¡çŠ¶æ€æ£€æŸ¥æ­£å¸¸
- [ ] åŸºæœ¬æŸ¥è¯¢åŠŸèƒ½æµ‹è¯•é€šè¿‡

**æ€§èƒ½æ£€æŸ¥**ï¼š
- [ ] å“åº”æ—¶é—´åœ¨å¯æ¥å—èŒƒå›´å†…
- [ ] å†…å­˜ä½¿ç”¨æ­£å¸¸
- [ ] CPUä½¿ç”¨ç‡æ­£å¸¸
- [ ] æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½æ­£å¸¸

### D. å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ
**é—®é¢˜1ï¼šClaude APIè°ƒç”¨å¤±è´¥**
**ç—‡çŠ¶**ï¼šæ—¥å¿—æ˜¾ç¤º"Claude APIè¯·æ±‚å¤±è´¥"
**å¯èƒ½åŸå› **ï¼š
- APIå¯†é’¥æ— æ•ˆæˆ–è¿‡æœŸ
- ç½‘ç»œè¿æ¥é—®é¢˜
- APIé…é¢è¶…é™
- è¯·æ±‚æ ¼å¼é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®
2. éªŒè¯ç½‘ç»œè¿æ¥
3. æ£€æŸ¥APIä½¿ç”¨é…é¢
4. æŸ¥çœ‹APIå“åº”é”™è¯¯è¯¦æƒ…

**é—®é¢˜2ï¼šæ•°æ®åº“è¿æ¥å¤±è´¥**
**ç—‡çŠ¶**ï¼šæ—¥å¿—æ˜¾ç¤º"æ•°æ®åº“è¿æ¥å¤±è´¥"
**å¯èƒ½åŸå› **ï¼š
- æ•°æ®åº“æœåŠ¡æœªå¯åŠ¨
- è¿æ¥å‚æ•°é”™è¯¯
- ç½‘ç»œè¿æ¥é—®é¢˜
- æƒé™ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥æ•°æ®åº“æœåŠ¡çŠ¶æ€
2. éªŒè¯è¿æ¥å‚æ•°
3. æµ‹è¯•ç½‘ç»œè¿é€šæ€§
4. æ£€æŸ¥ç”¨æˆ·æƒé™

**é—®é¢˜3ï¼šAIæœåŠ¡å›é€€åˆ°æ¨¡æ¿åŒ¹é…**
**ç—‡çŠ¶**ï¼šæ—¥å¿—æ˜¾ç¤º"ä½¿ç”¨æ¨¡æ¿åŒ¹é…"
**å¯èƒ½åŸå› **ï¼š
- AIæœåŠ¡ä¸å¯ç”¨
- APIè°ƒç”¨è¶…æ—¶
- é…é¢è¶…é™
- é…ç½®é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥AIæœåŠ¡çŠ¶æ€
2. éªŒè¯APIé…ç½®
3. æ£€æŸ¥ä½¿ç”¨é…é¢
4. æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—

### E. æ€§èƒ½ä¼˜åŒ–å»ºè®®
**æ•°æ®åº“ä¼˜åŒ–**ï¼š
```sql
-- åˆ›å»ºç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
CREATE INDEX idx_asset_snapshot_platform ON asset_snapshot(platform);
CREATE INDEX idx_asset_snapshot_asset_type ON asset_snapshot(asset_type);
CREATE INDEX idx_asset_snapshot_snapshot_time ON asset_snapshot(snapshot_time);

-- åˆ†åŒºè¡¨ä¼˜åŒ–å¤§æ•°æ®é‡æŸ¥è¯¢
CREATE TABLE asset_snapshot_partitioned (
    LIKE asset_snapshot INCLUDING ALL
) PARTITION BY RANGE (snapshot_time);

-- åˆ›å»ºåˆ†åŒº
CREATE TABLE asset_snapshot_2024_01 PARTITION OF asset_snapshot_partitioned
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
```

**åº”ç”¨å±‚ä¼˜åŒ–**ï¼š
```python
# è¿æ¥æ± é…ç½®
from psycopg2.pool import SimpleConnectionPool

connection_pool = SimpleConnectionPool(
    minconn=1,
    maxconn=20,
    host=DB_HOST,
    port=DB_PORT,
    database=DB_NAME,
    user=DB_USER,
    password=DB_PASSWORD
)

# æŸ¥è¯¢ç¼“å­˜
from functools import lru_cache

@lru_cache(maxsize=128)
def get_table_schema_cached(table_name: str) -> Dict[str, Any]:
    """å¸¦ç¼“å­˜çš„è¡¨ç»“æ„æŸ¥è¯¢"""
    return get_table_schema(table_name)
```

### F. ç›‘æ§æŒ‡æ ‡å®šä¹‰
**ä¸šåŠ¡æŒ‡æ ‡**ï¼š
- **æŸ¥è¯¢æˆåŠŸç‡**ï¼šæˆåŠŸæŸ¥è¯¢æ•° / æ€»æŸ¥è¯¢æ•°
- **å¹³å‡å“åº”æ—¶é—´**ï¼šæ‰€æœ‰æŸ¥è¯¢å“åº”æ—¶é—´çš„å¹³å‡å€¼
- **AIæœåŠ¡ä½¿ç”¨ç‡**ï¼šClaude vs DeepSeekçš„ä½¿ç”¨æ¯”ä¾‹
- **æ¨¡æ¿åŒ¹é…ç‡**ï¼šä½¿ç”¨æ¨¡æ¿åŒ¹é…çš„æŸ¥è¯¢æ¯”ä¾‹

**æŠ€æœ¯æŒ‡æ ‡**ï¼š
- **æ•°æ®åº“è¿æ¥æ•°**ï¼šå½“å‰æ´»è·ƒçš„æ•°æ®åº“è¿æ¥æ•°
- **å†…å­˜ä½¿ç”¨ç‡**ï¼šåº”ç”¨å†…å­˜ä½¿ç”¨æƒ…å†µ
- **CPUä½¿ç”¨ç‡**ï¼šåº”ç”¨CPUä½¿ç”¨æƒ…å†µ
- **é”™è¯¯ç‡**ï¼šå„ç±»é”™è¯¯çš„å‡ºç°é¢‘ç‡

**å‘Šè­¦é˜ˆå€¼**ï¼š
- **é”™è¯¯ç‡**ï¼š> 10% è§¦å‘è­¦å‘Š
- **å“åº”æ—¶é—´**ï¼š> 5ç§’ è§¦å‘è­¦å‘Š
- **æ•°æ®åº“è¿æ¥**ï¼š> 80% è§¦å‘è­¦å‘Š
- **å†…å­˜ä½¿ç”¨**ï¼š> 85% è§¦å‘è­¦å‘Š

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**ï¼š2024å¹´12æœˆ
**è¯„ä¼°ç‰ˆæœ¬**ï¼šMCPæœåŠ¡ v1.0
**è¯„ä¼°äººå‘˜**ï¼šAIæŠ€æœ¯é¡¾é—®
**æŠ¥å‘ŠçŠ¶æ€**ï¼šå·²å®Œæˆè¯¦ç»†è¯„ä¼°
**ä¸‹æ¬¡è¯„ä¼°å»ºè®®**ï¼šå®æ–½å®‰å…¨æ”¹è¿›åé‡æ–°è¯„ä¼°
